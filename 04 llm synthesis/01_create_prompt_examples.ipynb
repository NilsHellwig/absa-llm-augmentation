{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bb99927-a103-43f1-83a3-a945c547b342",
   "metadata": {},
   "source": [
    "# Notebook: Create Examples for Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08eed044",
   "metadata": {},
   "source": [
    "* Todo: Prüfen, wie lange Prompt wäre\n",
    "* Todo: Classifier anpassen an neue Größen\n",
    "* Prüfen ob wirklich neue Beispiele genommen werden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e32d2bd-049d-4bf6-9da7-3ef4bf665fef",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "399c6d6b-93d8-43c6-bc92-b4777c79d699",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_few_shot_generation import get_examples_for_fixed_label, get_random_examples\n",
    "from itertools import cycle, islice\n",
    "import numpy as np\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac519d5-7c23-4fd8-8bac-93b4f1b1f17f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "162de018",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 43\n",
    "random.seed(SEED)\n",
    "N_RETRY_SETS = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7eaae3a2-87e7-4008-b715-f548b8312ea8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup Classes/Polarities for Synthesis\n",
    "CLASSES  = [\"GENERAL-IMPRESSION\", \"FOOD\", \"SERVICE\", \"AMBIENCE\", \"PRICE\"]\n",
    "POLARITIES = [\"POSITIVE\", \"NEUTRAL\", \"NEGATIVE\"]\n",
    "COMBINATIONS = [(aspect, polarity) for polarity in POLARITIES for aspect in CLASSES]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2231fc-6972-4230-ac87-32530d8a1418",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6c613c-b693-4072-b1da-a79fc80f3e2b",
   "metadata": {},
   "source": [
    "### Create Function to get Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "23111433-11b5-416e-b16e-2d28f0174428",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_n_labels(n_labels):\n",
    "    label_ratio = {\"1\": int(0.5 * n_labels),\n",
    "                   \"2\": int(0.3 * n_labels),\n",
    "                   \"3\": int(0.2 * n_labels)}\n",
    "    if n_labels != sum(label_ratio.values()):\n",
    "        raise Exception(\"n_labels != sum(label_ratio.values())\")\n",
    "\n",
    "    n_tuples = 0\n",
    "    for key, value in label_ratio.items():\n",
    "        n_tuples += int(key) * value\n",
    "    n_tuples\n",
    "\n",
    "    aspect_polarity_tuples_list = list(islice(cycle(COMBINATIONS), n_tuples))\n",
    "    random.shuffle(aspect_polarity_tuples_list)\n",
    "    tuples_list = []\n",
    "    idx_start = 0\n",
    "    for key, value in label_ratio.items():\n",
    "        tuple_list_n_aspect = aspect_polarity_tuples_list[idx_start: idx_start + value*int(\n",
    "            key)]\n",
    "\n",
    "        k = 0\n",
    "        for i in range(int(len(tuple_list_n_aspect)/int(key))):\n",
    "            tuples_list.append(tuple_list_n_aspect[k:k+int(key)])\n",
    "            k += int(key)\n",
    "\n",
    "        idx_start += int(key) * int(value)\n",
    "    random.shuffle(tuples_list)\n",
    "    return tuples_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a51dee5",
   "metadata": {},
   "source": [
    "### Code to Count Prompt Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cbca62c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import get_examples_as_text\n",
    "import tiktoken\n",
    "\n",
    "with open('../prompt_template.txt', 'r') as file:\n",
    "    PROMPT_TEMPLATE = file.read()\n",
    "\n",
    "def num_tokens_from_string(string: str) -> int:\n",
    "    # I will use the gpt tokenizer\n",
    "    encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "def check_prompt_size(dataset, examples, label):\n",
    "    few_shot_examples = [entry for entry in dataset if entry['id'] in examples]\n",
    "\n",
    "    # Build Prompt\n",
    "    examples_text = get_examples_as_text(few_shot_examples)\n",
    "    prompt_footer = f'\\nLabel:{str(label)}\\nPrediction:'\n",
    "    prompt = PROMPT_TEMPLATE + examples_text + prompt_footer\n",
    "    return num_tokens_from_string(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452f0b6d-bf56-494b-b6ca-bc5d101b7b30",
   "metadata": {},
   "source": [
    "### Create Fixed Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2f78a6-6b38-484b-81d2-9f1dd6c73d0e",
   "metadata": {},
   "source": [
    "For the condition where I always use the same 10 Few-Shot Examples I will select random Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "413072e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_sizes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a96b864e-630d-44b8-869c-acae7c6287b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "condition_size = [490, 500, 1000]\n",
    "few_shot_examples_fixed = {}\n",
    "\n",
    "for split_id in range(5):\n",
    "    # Add index for split\n",
    "    few_shot_examples_fixed[f\"split_{split_id}\"] = {}\n",
    "\n",
    "    # Load real examples\n",
    "    with open(f\"../07 train classifier/real/split_{split_id}.json\", 'r', encoding='utf-8') as json_file:\n",
    "        dataset = json.load(json_file)\n",
    "\n",
    "    # Define fixed labels for split\n",
    "    labels = []\n",
    "    for size in condition_size:\n",
    "        labels += get_n_labels(size)\n",
    "\n",
    "    few_shot_examples_fixed[f\"split_{split_id}\"][\"labels_for_prediction\"] = labels\n",
    "\n",
    "    # Get 10 random examples\n",
    "    fixed_examples = get_examples_for_fixed_label(CLASSES, dataset, random, 2)\n",
    "\n",
    "    # Add 2000 Shuffles of fixed examples x 25 -> In case synthesis doesn't work\n",
    "    few_shot_examples_fixed[f\"split_{split_id}\"][\"few_shot_ids\"] = {}\n",
    "    for i in range(sum(condition_size)):\n",
    "        few_shot_examples_fixed[f\"split_{split_id}\"][\"few_shot_ids\"][i] = {}\n",
    "\n",
    "        for k in range(N_RETRY_SETS):\n",
    "            shuffled_fixed_examples = fixed_examples.copy()\n",
    "            random.shuffle(shuffled_fixed_examples)\n",
    "            few_shot_examples_fixed[f\"split_{split_id}\"][\"few_shot_ids\"][i][k] = shuffled_fixed_examples\n",
    "\n",
    "    # Calculate prompt size\n",
    "    prompt_sizes.append(check_prompt_size(\n",
    "        dataset, shuffled_fixed_examples, labels[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f6160dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Fixed Examples Prompt Size: 938.2\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Fixed Examples Prompt Size | avg: \" + str(np.mean(prompt_sizes)) + \" | \" + str(str(np.max(prompt_sizes))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbaaa582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1990)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(few_shot_examples_fixed[\"split_0\"][\"few_shot_ids\"]), len(few_shot_examples_fixed[\"split_0\"][\"labels_for_prediction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d76b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"few_shot_examples/few_shot_examples_fixed.json\", 'w') as json_file:\n",
    "    json.dump(few_shot_examples_fixed, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea6f942-107e-4f86-b15f-b62413d94f7c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create Random Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "842e620c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_sizes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "87caf6a2-c02f-41b4-898e-49e44925dea2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "0 100\n",
      "0 200\n",
      "0 300\n",
      "0 400\n",
      "0 500\n",
      "0 600\n",
      "0 700\n",
      "0 800\n",
      "0 900\n",
      "0 1000\n",
      "0 1100\n",
      "0 1200\n",
      "0 1300\n",
      "0 1400\n",
      "0 1500\n",
      "0 1600\n",
      "0 1700\n",
      "0 1800\n",
      "0 1900\n",
      "1 0\n",
      "1 100\n",
      "1 200\n",
      "1 300\n",
      "1 400\n",
      "1 500\n",
      "1 600\n",
      "1 700\n",
      "1 800\n",
      "1 900\n",
      "1 1000\n",
      "1 1100\n",
      "1 1200\n",
      "1 1300\n",
      "1 1400\n",
      "1 1500\n",
      "1 1600\n",
      "1 1700\n",
      "1 1800\n",
      "1 1900\n",
      "2 0\n",
      "2 100\n",
      "2 200\n",
      "2 300\n",
      "2 400\n",
      "2 500\n",
      "2 600\n",
      "2 700\n",
      "2 800\n",
      "2 900\n",
      "2 1000\n",
      "2 1100\n",
      "2 1200\n",
      "2 1300\n",
      "2 1400\n",
      "2 1500\n",
      "2 1600\n",
      "2 1700\n",
      "2 1800\n",
      "2 1900\n",
      "3 0\n",
      "3 100\n",
      "3 200\n",
      "3 300\n",
      "3 400\n",
      "3 500\n",
      "3 600\n",
      "3 700\n",
      "3 800\n",
      "3 900\n",
      "3 1000\n",
      "3 1100\n",
      "3 1200\n",
      "3 1300\n",
      "3 1400\n",
      "3 1500\n",
      "3 1600\n",
      "3 1700\n",
      "3 1800\n",
      "3 1900\n",
      "4 0\n",
      "4 100\n",
      "4 200\n",
      "4 300\n",
      "4 400\n",
      "4 500\n",
      "4 600\n",
      "4 700\n",
      "4 800\n",
      "4 900\n",
      "4 1000\n",
      "4 1100\n",
      "4 1200\n",
      "4 1300\n",
      "4 1400\n",
      "4 1500\n",
      "4 1600\n",
      "4 1700\n",
      "4 1800\n",
      "4 1900\n"
     ]
    }
   ],
   "source": [
    "condition_size = [500, 500, 1000]\n",
    "few_shot_examples_random = {}\n",
    "\n",
    "for split_id in range(5):\n",
    "    # Add index for split\n",
    "    few_shot_examples_random[f\"split_{split_id}\"] = {}\n",
    "\n",
    "    # Load real examples\n",
    "    with open(f\"../07 train classifier/real/split_{split_id}.json\", 'r', encoding='utf-8') as json_file:\n",
    "        dataset = json.load(json_file)\n",
    "\n",
    "    # Define fixed labels for split\n",
    "    labels = []\n",
    "    for size in condition_size:\n",
    "        labels += get_n_labels(size)\n",
    "    few_shot_examples_random[f\"split_{split_id}\"][\"labels_for_prediction\"] = labels\n",
    "\n",
    "    # Add Shuffles of fixed examples x 25 -> In case synthesis doesn't work\n",
    "    few_shot_examples_random[f\"split_{split_id}\"][\"few_shot_ids\"] = {}\n",
    "    for i in range(sum(condition_size)):\n",
    "        if i % 1000 == 0:\n",
    "            print(split_id, i)\n",
    "        few_shot_examples_random[f\"split_{split_id}\"][\"few_shot_ids\"][i] = {}\n",
    "        for k in range(N_RETRY_SETS):\n",
    "            random_examples = get_random_examples(\n",
    "                10, labels[i], dataset, random, CLASSES)\n",
    "            few_shot_examples_random[f\"split_{split_id}\"][\"few_shot_ids\"][i][k] = random_examples\n",
    "            # Calculate prompt size\n",
    "            prompt_sizes.append(check_prompt_size(\n",
    "                dataset, random_examples, labels[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "586961ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Fixed Examples Prompt Size | avg: 926.099176 | 1579\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Fixed Examples Prompt Size | avg: \" + str(np.mean(prompt_sizes)) + \" | \" + str(str(np.max(prompt_sizes))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f7dd67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(few_shot_examples_random[\"split_0\"][\"few_shot_ids\"]), len(few_shot_examples_random[\"split_0\"][\"labels_for_prediction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a21830",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"few_shot_examples/few_shot_examples_random.json\", 'w') as json_file:\n",
    "    json.dump(few_shot_examples_random, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39007d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('GENERAL-IMPRESSION', 'NEGATIVE'), ('GENERAL-IMPRESSION', 'NEGATIVE')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "few_shot_examples_random[\"split_0\"][\"labels_for_prediction\"][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
