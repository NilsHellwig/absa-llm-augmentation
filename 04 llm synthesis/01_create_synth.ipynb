{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bb99927-a103-43f1-83a3-a945c547b342",
   "metadata": {},
   "source": [
    "# Notebook: Split Dataset in folds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e32d2bd-049d-4bf6-9da7-3ef4bf665fef",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "399c6d6b-93d8-43c6-bc92-b4777c79d699",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import divide_equally, get_examples_for_aspects_in_label, get_examples_as_text, xml_to_json, is_valid_xml, check_valid_aspect_xml, count_sentences_in_text\n",
    "from IPython.display import clear_output\n",
    "from itertools import cycle, islice\n",
    "from dotenv import load_dotenv\n",
    "from llama_cpp import Llama\n",
    "import numpy as np\n",
    "import itertools\n",
    "import warnings\n",
    "import random\n",
    "import openai\n",
    "import json\n",
    "import uuid\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ba178e1d-cb71-4592-bc13-4117f199da2e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fcaa69-41c0-4e90-a522-f4d3915d16fe",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "83965861-d5ac-4d59-a373-a26ca8743c57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SPLIT = 0\n",
    "MODEL_ID = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac519d5-7c23-4fd8-8bac-93b4f1b1f17f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "54dca12b-2965-4441-b1ce-48a1008a129d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = f'../03 dataset split/real/real_{SPLIT}.json'\n",
    "MAX_TOKENS = 250\n",
    "CONTEXT_SIZE = 4096\n",
    "SEED = int(str(43) + str(SPLIT) + str(MODEL_ID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7eaae3a2-87e7-4008-b715-f548b8312ea8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup Classes/Polarities for Synthesis\n",
    "CLASSES  = [\"GENERAL-IMPRESSION\", \"FOOD\", \"SERVICE\", \"AMBIENCE\", \"PRICE\"]\n",
    "POLARITIES = [\"POSITIVE\", \"NEUTRAL\", \"NEGATIVE\"]\n",
    "COMBINATIONS = [(aspect, polarity) for polarity in POLARITIES for aspect in CLASSES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9aef1ca2-4279-4d15-9157-54fa7093b95b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "STOP_CRITERIA = [\"Label:\", \"\\n\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2bbf5c9b-7f77-4466-99b8-fa1bc7fa51aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "243bd623-87d1-4448-9a42-600c9158dbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = [\"Llama13B\", \"Llama70B\", \"Falcon40B\", \"GPT-3\"]\n",
    "# 175B, 70B und 40B\n",
    "MODEL_PATHS = {\"Llama13B\": \"llama-2-13b.Q4_0.gguf\", \"Llama70B\": \"llama-2-70b.Q4_0.gguf\", \"Falcon40B\": \"falcon-40b-Q4_K_S.gguf\"}\n",
    "MODEL_NAME = MODELS[MODEL_ID]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2231fc-6972-4230-ac87-32530d8a1418",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee9da56-2f69-40ec-8bb2-d493f2c50f84",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create Labels for Synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7ad1cb2f-cdd2-40f3-9f1a-2d8c4ccf86ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_ratio = {\"1\": int(0.1 * 500), \"2\": int(0.4 * 500), \"3\": int(0.5 * 500)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d45ce04f-2381-4f19-8b56-6a084fb275d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': 50, '2': 200, '3': 250}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba0699e-353b-4c0f-a8e2-719b510da291",
   "metadata": {},
   "source": [
    "### Calculate how many Aspect-Polarity Pairs should be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b43ab0b6-a2bd-447f-9fbc-d3feefa89855",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1200"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_tuples = 0\n",
    "for key, value in label_ratio.items():\n",
    "    n_tuples += int(key) * value\n",
    "n_tuples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6c613c-b693-4072-b1da-a79fc80f3e2b",
   "metadata": {},
   "source": [
    "### Create List of balanced aspect-polarity tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "23111433-11b5-416e-b16e-2d28f0174428",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_500_labels():\n",
    "    aspect_polarity_tuples_list = list(islice(cycle(COMBINATIONS), n_tuples))\n",
    "    random.shuffle(aspect_polarity_tuples_list)\n",
    "    \n",
    "    tuples_list = []\n",
    "    idx_start = 0\n",
    "    for key, value in label_ratio.items():\n",
    "        tuple_list_n_aspect = aspect_polarity_tuples_list[idx_start: idx_start + value*int(key)]\n",
    "\n",
    "        k = 0\n",
    "        for i in range(int(len(tuple_list_n_aspect)/int(key))):\n",
    "            tuples_list.append(tuple_list_n_aspect[k:k+int(key)])\n",
    "            k += int(key)\n",
    "            \n",
    "        idx_start += int(key) * int(value)\n",
    "    random.shuffle(tuples_list)\n",
    "    return tuples_list\n",
    "\n",
    "labels = get_500_labels() + get_500_labels() + get_500_labels() + get_500_labels()\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7c44e0-b2ad-4e98-b48a-5c821b68b842",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Setup Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ff2483b2-621a-4f0e-86f3-a0d2ce921ea0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('../prompt_template.txt', 'r') as file:\n",
    "    PROMPT_TEMPLATE = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27e2452-ebd5-47e4-8b9a-bdd011ea139c",
   "metadata": {},
   "source": [
    "### Load Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "817d57c6-f670-446f-9014-706bf10ec4d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(DATASET_PATH, 'r', encoding='utf-8') as json_file:\n",
    "    dataset = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040660c9-c758-4f82-82bc-17883d92f7f3",
   "metadata": {},
   "source": [
    "### Setup Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "194f288c-533a-4776-aee8-91556516cd81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if MODEL_NAME == \"Llama70B\":\n",
    "    llm = Llama(model_path=MODEL_PATHS[MODEL_NAME], seed=SEED, n_gpu_layers=1, n_ctx=CONTEXT_SIZE, verbose=False, n_gqa=8)\n",
    "    clear_output(wait=False)\n",
    "    def llm_model(text):\n",
    "        return llm(prompt, max_tokens=MAX_TOKENS, stop=STOP_CRITERIA, echo=True, top_p=1)[\"choices\"][0][\"text\"][len(text):]\n",
    "    \n",
    "if MODEL_NAME == \"Llama13B\" or MODEL_NAME == \"Falcon40B\":\n",
    "    llm = Llama(model_path=MODEL_PATHS[MODEL_NAME], seed=SEED, n_gpu_layers=1, n_ctx=CONTEXT_SIZE, verbose=False)\n",
    "    clear_output(wait=False)\n",
    "    def llm_model(text):\n",
    "        return llm(prompt, max_tokens=MAX_TOKENS, stop=STOP_CRITERIA, echo=True, top_p=1)[\"choices\"][0][\"text\"][len(text):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "34d4e54d-0533-4d64-8a69-7383169293e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if MODEL_NAME == \"GPT-3\":\n",
    "    openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    def llm_model(text):\n",
    "        response = openai.ChatCompletion.create(\n",
    "           model=\"gpt-3.5-turbo\",\n",
    "           messages=[\n",
    "              {\"role\": \"user\", \"content\": text}\n",
    "           ],\n",
    "           max_tokens=MAX_TOKENS,  \n",
    "           temperature=0.7, \n",
    "           stop=STOP_CRITERIA\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea6f942-107e-4f86-b15f-b62413d94f7c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create Synthetic Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6cf3ee06-3bfa-4366-b8ba-6fdfec400a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_dataset = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b6fa3658-fbe2-4856-bce1-38d3dea48295",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for label in labels[:5]:\n",
    "    \n",
    "    valid_example = False\n",
    "    invalid_xml_schema = 0\n",
    "    invalid_xml_tags = 0\n",
    "    aspect_polarity_in_text_but_not_in_label = 0\n",
    "    more_than_one_sentences = 0\n",
    "    \n",
    "    while valid_example == False:\n",
    "        unique_aspects = [aspect for aspect, _ in label if label.count((aspect, _)) == 1]\n",
    "    \n",
    "        ids_examples_for_aspects = get_examples_for_aspects_in_label(unique_aspects, dataset, random)\n",
    "        additional_examples = [entry for entry in dataset if entry['id'] not in ids_examples_for_aspects]\n",
    "        additional_examples = random.sample(additional_examples, 10-len(ids_examples_for_aspects))\n",
    "\n",
    "        examples = additional_examples + [entry for entry in dataset if entry['id'] in ids_examples_for_aspects]\n",
    "        examples_text = get_examples_as_text(examples)\n",
    "    \n",
    "        prompt_footer = f'\\nLabel:{str(label)}\\nPrediction:'\n",
    "        prompt = PROMPT_TEMPLATE + examples_text + prompt_footer\n",
    "    \n",
    "        prediction = llm_model(prompt)\n",
    "        \n",
    "        if is_valid_xml(f'<input>{prediction}</input>') == False:\n",
    "            invalid_xml_schema += 1\n",
    "        else:\n",
    "            if check_valid_aspect_xml(f'<input>{prediction}</input>') == False:\n",
    "                invalid_xml_tags += 1\n",
    "            else: \n",
    "                prediction_as_json = xml_to_json(prediction, label, MODEL_NAME, SPLIT)\n",
    "                if prediction_as_json == \"not-in-label\":\n",
    "                    aspect_polarity_in_text_but_not_in_label += 1\n",
    "                else: \n",
    "                    if count_sentences_in_text(prediction_as_json[\"text\"]) > 1:\n",
    "                        more_than_one_sentences += 1\n",
    "                    else:\n",
    "                        valid_example = True\n",
    "    \n",
    "    prediction_as_json[\"llm_label\"] = label\n",
    "    prediction_as_json[\"llm_examples\"] = examples\n",
    "    prediction_as_json[\"llm_invalid_xml_schema\"] = invalid_xml_schema\n",
    "    prediction_as_json[\"llm_invalid_xml_tags\"] = invalid_xml_tags\n",
    "    prediction_as_json[\"llm_aspect_polarity_in_text_but_not_in_label\"] = aspect_polarity_in_text_but_not_in_label\n",
    "    prediction_as_json[\"llm_more_than_one_sentences\"] = more_than_one_sentences\n",
    "    \n",
    "    synth_dataset.append(prediction_as_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bbb55592-4e15-4e4e-98b0-ed3346ec21af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "json_file_path = f\"synth/{MODEL_NAME}/split_{SPLIT}.json\"\n",
    "os.makedirs(os.path.dirname(json_file_path), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "87caf6a2-c02f-41b4-898e-49e44925dea2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(json_file_path, \"w\") as outfile:\n",
    "    json.dump(synth_dataset, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "755d0e66-6cba-4f3e-ad82-03e224dd44c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Mitten im Chalets und Hütten der Gegend',\n",
       "  [('FOOD', 'NEUTRAL'), ('AMBIENCE', 'NEUTRAL')],\n",
       "  ['Käsespätzle sind halt nicht mit einer Alm zu vergleichen.',\n",
       "   'Käsespätzle sind halt nicht mit einer Alm zu vergleichen.',\n",
       "   'LOC, eine beeindruckende Kuchen- und Tortenauswahl und ein Interior Design, das als Filmkulisse für eine Geschischte dienen könnte, die in den goldenen 1920er Jahren spielt.',\n",
       "   'Suppe war nicht heiß, kümmerte den Service aber nicht.',\n",
       "   'War zwar viel los, dennoch hat das Personal nicht an Höflichkeit und Spaß verloren.',\n",
       "   'Niemand hatte den Tisch im Blick, keiner fühlte sich zuständig.',\n",
       "   'Irgendwann kam unser Kellner nicht mehr, wir mussten andere Kellner ansprechen, damit sie ihn holten, um noch Getränke bestellen zu können.',\n",
       "   'Käsespätzle sind halt nicht mit einer Alm zu vergleichen.',\n",
       "   'LOC, eine beeindruckende Kuchen- und Tortenauswahl und ein Interior Design, das als Filmkulisse für eine Geschischte dienen könnte, die in den goldenen 1920er Jahren spielt.',\n",
       "   'Käsespätzle sind halt nicht mit einer Alm zu vergleichen.']),\n",
       " ('Wir würden wiederkommen.',\n",
       "  [('SERVICE', 'NEUTRAL'), ('SERVICE', 'NEUTRAL'), ('PRICE', 'NEUTRAL')],\n",
       "  ['Käsespätzle sind halt nicht mit einer Alm zu vergleichen.',\n",
       "   'Wir würden wiederkommen.',\n",
       "   'Keine BedienungSind 1 1/2 Stunden im Gastgarten gesessen aber es hat sich kein Kellner zuständig gefühlt Auch bei Nachfrage ging alles nur sehr schleppendBekamen dan nur ein Getränk und wollten eigentlich essen.',\n",
       "   'Suppe war nicht heiß, kümmerte den Service aber nicht.',\n",
       "   'Alles war wunderbar.',\n",
       "   'Käsespätzle sind halt nicht mit einer Alm zu vergleichen.',\n",
       "   'Für mich war das leider rausgeworfenes Geld.',\n",
       "   'Wir sind maximal enttäuscht und werden uns überlegen, ob wir wirklich nochmal hingehen.',\n",
       "   'Suppe war nicht heiß, kümmerte den Service aber nicht.',\n",
       "   'Für mich war das leider rausgeworfenes Geld.']),\n",
       " ('Wir sind maximal enttäuscht und werden uns überlegen, ob wir wirklich nochmal hingehen.',\n",
       "  [('GENERAL-IMPRESSION', 'NEGATIVE'), ('PRICE', 'NEUTRAL')],\n",
       "  ['Waren 2x dort, da uns das Ambiente eigentlich gut gefällt.',\n",
       "   'Keine BedienungSind 1 1/2 Stunden im Gastgarten gesessen aber es hat sich kein Kellner zuständig gefühlt Auch bei Nachfrage ging alles nur sehr schleppendBekamen dan nur ein Getränk und wollten eigentlich essen.',\n",
       "   'Wir sind maximal enttäuscht und werden uns überlegen, ob wir wirklich nochmal hingehen.',\n",
       "   'Das Essen war super.',\n",
       "   'Suppe war nicht heiß, kümmerte den Service aber nicht.',\n",
       "   'Im Vergleich zum Personal im Schlüssel und LOC bleibt das Uerige aber doch zurück.',\n",
       "   'Alles war wunderbar.',\n",
       "   'Wir würden wiederkommen.',\n",
       "   'Wir sind maximal enttäuscht und werden uns überlegen, ob wir wirklich nochmal hingehen.',\n",
       "   'Für mich war das leider rausgeworfenes Geld.']),\n",
       " ('Irgendwann kam unser Kellner nicht mehr, wir mussten andere Kellner ansprechen, damit sie ihn holten, um noch Getränke bestellen zu können .',\n",
       "  [('FOOD', 'NEUTRAL'), ('SERVICE', 'NEUTRAL'), ('FOOD', 'NEUTRAL')],\n",
       "  ['Alles war wunderbar.',\n",
       "   'Suppe war nicht heiß, kümmerte den Service aber nicht.',\n",
       "   'Im Vergleich zum Personal im Schlüssel und LOC bleibt das Uerige aber doch zurück.',\n",
       "   'Alles war wunderbar.',\n",
       "   'Wir sind maximal enttäuscht und werden uns überlegen, ob wir wirklich nochmal hingehen.',\n",
       "   'Käsespätzle sind halt nicht mit einer Alm zu vergleichen.',\n",
       "   'Keine BedienungSind 1 1/2 Stunden im Gastgarten gesessen aber es hat sich kein Kellner zuständig gefühlt Auch bei Nachfrage ging alles nur sehr schleppendBekamen dan nur ein Getränk und wollten eigentlich essen.',\n",
       "   'Wir sind maximal enttäuscht und werden uns überlegen, ob wir wirklich nochmal hingehen.',\n",
       "   'War zwar viel los, dennoch hat das Personal nicht an Höflichkeit und Spaß verloren.',\n",
       "   'Irgendwann kam unser Kellner nicht mehr, wir mussten andere Kellner ansprechen, damit sie ihn holten, um noch Getränke bestellen zu können.']),\n",
       " ('Kellner hätte nichts angebracht, Preis war aber ok.',\n",
       "  [('SERVICE', 'NEGATIVE'), ('FOOD', 'NEUTRAL'), ('PRICE', 'POSITIVE')],\n",
       "  ['Waren 2x dort, da uns das Ambiente eigentlich gut gefällt.',\n",
       "   'Keine BedienungSind 1 1/2 Stunden im Gastgarten gesessen aber es hat sich kein Kellner zuständig gefühlt Auch bei Nachfrage ging alles nur sehr schleppendBekamen dan nur ein Getränk und wollten eigentlich essen.',\n",
       "   'Unbedingt fernbleiben!',\n",
       "   'Suppe war nicht heiß, kümmerte den Service aber nicht.',\n",
       "   'Wir sind maximal enttäuscht und werden uns überlegen, ob wir wirklich nochmal hingehen.',\n",
       "   'Irgendwann kam unser Kellner nicht mehr, wir mussten andere Kellner ansprechen, damit sie ihn holten, um noch Getränke bestellen zu können.',\n",
       "   'War zwar viel los, dennoch hat das Personal nicht an Höflichkeit und Spaß verloren.',\n",
       "   'Für mich war das leider rausgeworfenes Geld.',\n",
       "   'Das Essen war super.',\n",
       "   'Keine BedienungSind 1 1/2 Stunden im Gastgarten gesessen aber es hat sich kein Kellner zuständig gefühlt Auch bei Nachfrage ging alles nur sehr schleppendBekamen dan nur ein Getränk und wollten eigentlich essen.'])]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(example[\"text\"], example[\"llm_label\"], [text[\"text\"] for text in example[\"llm_examples\"]]) for example in synth_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bce0f14-781f-4e36-8599-8b20d07b10d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
