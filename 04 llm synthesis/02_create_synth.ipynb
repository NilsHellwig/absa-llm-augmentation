{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bb99927-a103-43f1-83a3-a945c547b342",
   "metadata": {},
   "source": [
    "# Notebook: Create Synthetic Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e32d2bd-049d-4bf6-9da7-3ef4bf665fef",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "399c6d6b-93d8-43c6-bc92-b4777c79d699",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_synthesis import get_examples_as_text, xml_to_json, is_valid_xml, check_valid_aspect_xml, count_sentences_in_text, german_language_detected\n",
    "from IPython.display import clear_output\n",
    "from dotenv import load_dotenv\n",
    "from llama_cpp import Llama\n",
    "import random\n",
    "import openai\n",
    "import json\n",
    "import uuid\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "ba178e1d-cb71-4592-bc13-4117f199da2e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fcaa69-41c0-4e90-a522-f4d3915d16fe",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "83965861-d5ac-4d59-a373-a26ca8743c57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SPLIT = 4\n",
    "MODEL_ID = 0\n",
    "FEW_SHOTS = \"fixed\" # \"fixed\" or \"random\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac519d5-7c23-4fd8-8bac-93b4f1b1f17f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "54dca12b-2965-4441-b1ce-48a1008a129d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = f'../07 train classifier/real/split_{SPLIT}.json'\n",
    "LABELS_AND_EXAMPLES_PATH = f\"few_shot_examples/few_shot_examples_{FEW_SHOTS}.json\"\n",
    "\n",
    "# LLM Settings\n",
    "MAX_TOKENS = 250\n",
    "CONTEXT_SIZE = 4096\n",
    "TEMPERATURE = 0.7\n",
    "\n",
    "# Set Seed\n",
    "SEED = int(str(43) + str(SPLIT) + str(MODEL_ID))\n",
    "\n",
    "N_RETRIES = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "7eaae3a2-87e7-4008-b715-f548b8312ea8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup Classes/Polarities for Synthesis\n",
    "CLASSES  = [\"GENERAL-IMPRESSION\", \"FOOD\", \"SERVICE\", \"AMBIENCE\", \"PRICE\"]\n",
    "POLARITIES = [\"POSITIVE\", \"NEUTRAL\", \"NEGATIVE\"]\n",
    "COMBINATIONS = [(aspect, polarity) for polarity in POLARITIES for aspect in CLASSES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "9aef1ca2-4279-4d15-9157-54fa7093b95b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "STOP_CRITERIA = [\"Label:\", \"\\n\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "2bbf5c9b-7f77-4466-99b8-fa1bc7fa51aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "243bd623-87d1-4448-9a42-600c9158dbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = [\"Llama13B\", \"Llama70B\", \"Falcon40B\", \"GPT-3\"]\n",
    "# 175B, 70B und 40B\n",
    "MODEL_PATHS = {\"Llama13B\": \"llm_models/llama-2-13b.Q4_0.gguf\", \"Llama70B\": \"llm_models/llama-2-70b.Q4_0.gguf\", \"Falcon40B\": \"llm_models/falcon-40b-Q4_K_S.gguf\"}\n",
    "MODEL_NAME = MODELS[MODEL_ID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "a2424728-2345-46c6-b27b-116d203f869d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYNTH_PATH = f\"../07 train classifier/synth/{MODEL_NAME}/{FEW_SHOTS}/split_{SPLIT}.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2231fc-6972-4230-ac87-32530d8a1418",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7c44e0-b2ad-4e98-b48a-5c821b68b842",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Setup Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "ff2483b2-621a-4f0e-86f3-a0d2ce921ea0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('../prompt_template.txt', 'r') as file:\n",
    "    PROMPT_TEMPLATE = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27e2452-ebd5-47e4-8b9a-bdd011ea139c",
   "metadata": {},
   "source": [
    "### Load Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "817d57c6-f670-446f-9014-706bf10ec4d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(DATASET_PATH, 'r', encoding='utf-8') as json_file:\n",
    "    dataset = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040660c9-c758-4f82-82bc-17883d92f7f3",
   "metadata": {},
   "source": [
    "### Setup Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "194f288c-533a-4776-aee8-91556516cd81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if MODEL_NAME == \"Llama70B\":\n",
    "    llm = Llama(model_path=MODEL_PATHS[MODEL_NAME], seed=SEED, n_gpu_layers=1, n_ctx=CONTEXT_SIZE, verbose=False, n_gqa=8)\n",
    "    clear_output(wait=False)\n",
    "    def llm_model(text):\n",
    "        return llm(text, max_tokens=MAX_TOKENS, stop=STOP_CRITERIA, echo=True, top_p=1, temperature=TEMPERATURE)[\"choices\"][0][\"text\"][len(text):]\n",
    "    \n",
    "if MODEL_NAME == \"Llama13B\" or MODEL_NAME == \"Falcon40B\":\n",
    "    llm = Llama(model_path=MODEL_PATHS[MODEL_NAME], seed=SEED, n_gpu_layers=1, n_ctx=CONTEXT_SIZE, verbose=False)\n",
    "    clear_output(wait=False)\n",
    "    def llm_model(text):\n",
    "        return llm(text, max_tokens=MAX_TOKENS, stop=STOP_CRITERIA, echo=True, top_p=1, temperature=TEMPERATURE)[\"choices\"][0][\"text\"][len(text):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "34d4e54d-0533-4d64-8a69-7383169293e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if MODEL_NAME == \"GPT-3\":\n",
    "    openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    def llm_model(text):\n",
    "        response = openai.ChatCompletion.create(\n",
    "           model=\"gpt-3.5-turbo\",\n",
    "           messages=[\n",
    "              {\"role\": \"user\", \"content\": text}\n",
    "           ],\n",
    "           max_tokens=MAX_TOKENS,  \n",
    "           temperature=TEMPERATURE, \n",
    "           stop=STOP_CRITERIA\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452f0b6d-bf56-494b-b6ca-bc5d101b7b30",
   "metadata": {},
   "source": [
    "### Load Labels and Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "7c780171",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(LABELS_AND_EXAMPLES_PATH, 'r', encoding='utf-8') as json_file:\n",
    "    labels_and_examples = json.load(json_file)[f\"split_{SPLIT}\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "f8350a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels_and_examples[\"labels_for_prediction\"]\n",
    "labels = [[(aspect, polarity) for aspect, polarity in sub_list] for sub_list in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "161cf83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = labels_and_examples[\"few_shot_ids\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea6f942-107e-4f86-b15f-b62413d94f7c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create Synthetic Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "6cf3ee06-3bfa-4366-b8ba-6fdfec400a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_dataset = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "d6307db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current index: 0, n_retry: 0, text: Der Preis ist in Ordnung. Wir kannten allerdings <aspect-term aspect=\"GENERAL-IMPRESSION\" polarity=\"NEGATIVE\">einen günstigeren Laden</aspect-term>.\n",
      "current index: 0, n_retry: 1, text: Die Portionen waren groß und <aspect-term aspect=\"PRICE\" polarity=\"POSITIVE\">preiswerter</aspect-term>.\n",
      "current index: 1, n_retry: 0, text: Noch immer nicht sicher, ob wir wiederkommen werden.\n",
      "current index: 2, n_retry: 0, text: Das <aspect-term aspect=\"FOOD\" polarity=\"NEUTRAL\">Essen</aspect-term> war ziemlich gut. (Nur ein Aspekt adressiert)\n",
      "current index: 2, n_retry: 1, text: Das Essen war ok.\n",
      "current index: 2, n_retry: 2, text: Die <aspect-term aspect=\"FOOD\" polarity=\"NEUTRAL\">Speisen</aspect-term> waren gut, aber nicht mit Leib und Seele.\n",
      "current index: 3, n_retry: 0, text: Hat mir keinerlei Einfluss auf meinen Besuch gemacht.\n",
      "current index: 4, n_retry: 0, text: <aspect-term aspect=\"AMBIENCE\" polarity=\"POSITIVE\">Interior Design</aspect-term>, das als Filmkulisse für eine Geschischte dienen könnte, die in den goldenen 1920er Jahren spielt. Wir würden wiederkommen.\n",
      "current index: 4, n_retry: 1, text: Eine beeindruckende <aspect-term aspect=\"AMBIENCE\" polarity=\"POSITIVE\">Architektur</aspect-term> und ein <aspect-term aspect=\"AMBIENCE\" polarity=\"POSITIVE\">Interior Design</aspect-term>, das als Filmkulisse für eine Geschischte dienen könnte, die in den goldenen 1920er Jahren spielt.\n",
      "current index: 4, n_retry: 2, text: Das Ambiente ist <aspect-term aspect=\"AMBIENCE\" polarity=\"POSITIVE\">schön</aspect-term>, aber die General-Impression <aspect-term aspect=\"GENERAL-IMPRESSION\" polarity=\"NEUTRAL\">neutral</aspect-term>.\n"
     ]
    }
   ],
   "source": [
    "for idx, label in enumerate(labels[:5]):\n",
    "    # Setup Statistics\n",
    "    invalid_xml_schema = 0\n",
    "    invalid_xml_tags = 0\n",
    "    aspect_polarity_in_text_but_not_in_label = 0\n",
    "    more_than_one_sentences = 0\n",
    "    no_german_language = 0\n",
    "\n",
    "    # Setup JSON for new synth example\n",
    "    synth_example = {}\n",
    "    synth_example[\"llm_retry_statistic\"] = []\n",
    "\n",
    "    found_valid_example = False\n",
    "\n",
    "    # Alle 25 Beispielsets sollen 25 mal versucht werden\n",
    "    for new_example_idx in range(len(examples[str(idx)])):\n",
    "        for retry in range(N_RETRIES):\n",
    "            # new_example_idx will change in case it wasn't possible to generate a text for a given label after N_MAX_NEW_EXAMPLES retires\n",
    "            few_shot_examples = examples[str(idx)][f\"{new_example_idx}\"]\n",
    "            few_shot_examples = [\n",
    "                entry for entry in dataset if entry['id'] in few_shot_examples]\n",
    "\n",
    "            # Build Prompt\n",
    "            examples_text = get_examples_as_text(few_shot_examples)\n",
    "            prompt_footer = f'\\nLabel:{str(label)}\\nPrediction:'\n",
    "            prompt = PROMPT_TEMPLATE + examples_text + prompt_footer\n",
    "\n",
    "            # Execute LLM\n",
    "            prediction = llm_model(prompt)\n",
    "            \n",
    "            if is_valid_xml(f'<input>{prediction}</input>') == False:\n",
    "                invalid_xml_schema += 1\n",
    "            else:\n",
    "                if check_valid_aspect_xml(f'<input>{prediction}</input>') == False:\n",
    "                    invalid_xml_tags += 1\n",
    "                else:\n",
    "                    prediction_as_json = xml_to_json(\n",
    "                        prediction, label, MODEL_NAME, SPLIT)\n",
    "                    if prediction_as_json == \"not-in-label\":\n",
    "                        aspect_polarity_in_text_but_not_in_label += 1\n",
    "                    else:\n",
    "                        if count_sentences_in_text(prediction_as_json[\"text\"]) > 1:\n",
    "                            more_than_one_sentences += 1\n",
    "                        else:\n",
    "                            if german_language_detected(prediction_as_json[\"text\"]) == False:\n",
    "                                no_german_language += 1\n",
    "                            else:\n",
    "                                synth_example[\"id\"] = str(uuid.uuid4())\n",
    "                                synth_example[\"llm_label\"] = label\n",
    "                                synth_example[\"llm_examples\"] = few_shot_examples\n",
    "                                synth_example[\"llm_prompt\"] = prompt\n",
    "                                synth_example[\"llm_prediction_raw\"] = prediction\n",
    "                                synth_example[\"llm_invalid_xml_schema\"] = invalid_xml_schema\n",
    "                                synth_example[\"llm_invalid_xml_tags\"] = invalid_xml_tags\n",
    "                                synth_example[\"llm_aspect_polarity_in_text_but_not_in_label\"] = aspect_polarity_in_text_but_not_in_label\n",
    "                                synth_example[\"llm_more_than_one_sentences\"] = more_than_one_sentences\n",
    "                                synth_example[\"llm_no_german_language\"] = no_german_language\n",
    "                                for key in prediction_as_json.keys():\n",
    "                                    synth_example[key] = prediction_as_json[key]\n",
    "\n",
    "                                found_valid_example = True\n",
    "            \n",
    "            # Log current generation\n",
    "            print(f'current index: {idx}, n_retry: {len(synth_example[\"llm_retry_statistic\"])}, text: {prediction}')\n",
    "\n",
    "            if found_valid_example:\n",
    "                break\n",
    "            else:\n",
    "                # Save Statistics of retries\n",
    "                retry_statistic = {}\n",
    "                retry_statistic[\"llm_label\"] = label\n",
    "                retry_statistic[\"llm_examples\"] = [example[\"id\"] for example in few_shot_examples]\n",
    "                retry_statistic[\"llm_prompt\"] = prompt\n",
    "                retry_statistic[\"llm_prediction_raw\"] = prediction\n",
    "                retry_statistic[\"llm_invalid_xml_schema\"] = invalid_xml_schema\n",
    "                retry_statistic[\"llm_invalid_xml_tags\"] = invalid_xml_tags\n",
    "                retry_statistic[\"llm_aspect_polarity_in_text_but_not_in_label\"] = aspect_polarity_in_text_but_not_in_label\n",
    "                retry_statistic[\"llm_more_than_one_sentences\"] = more_than_one_sentences\n",
    "                retry_statistic[\"llm_no_german_language\"] = no_german_language\n",
    "                retry_statistic[\"llm_change_examples\"] = new_example_idx\n",
    "                retry_statistic[\"llm_retries_for_example_set\"] = retry\n",
    "                synth_example[\"llm_retry_statistic\"].append(retry_statistic)\n",
    "\n",
    "        if found_valid_example:\n",
    "            synth_dataset.append(synth_example)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "a23b811e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Hat mir keinerlei Einfluss auf meinen Besuch gemacht.',\n",
       " [{'text': None,\n",
       "   'start': 0,\n",
       "   'end': 0,\n",
       "   'tag_with_polarity': 'AMBIENCE-NEUTRAL',\n",
       "   'tag_with_polarity_and_type': 'AMBIENCE-NEUTRAL-implicit',\n",
       "   'type': 'label-implicit',\n",
       "   'label': 'AMBIENCE',\n",
       "   'polarity': 'NEUTRAL'},\n",
       "  {'text': None,\n",
       "   'start': 0,\n",
       "   'end': 0,\n",
       "   'tag_with_polarity': 'SERVICE-NEUTRAL',\n",
       "   'tag_with_polarity_and_type': 'SERVICE-NEUTRAL-implicit',\n",
       "   'type': 'label-implicit',\n",
       "   'label': 'SERVICE',\n",
       "   'polarity': 'NEUTRAL'}])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synth_dataset[3][\"text\"], synth_dataset[3][\"tags\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "d85cd6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.dirname(SYNTH_PATH), exist_ok=True)\n",
    "with open(SYNTH_PATH, \"w\") as outfile:\n",
    "    json.dump(synth_dataset, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "675df30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bitte erzeuge genau einen Satz einer Restaurant-Bewertung, die für das Training eines Modells für die Aspekt-basierte Sentiment Analyse verwendet werden kann.\n",
      "Gegeben ist ein Label in Form eines Arrays, wobei für jedes Sentiment, mit dem eine Aspekt-Kategorie im Satz adressiert wird, ein Tuple (Aspekt-Kategorie, Aspekt-Sentiment) vorhanden ist.\n",
      "Eine Aspekt-Kategorie kann mehrfach im Satz adressiert werden, auch mit verschiedenen Sentiment-Polaritäten.\n",
      "\n",
      "* Folgende Aspekt-Kategorien werden betrachtet: [\"GENERAL-IMPRESSION\", \"FOOD\", \"SERVICE\", \"PRICE\", \"AMBIENCE\"]\n",
      "* Folgende Sentiment-Polaritäten werden betrachtet: [\"negative\", \"neutral\", \"positive\"]\n",
      "\n",
      "Auf Basis des Labels soll genau ein deutscher Satz erzeugt werden, der die in den Tuple definierten Aspekte adressiert.\n",
      "Zusätzlich kann für ein im Label vorgegebenes Tuple (Aspekt-Kategorie, Aspekt-Sentiment) ein Aspekt-Begriff im Text vorliegen.\n",
      "Ein Aspekt-Begriff ist eine  Entität oder Eigenschaft innerhalb eines Textes, die auf eine der betrachteten Aspekt-Kategorien hinweist und deren Sentiment bewertet.\n",
      "Ein im Tuple vorgegebener Aspekt kann im Text auch implizit adressiert werden, wobei für einen solchen Aspekt kein Aspekt-Begriff im Text markiert werden soll.\n",
      "Ein Aspekt-Begriff soll immer mit einem xml-Tag markiert werden.\n",
      "\n",
      "Gebe nur die Prediction zurück, ohne Kommentare oder zusätzlichen Text.\n",
      "\n",
      "Label:[('FOOD', 'POSITIVE'), ('AMBIENCE', 'POSITIVE'), ('AMBIENCE', 'POSITIVE')]\n",
      "Prediction:LOC, eine beeindruckende <aspect-term aspect=\"FOOD\" polarity=\"POSITIVE\">Kuchen</aspect-term>- und <aspect-term aspect=\"AMBIENCE\" polarity=\"POSITIVE\">Tortenauswahl</aspect-term> und ein <aspect-term aspect=\"AMBIENCE\" polarity=\"POSITIVE\">Interior Design</aspect-term>, das als Filmkulisse für eine Geschischte dienen könnte, die in den goldenen 1920er Jahren spielt.\n",
      "Label:[('FOOD', 'POSITIVE'), ('AMBIENCE', 'POSITIVE'), ('AMBIENCE', 'POSITIVE')]\n",
      "Prediction:LOC, eine beeindruckende <aspect-term aspect=\"FOOD\" polarity=\"POSITIVE\">Kuchen</aspect-term>- und <aspect-term aspect=\"AMBIENCE\" polarity=\"POSITIVE\">Tortenauswahl</aspect-term> und ein <aspect-term aspect=\"AMBIENCE\" polarity=\"POSITIVE\">Interior Design</aspect-term>, das als Filmkulisse für eine Geschischte dienen könnte, die in den goldenen 1920er Jahren spielt.\n",
      "Label:[('GENERAL-IMPRESSION', 'POSITIVE')]\n",
      "Prediction:Wir würden wiederkommen.\n",
      "Label:[('SERVICE', 'NEGATIVE')]\n",
      "Prediction:Niemand hatte den Tisch im Blick, keiner fühlte sich zuständig.\n",
      "Label:[('SERVICE', 'POSITIVE')]\n",
      "Prediction:War zwar viel los, dennoch hat das <aspect-term aspect=\"SERVICE\" polarity=\"POSITIVE\">Personal</aspect-term> nicht an Höflichkeit und Spaß verloren.\n",
      "Label:[('GENERAL-IMPRESSION', 'NEGATIVE')]\n",
      "Prediction:Wir sind maximal enttäuscht und werden uns überlegen, ob wir wirklich nochmal hingehen.\n",
      "Label:[('PRICE', 'NEGATIVE')]\n",
      "Prediction:Für mich war das leider rausgeworfenes <aspect-term aspect=\"PRICE\" polarity=\"NEGATIVE\">Geld</aspect-term>.\n",
      "Label:[('FOOD', 'POSITIVE')]\n",
      "Prediction:Das <aspect-term aspect=\"FOOD\" polarity=\"POSITIVE\">Essen</aspect-term> war super.\n",
      "Label:[('FOOD', 'POSITIVE')]\n",
      "Prediction:Das <aspect-term aspect=\"FOOD\" polarity=\"POSITIVE\">Essen</aspect-term> war super.\n",
      "Label:[('PRICE', 'NEGATIVE')]\n",
      "Prediction:Für mich war das leider rausgeworfenes <aspect-term aspect=\"PRICE\" polarity=\"NEGATIVE\">Geld</aspect-term>\n",
      "Label:[('PRICE', 'POSITIVE'), ('GENERAL-IMPRESSION', 'NEGATIVE')]\n",
      "Prediction:\n"
     ]
    }
   ],
   "source": [
    "print(synth_dataset[0][\"llm_prompt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fe9fea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
