{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook: Analyse LLM Synthesis Retries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LLMS = [\"Llama2_70B\", \"Llama3_70B\", \"GPT-3\"] # \"Llama70B\", \"GPT-3\"\n",
    "FEW_SHOT_CONDITIONS = [\"fixed\", \"random\"] # \"fixed\", \"random\"\n",
    "N_SPLITS = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_statistics = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qy/5gtwsk6s7jgbknbqgb533x9w0000gn/T/ipykernel_31228/208319655.py:22: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  language_statistics[llm][condition][\"n_retries\"] += np.sum(len(example[\"llm_retry_statistic\"]) for example in synth_data_split)\n"
     ]
    }
   ],
   "source": [
    "for llm in LLMS:\n",
    "    language_statistics[llm] = {}\n",
    "    for condition in FEW_SHOT_CONDITIONS:\n",
    "        language_statistics[llm][condition] = {\n",
    "            \"n_examples\": 0,\n",
    "            \"n_retries\": 0,\n",
    "            \"more_than_25_retries\": 0,\n",
    "            \"invalid_xml_schema\": 0,\n",
    "            \"invalid_xml_tags\": 0,\n",
    "            \"aspect_polarity_in_text_but_not_in_label\": 0,\n",
    "            \"more_than_one_sentences\": 0,\n",
    "            \"empty_aspect_term\": 0,\n",
    "            \"invalid_single_word_aspect_term_pos_tag\": 0,\n",
    "            \"no_token_in_sentence\": 0,\n",
    "        }\n",
    "\n",
    "        for split in range(N_SPLITS):\n",
    "            with open(f\"../07 train models/synth/{llm}/{condition}/split_{split}.json\", 'r') as file:\n",
    "                synth_data_split = json.load(file)\n",
    "\n",
    "            language_statistics[llm][condition][\"n_examples\"] += len(synth_data_split)\n",
    "            language_statistics[llm][condition][\"n_retries\"] += np.sum(len(example[\"llm_retry_statistic\"]) for example in synth_data_split)\n",
    "            language_statistics[llm][condition][\"more_than_25_retries\"] += len([ex for ex in (len(example[\"llm_retry_statistic\"]) for example in synth_data_split) if ex > 25])\n",
    "            language_statistics[llm][condition][\"invalid_xml_schema\"] += sum(example[\"llm_invalid_xml_schema\"] for example in synth_data_split)\n",
    "            language_statistics[llm][condition][\"invalid_xml_tags\"] += sum(example[\"llm_invalid_xml_tags\"] for example in synth_data_split)\n",
    "            language_statistics[llm][condition][\"aspect_polarity_in_text_but_not_in_label\"] += sum(example[\"llm_aspect_polarity_in_text_but_not_in_label\"] for example in synth_data_split)\n",
    "            language_statistics[llm][condition][\"more_than_one_sentences\"] += sum(example[\"llm_more_than_one_sentences\"] for example in synth_data_split)\n",
    "            language_statistics[llm][condition][\"empty_aspect_term\"] += sum(example[\"llm_empty_aspect_term\"] for example in synth_data_split)\n",
    "            language_statistics[llm][condition][\"invalid_single_word_aspect_term_pos_tag\"] += sum(example[\"llm_invalid_single_word_aspect_term_pos_tag\"] for example in synth_data_split)\n",
    "            language_statistics[llm][condition][\"no_token_in_sentence\"] += sum(example[\"llm_no_token_in_sentence\"] for example in synth_data_split)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Llama2_70B': {'fixed': {'n_examples': 11850,\n",
       "   'n_retries': 1355,\n",
       "   'more_than_25_retries': 0,\n",
       "   'invalid_xml_schema': 6,\n",
       "   'invalid_xml_tags': 11,\n",
       "   'aspect_polarity_in_text_but_not_in_label': 1107,\n",
       "   'more_than_one_sentences': 173,\n",
       "   'empty_aspect_term': 1,\n",
       "   'invalid_single_word_aspect_term_pos_tag': 127,\n",
       "   'no_token_in_sentence': 0},\n",
       "  'random': {'n_examples': 9000,\n",
       "   'n_retries': 1131,\n",
       "   'more_than_25_retries': 0,\n",
       "   'invalid_xml_schema': 3,\n",
       "   'invalid_xml_tags': 2,\n",
       "   'aspect_polarity_in_text_but_not_in_label': 965,\n",
       "   'more_than_one_sentences': 117,\n",
       "   'empty_aspect_term': 3,\n",
       "   'invalid_single_word_aspect_term_pos_tag': 108,\n",
       "   'no_token_in_sentence': 0}},\n",
       " 'Llama3_70B': {'fixed': {'n_examples': 11850,\n",
       "   'n_retries': 12656,\n",
       "   'more_than_25_retries': 92,\n",
       "   'invalid_xml_schema': 25,\n",
       "   'invalid_xml_tags': 23,\n",
       "   'aspect_polarity_in_text_but_not_in_label': 1147,\n",
       "   'more_than_one_sentences': 12059,\n",
       "   'empty_aspect_term': 1,\n",
       "   'invalid_single_word_aspect_term_pos_tag': 997,\n",
       "   'no_token_in_sentence': 0},\n",
       "  'random': {'n_examples': 9000,\n",
       "   'n_retries': 4411,\n",
       "   'more_than_25_retries': 19,\n",
       "   'invalid_xml_schema': 27,\n",
       "   'invalid_xml_tags': 14,\n",
       "   'aspect_polarity_in_text_but_not_in_label': 877,\n",
       "   'more_than_one_sentences': 3706,\n",
       "   'empty_aspect_term': 0,\n",
       "   'invalid_single_word_aspect_term_pos_tag': 359,\n",
       "   'no_token_in_sentence': 0}},\n",
       " 'GPT-3': {'fixed': {'n_examples': 11850,\n",
       "   'n_retries': 901,\n",
       "   'more_than_25_retries': 9,\n",
       "   'invalid_xml_schema': 1,\n",
       "   'invalid_xml_tags': 0,\n",
       "   'aspect_polarity_in_text_but_not_in_label': 93,\n",
       "   'more_than_one_sentences': 674,\n",
       "   'empty_aspect_term': 0,\n",
       "   'invalid_single_word_aspect_term_pos_tag': 179,\n",
       "   'no_token_in_sentence': 0},\n",
       "  'random': {'n_examples': 9000,\n",
       "   'n_retries': 258,\n",
       "   'more_than_25_retries': 0,\n",
       "   'invalid_xml_schema': 4,\n",
       "   'invalid_xml_tags': 0,\n",
       "   'aspect_polarity_in_text_but_not_in_label': 31,\n",
       "   'more_than_one_sentences': 143,\n",
       "   'empty_aspect_term': 0,\n",
       "   'invalid_single_word_aspect_term_pos_tag': 86,\n",
       "   'no_token_in_sentence': 0}}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_seconds_to_time(seconds):\n",
    "    hours, remainder = divmod(seconds, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    \n",
    "    time_string = \"{:02}:{:02}:{:.4f}\".format(int(hours), int(minutes), seconds)\n",
    "    return time_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_statistics = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13205\n",
      "10131\n",
      "24506\n",
      "13411\n",
      "12751\n",
      "9258\n"
     ]
    }
   ],
   "source": [
    "for llm in LLMS:\n",
    "    duration_statistics[llm] = {}\n",
    "    for condition in FEW_SHOT_CONDITIONS:\n",
    "        duration_statistics[llm][condition] = {}\n",
    "        duration_statistics[llm][condition][\"time_no_retries\"] = []\n",
    "        duration_statistics[llm][condition][\"time_with_retries\"] = []\n",
    "        duration_statistics[llm][condition][\"avg_gen_time_no_retries\"] = []\n",
    "        duration_statistics[llm][condition][\"avg_gen_time_with_retries\"] = []\n",
    "        for split in range(N_SPLITS):\n",
    "            with open(f\"../07 train models/synth/{llm}/{condition}/split_{split}.json\", 'r') as file:\n",
    "                synth_data_split = json.load(file)\n",
    "            duration_statistics[llm][condition][\"time_no_retries\"] += [example[\"llm_prediction_duration\"] for example in synth_data_split]\n",
    "            duration_statistics[llm][condition][\"time_with_retries\"] += [example[\"llm_prediction_duration\"] for example in synth_data_split]\n",
    "            duration_statistics[llm][condition][\"time_with_retries\"] += [example[\"llm_prediction_duration\"] for main_example in synth_data_split for example in main_example[\"llm_retry_statistic\"]]\n",
    "  \n",
    "\n",
    "        print(len(duration_statistics[llm][condition][\"time_with_retries\"]))\n",
    "        duration_statistics[llm][condition][\"avg_gen_time_no_retries\"] = convert_seconds_to_time(np.mean(duration_statistics[llm][condition][\"time_no_retries\"]))\n",
    "        duration_statistics[llm][condition][\"avg_gen_time_with_retries\"] = convert_seconds_to_time(np.mean(duration_statistics[llm][condition][\"time_with_retries\"]))\n",
    "        duration_statistics[llm][condition][\"time_no_retries\"] = convert_seconds_to_time(np.sum(duration_statistics[llm][condition][\"time_no_retries\"]))\n",
    "        duration_statistics[llm][condition][\"time_with_retries\"] = convert_seconds_to_time(np.sum(duration_statistics[llm][condition][\"time_with_retries\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Llama2_70B': {'fixed': {'time_no_retries': '196:46:55.6779',\n",
       "   'time_with_retries': '222:28:6.0857',\n",
       "   'avg_gen_time_no_retries': '00:00:59.7819',\n",
       "   'avg_gen_time_with_retries': '00:01:0.6502'},\n",
       "  'random': {'time_no_retries': '143:06:27.2072',\n",
       "   'time_with_retries': '164:14:50.4334',\n",
       "   'avg_gen_time_no_retries': '00:00:57.2430',\n",
       "   'avg_gen_time_with_retries': '00:00:58.3645'}},\n",
       " 'Llama3_70B': {'fixed': {'time_no_retries': '73:52:55.0598',\n",
       "   'time_with_retries': '230:40:55.8351',\n",
       "   'avg_gen_time_no_retries': '00:00:22.4452',\n",
       "   'avg_gen_time_with_retries': '00:00:33.8879'},\n",
       "  'random': {'time_no_retries': '51:41:47.5828',\n",
       "   'time_with_retries': '98:30:40.1811',\n",
       "   'avg_gen_time_no_retries': '00:00:20.6786',\n",
       "   'avg_gen_time_with_retries': '00:00:26.4440'}},\n",
       " 'GPT-3': {'fixed': {'time_no_retries': '03:48:36.3313',\n",
       "   'time_with_retries': '04:17:41.3398',\n",
       "   'avg_gen_time_no_retries': '00:00:1.1575',\n",
       "   'avg_gen_time_with_retries': '00:00:1.2126'},\n",
       "  'random': {'time_no_retries': '02:41:13.0422',\n",
       "   'time_with_retries': '02:49:6.3992',\n",
       "   'avg_gen_time_no_retries': '00:00:1.0748',\n",
       "   'avg_gen_time_with_retries': '00:00:1.0960'}}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duration_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_duration(time_str):\n",
    "    hours, minutes, seconds, milliseconds = map(float, time_str.replace('.', ':').split(':'))\n",
    "    days = (hours - (hours % 24)) / 24\n",
    "    hours = hours % 24\n",
    "    total_seconds = (hours * 60 * 60) + (minutes * 60) + seconds\n",
    "    formatted_time = \"\"\n",
    "\n",
    "    if days:\n",
    "        formatted_time += f\"{int(days)} d, \"\n",
    "    if hours:\n",
    "        formatted_time += f\"{int(hours)} h, \"\n",
    "    if minutes:\n",
    "        formatted_time += f\"{int(minutes)} m, \"\n",
    "    if seconds:\n",
    "        formatted_time += f\"{int(seconds)} s, \"\n",
    "    if milliseconds:\n",
    "        formatted_time += f\"{int(milliseconds)} ms\"\n",
    "\n",
    "    return formatted_time.strip()\n",
    "\n",
    "\n",
    "def format_dictionary_duration(dictionary):\n",
    "    for model, model_data in dictionary.items():\n",
    "        for mode, mode_data in model_data.items():\n",
    "            for key, value in mode_data.items():\n",
    "                mode_data[key] = format_duration(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_dictionary_duration(duration_statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Llama2_70B': {'fixed': {'time_no_retries': '8 d, 4 h, 46 m, 55 s, 6779 ms',\n",
       "   'time_with_retries': '9 d, 6 h, 28 m, 6 s, 857 ms',\n",
       "   'avg_gen_time_no_retries': '59 s, 7819 ms',\n",
       "   'avg_gen_time_with_retries': '1 m, 6502 ms'},\n",
       "  'random': {'time_no_retries': '5 d, 23 h, 6 m, 27 s, 2072 ms',\n",
       "   'time_with_retries': '6 d, 20 h, 14 m, 50 s, 4334 ms',\n",
       "   'avg_gen_time_no_retries': '57 s, 2430 ms',\n",
       "   'avg_gen_time_with_retries': '58 s, 3645 ms'}},\n",
       " 'Llama3_70B': {'fixed': {'time_no_retries': '3 d, 1 h, 52 m, 55 s, 598 ms',\n",
       "   'time_with_retries': '9 d, 14 h, 40 m, 55 s, 8351 ms',\n",
       "   'avg_gen_time_no_retries': '22 s, 4452 ms',\n",
       "   'avg_gen_time_with_retries': '33 s, 8879 ms'},\n",
       "  'random': {'time_no_retries': '2 d, 3 h, 41 m, 47 s, 5828 ms',\n",
       "   'time_with_retries': '4 d, 2 h, 30 m, 40 s, 1811 ms',\n",
       "   'avg_gen_time_no_retries': '20 s, 6786 ms',\n",
       "   'avg_gen_time_with_retries': '26 s, 4440 ms'}},\n",
       " 'GPT-3': {'fixed': {'time_no_retries': '3 h, 48 m, 36 s, 3313 ms',\n",
       "   'time_with_retries': '4 h, 17 m, 41 s, 3398 ms',\n",
       "   'avg_gen_time_no_retries': '1 s, 1575 ms',\n",
       "   'avg_gen_time_with_retries': '1 s, 2126 ms'},\n",
       "  'random': {'time_no_retries': '2 h, 41 m, 13 s, 422 ms',\n",
       "   'time_with_retries': '2 h, 49 m, 6 s, 3992 ms',\n",
       "   'avg_gen_time_no_retries': '1 s, 748 ms',\n",
       "   'avg_gen_time_with_retries': '1 s, 960 ms'}}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duration_statistics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_m1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
