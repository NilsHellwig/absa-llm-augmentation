{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook: Analyse LLM Synthesis Retries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "LLMS = [\"Llama70B\", \"GPT-3\"] # \"Llama70B\", \"GPT-3\"\n",
    "FEW_SHOT_CONDITIONS = [\"fixed\", \"random\"] # \"fixed\", \"random\"\n",
    "N_SPLITS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_statistics = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qy/5gtwsk6s7jgbknbqgb533x9w0000gn/T/ipykernel_1913/208319655.py:22: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  language_statistics[llm][condition][\"n_retries\"] += np.sum(len(example[\"llm_retry_statistic\"]) for example in synth_data_split)\n"
     ]
    }
   ],
   "source": [
    "for llm in LLMS:\n",
    "    language_statistics[llm] = {}\n",
    "    for condition in FEW_SHOT_CONDITIONS:\n",
    "        language_statistics[llm][condition] = {\n",
    "            \"n_examples\": 0,\n",
    "            \"n_retries\": 0,\n",
    "            \"more_than_25_retries\": 0,\n",
    "            \"invalid_xml_schema\": 0,\n",
    "            \"invalid_xml_tags\": 0,\n",
    "            \"aspect_polarity_in_text_but_not_in_label\": 0,\n",
    "            \"more_than_one_sentences\": 0,\n",
    "            \"empty_aspect_term\": 0,\n",
    "            \"invalid_single_word_aspect_term_pos_tag\": 0,\n",
    "            \"no_token_in_sentence\": 0,\n",
    "        }\n",
    "\n",
    "        for split in range(N_SPLITS):\n",
    "            with open(f\"../07 train models/synth/{llm}/{condition}/split_{split}.json\", 'r') as file:\n",
    "                synth_data_split = json.load(file)\n",
    "\n",
    "            language_statistics[llm][condition][\"n_examples\"] += len(synth_data_split)\n",
    "            language_statistics[llm][condition][\"n_retries\"] += np.sum(len(example[\"llm_retry_statistic\"]) for example in synth_data_split)\n",
    "            language_statistics[llm][condition][\"more_than_25_retries\"] += len([ex for ex in (len(example[\"llm_retry_statistic\"]) for example in synth_data_split) if ex > 25])\n",
    "            language_statistics[llm][condition][\"invalid_xml_schema\"] += sum(example[\"llm_invalid_xml_schema\"] for example in synth_data_split)\n",
    "            language_statistics[llm][condition][\"invalid_xml_tags\"] += sum(example[\"llm_invalid_xml_tags\"] for example in synth_data_split)\n",
    "            language_statistics[llm][condition][\"aspect_polarity_in_text_but_not_in_label\"] += sum(example[\"llm_aspect_polarity_in_text_but_not_in_label\"] for example in synth_data_split)\n",
    "            language_statistics[llm][condition][\"more_than_one_sentences\"] += sum(example[\"llm_more_than_one_sentences\"] for example in synth_data_split)\n",
    "            language_statistics[llm][condition][\"empty_aspect_term\"] += sum(example[\"llm_empty_aspect_term\"] for example in synth_data_split)\n",
    "            language_statistics[llm][condition][\"invalid_single_word_aspect_term_pos_tag\"] += sum(example[\"llm_invalid_single_word_aspect_term_pos_tag\"] for example in synth_data_split)\n",
    "            language_statistics[llm][condition][\"no_token_in_sentence\"] += sum(example[\"llm_no_token_in_sentence\"] for example in synth_data_split)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Llama70B': {'fixed': {'n_examples': 9875,\n",
       "   'n_retries': 1176,\n",
       "   'more_than_25_retries': 0,\n",
       "   'invalid_xml_schema': 5,\n",
       "   'invalid_xml_tags': 11,\n",
       "   'aspect_polarity_in_text_but_not_in_label': 1001,\n",
       "   'more_than_one_sentences': 154,\n",
       "   'empty_aspect_term': 1,\n",
       "   'invalid_single_word_aspect_term_pos_tag': 63,\n",
       "   'no_token_in_sentence': 0},\n",
       "  'random': {'n_examples': 7500,\n",
       "   'n_retries': 906,\n",
       "   'more_than_25_retries': 0,\n",
       "   'invalid_xml_schema': 3,\n",
       "   'invalid_xml_tags': 1,\n",
       "   'aspect_polarity_in_text_but_not_in_label': 818,\n",
       "   'more_than_one_sentences': 85,\n",
       "   'empty_aspect_term': 2,\n",
       "   'invalid_single_word_aspect_term_pos_tag': 49,\n",
       "   'no_token_in_sentence': 0}},\n",
       " 'GPT-3': {'fixed': {'n_examples': 9875,\n",
       "   'n_retries': 810,\n",
       "   'more_than_25_retries': 9,\n",
       "   'invalid_xml_schema': 1,\n",
       "   'invalid_xml_tags': 0,\n",
       "   'aspect_polarity_in_text_but_not_in_label': 51,\n",
       "   'more_than_one_sentences': 644,\n",
       "   'empty_aspect_term': 0,\n",
       "   'invalid_single_word_aspect_term_pos_tag': 155,\n",
       "   'no_token_in_sentence': 0},\n",
       "  'random': {'n_examples': 7500,\n",
       "   'n_retries': 228,\n",
       "   'more_than_25_retries': 0,\n",
       "   'invalid_xml_schema': 4,\n",
       "   'invalid_xml_tags': 0,\n",
       "   'aspect_polarity_in_text_but_not_in_label': 23,\n",
       "   'more_than_one_sentences': 132,\n",
       "   'empty_aspect_term': 0,\n",
       "   'invalid_single_word_aspect_term_pos_tag': 75,\n",
       "   'no_token_in_sentence': 0}}}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_seconds_to_time(seconds):\n",
    "    hours, remainder = divmod(seconds, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    \n",
    "    time_string = \"{:02}:{:02}:{:.4f}\".format(int(hours), int(minutes), seconds)\n",
    "    return time_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_statistics = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11051\n",
      "8406\n",
      "10685\n",
      "7728\n"
     ]
    }
   ],
   "source": [
    "for llm in LLMS:\n",
    "    duration_statistics[llm] = {}\n",
    "    for condition in FEW_SHOT_CONDITIONS:\n",
    "        duration_statistics[llm][condition] = {}\n",
    "        duration_statistics[llm][condition][\"time_no_retries\"] = []\n",
    "        duration_statistics[llm][condition][\"time_with_retries\"] = []\n",
    "        duration_statistics[llm][condition][\"avg_gen_time_no_retries\"] = []\n",
    "        duration_statistics[llm][condition][\"avg_gen_time_with_retries\"] = []\n",
    "        for split in range(N_SPLITS):\n",
    "            with open(f\"../07 train models/synth/{llm}/{condition}/split_{split}.json\", 'r') as file:\n",
    "                synth_data_split = json.load(file)\n",
    "            duration_statistics[llm][condition][\"time_no_retries\"] += [example[\"llm_prediction_duration\"] for example in synth_data_split]\n",
    "            duration_statistics[llm][condition][\"time_with_retries\"] += [example[\"llm_prediction_duration\"] for example in synth_data_split]\n",
    "            duration_statistics[llm][condition][\"time_with_retries\"] += [example[\"llm_prediction_duration\"] for main_example in synth_data_split for example in main_example[\"llm_retry_statistic\"]]\n",
    "  \n",
    "\n",
    "        print(len(duration_statistics[llm][condition][\"time_with_retries\"]))\n",
    "        duration_statistics[llm][condition][\"avg_gen_time_no_retries\"] = convert_seconds_to_time(np.mean(duration_statistics[llm][condition][\"time_no_retries\"]))\n",
    "        duration_statistics[llm][condition][\"avg_gen_time_with_retries\"] = convert_seconds_to_time(np.mean(duration_statistics[llm][condition][\"time_with_retries\"]))\n",
    "        duration_statistics[llm][condition][\"time_no_retries\"] = convert_seconds_to_time(np.sum(duration_statistics[llm][condition][\"time_no_retries\"]))\n",
    "        duration_statistics[llm][condition][\"time_with_retries\"] = convert_seconds_to_time(np.sum(duration_statistics[llm][condition][\"time_with_retries\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Llama70B': {'fixed': {'time_no_retries': '166:30:37.4865',\n",
       "   'time_with_retries': '189:04:30.2025',\n",
       "   'avg_gen_time_no_retries': '00:01:0.7025',\n",
       "   'avg_gen_time_with_retries': '00:01:1.5935'},\n",
       "  'random': {'time_no_retries': '120:22:12.3716',\n",
       "   'time_with_retries': '137:42:16.8850',\n",
       "   'avg_gen_time_no_retries': '00:00:57.7776',\n",
       "   'avg_gen_time_with_retries': '00:00:58.9742'}},\n",
       " 'GPT-3': {'fixed': {'time_no_retries': '03:12:3.1241',\n",
       "   'time_with_retries': '03:38:25.7390',\n",
       "   'avg_gen_time_no_retries': '00:00:1.1669',\n",
       "   'avg_gen_time_with_retries': '00:00:1.2266'},\n",
       "  'random': {'time_no_retries': '02:14:19.3520',\n",
       "   'time_with_retries': '02:21:22.4018',\n",
       "   'avg_gen_time_no_retries': '00:00:1.0746',\n",
       "   'avg_gen_time_with_retries': '00:00:1.0976'}}}"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duration_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_duration(time_str):\n",
    "    hours, minutes, seconds, milliseconds = map(float, time_str.replace('.', ':').split(':'))\n",
    "    days = (hours - (hours % 24)) / 24\n",
    "    hours = hours % 24\n",
    "    total_seconds = (hours * 60 * 60) + (minutes * 60) + seconds\n",
    "    formatted_time = \"\"\n",
    "\n",
    "    if days:\n",
    "        formatted_time += f\"{int(days)}d \"\n",
    "    if hours:\n",
    "        formatted_time += f\"{int(hours)}h \"\n",
    "    if minutes:\n",
    "        formatted_time += f\"{int(minutes)}m \"\n",
    "    if seconds:\n",
    "        formatted_time += f\"{int(seconds)}s \"\n",
    "    if milliseconds:\n",
    "        formatted_time += f\"{int(milliseconds)}ms\"\n",
    "\n",
    "    return formatted_time.strip()\n",
    "\n",
    "\n",
    "def format_dictionary_duration(dictionary):\n",
    "    for model, model_data in dictionary.items():\n",
    "        for mode, mode_data in model_data.items():\n",
    "            for key, value in mode_data.items():\n",
    "                mode_data[key] = format_duration(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_dictionary_duration(duration_statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Llama70B': {'fixed': {'time_no_retries': '6d 22h 30m 37s 4865ms',\n",
       "   'time_with_retries': '7d 21h 4m 30s 2025ms',\n",
       "   'avg_gen_time_no_retries': '1m 7025ms',\n",
       "   'avg_gen_time_with_retries': '1m 1s 5935ms'},\n",
       "  'random': {'time_no_retries': '5d 22m 12s 3716ms',\n",
       "   'time_with_retries': '5d 17h 42m 16s 8850ms',\n",
       "   'avg_gen_time_no_retries': '57s 7776ms',\n",
       "   'avg_gen_time_with_retries': '58s 9742ms'}},\n",
       " 'GPT-3': {'fixed': {'time_no_retries': '3h 12m 3s 1241ms',\n",
       "   'time_with_retries': '3h 38m 25s 7390ms',\n",
       "   'avg_gen_time_no_retries': '1s 1669ms',\n",
       "   'avg_gen_time_with_retries': '1s 2266ms'},\n",
       "  'random': {'time_no_retries': '2h 14m 19s 3520ms',\n",
       "   'time_with_retries': '2h 21m 22s 4018ms',\n",
       "   'avg_gen_time_no_retries': '1s 746ms',\n",
       "   'avg_gen_time_with_retries': '1s 976ms'}}}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duration_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = []\n",
    "for split in range(N_SPLITS):\n",
    "    with open(f\"../07 train models/synth/GPT-3/fixed/split_{split}.json\", 'r') as file:\n",
    "        synth_data_split = json.load(file)\n",
    "        examples += synth_data_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('-->',\n",
       "  [['SERVICE', 'NEUTRAL'],\n",
       "   ['PRICE', 'NEGATIVE'],\n",
       "   ['GENERAL-IMPRESSION', 'POSITIVE']],\n",
       "  33,\n",
       "  33),\n",
       " ('-->',\n",
       "  [['SERVICE', 'NEUTRAL'],\n",
       "   ['PRICE', 'NEGATIVE'],\n",
       "   ['AMBIENCE', 'POSITIVE'],\n",
       "   ['GENERAL-IMPRESSION', 'POSITIVE'],\n",
       "   ['PRICE', 'NEUTRAL']],\n",
       "  34,\n",
       "  34),\n",
       " ('-->',\n",
       "  [['FOOD', 'POSITIVE'],\n",
       "   ['PRICE', 'NEGATIVE'],\n",
       "   ['FOOD', 'NEGATIVE'],\n",
       "   ['GENERAL-IMPRESSION', 'POSITIVE'],\n",
       "   ['GENERAL-IMPRESSION', 'NEGATIVE']],\n",
       "  27,\n",
       "  27),\n",
       " ('-->',\n",
       "  [['AMBIENCE', 'NEUTRAL'],\n",
       "   ['PRICE', 'NEGATIVE'],\n",
       "   ['AMBIENCE', 'POSITIVE'],\n",
       "   ['GENERAL-IMPRESSION', 'POSITIVE']],\n",
       "  50,\n",
       "  50),\n",
       " ('-->',\n",
       "  [['FOOD', 'NEUTRAL'],\n",
       "   ['FOOD', 'POSITIVE'],\n",
       "   ['GENERAL-IMPRESSION', 'NEUTRAL']],\n",
       "  50,\n",
       "  50),\n",
       " ('-->',\n",
       "  [['SERVICE', 'POSITIVE'],\n",
       "   ['FOOD', 'NEGATIVE'],\n",
       "   ['GENERAL-IMPRESSION', 'POSITIVE']],\n",
       "  32,\n",
       "  32),\n",
       " ('-->',\n",
       "  [['FOOD', 'POSITIVE'],\n",
       "   ['PRICE', 'NEGATIVE'],\n",
       "   ['GENERAL-IMPRESSION', 'POSITIVE'],\n",
       "   ['GENERAL-IMPRESSION', 'NEGATIVE']],\n",
       "  35,\n",
       "  35),\n",
       " ('-->',\n",
       "  [['AMBIENCE', 'NEGATIVE'],\n",
       "   ['FOOD', 'POSITIVE'],\n",
       "   ['PRICE', 'NEGATIVE'],\n",
       "   ['GENERAL-IMPRESSION', 'POSITIVE']],\n",
       "  129,\n",
       "  129),\n",
       " ('-->',\n",
       "  [['PRICE', 'NEGATIVE'],\n",
       "   ['SERVICE', 'POSITIVE'],\n",
       "   ['GENERAL-IMPRESSION', 'NEUTRAL'],\n",
       "   ['PRICE', 'POSITIVE'],\n",
       "   ['GENERAL-IMPRESSION', 'NEGATIVE'],\n",
       "   ['GENERAL-IMPRESSION', 'POSITIVE']],\n",
       "  27,\n",
       "  27)]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(\"-->\", example[\"llm_label\"], len(example[\"llm_retry_statistic\"]), example[\"llm_more_than_one_sentences\"]) for example in examples if len(example[\"llm_retry_statistic\"]) > 25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_m1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
