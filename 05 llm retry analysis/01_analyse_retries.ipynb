{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook: Analyse LLM Synthesis Retries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "LLMS = [\"Llama70B\", \"GPT-3\"] # \"Llama70B\", \"GPT-3\"\n",
    "FEW_SHOT_CONDITIONS = [\"fixed\", \"random\"] # \"fixed\", \"random\"\n",
    "N_SPLITS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_statistics = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qy/5gtwsk6s7jgbknbqgb533x9w0000gn/T/ipykernel_22344/694632481.py:20: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  language_statistics[llm][condition][\"n_retries\"] += np.sum(len(example[\"llm_retry_statistic\"]) for example in synth_data_split)\n"
     ]
    }
   ],
   "source": [
    "for llm in LLMS:\n",
    "    language_statistics[llm] = {}\n",
    "    for condition in FEW_SHOT_CONDITIONS:\n",
    "        language_statistics[llm][condition] = {\n",
    "            \"n_examples\": 0,\n",
    "            \"n_retries\": 0,\n",
    "            \"more_than_25_retries\": 0,\n",
    "            \"invalid_xml_schema\": 0,\n",
    "            \"invalid_xml_tags\": 0,\n",
    "            \"aspect_polarity_in_text_but_not_in_label\": 0,\n",
    "            \"more_than_one_sentences\": 0,\n",
    "            \"llm_empty_aspect_term\": 0\n",
    "        }\n",
    "\n",
    "        for split in range(N_SPLITS):\n",
    "            with open(f\"../07 train models/synth/{llm}/{condition}/split_{split}.json\", 'r') as file:\n",
    "                synth_data_split = json.load(file)\n",
    "\n",
    "            language_statistics[llm][condition][\"n_examples\"] += len(synth_data_split)\n",
    "            language_statistics[llm][condition][\"n_retries\"] += np.sum(len(example[\"llm_retry_statistic\"]) for example in synth_data_split)\n",
    "            language_statistics[llm][condition][\"more_than_25_retries\"] += len([ex for ex in (len(example[\"llm_retry_statistic\"]) for example in synth_data_split) if ex > 25])\n",
    "            language_statistics[llm][condition][\"invalid_xml_schema\"] += sum(example[\"llm_invalid_xml_schema\"] for example in synth_data_split)\n",
    "            language_statistics[llm][condition][\"invalid_xml_tags\"] += sum(example[\"llm_invalid_xml_tags\"] for example in synth_data_split)\n",
    "            language_statistics[llm][condition][\"aspect_polarity_in_text_but_not_in_label\"] += sum(example[\"llm_aspect_polarity_in_text_but_not_in_label\"] for example in synth_data_split)\n",
    "            language_statistics[llm][condition][\"more_than_one_sentences\"] += sum(example[\"llm_more_than_one_sentences\"] for example in synth_data_split)\n",
    "            language_statistics[llm][condition][\"empty_aspect_term\"] += sum(example[\"llm_llm_empty_aspect_term\"] for example in synth_data_split)\n",
    "            language_statistics[llm][condition][\"invalid_single_word_aspect_term_pos_tag\"] += sum(example[\"llm_invalid_single_word_aspect_term_pos_tag\"] for example in synth_data_split)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Llama70B': {'fixed': {'n_examples': 7500,\n",
       "   'n_retries': 985,\n",
       "   'more_than_25_retries': 5,\n",
       "   'invalid_xml_schema': 5,\n",
       "   'invalid_xml_tags': 0,\n",
       "   'aspect_polarity_in_text_but_not_in_label': 200,\n",
       "   'more_than_one_sentences': 670,\n",
       "   'no_german_language_total': 110},\n",
       "  'random': {'n_examples': 7500,\n",
       "   'n_retries': 985,\n",
       "   'more_than_25_retries': 5,\n",
       "   'invalid_xml_schema': 5,\n",
       "   'invalid_xml_tags': 0,\n",
       "   'aspect_polarity_in_text_but_not_in_label': 200,\n",
       "   'more_than_one_sentences': 670,\n",
       "   'no_german_language_total': 110}},\n",
       " 'GPT-3': {'fixed': {'n_examples': 7500,\n",
       "   'n_retries': 985,\n",
       "   'more_than_25_retries': 5,\n",
       "   'invalid_xml_schema': 5,\n",
       "   'invalid_xml_tags': 0,\n",
       "   'aspect_polarity_in_text_but_not_in_label': 200,\n",
       "   'more_than_one_sentences': 670,\n",
       "   'no_german_language_total': 110},\n",
       "  'random': {'n_examples': 7500,\n",
       "   'n_retries': 985,\n",
       "   'more_than_25_retries': 5,\n",
       "   'invalid_xml_schema': 5,\n",
       "   'invalid_xml_tags': 0,\n",
       "   'aspect_polarity_in_text_but_not_in_label': 200,\n",
       "   'more_than_one_sentences': 670,\n",
       "   'no_german_language_total': 110}}}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_seconds_to_time(seconds):\n",
    "    hours, remainder = divmod(seconds, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    \n",
    "    time_string = \"{:02}:{:02}:{:.2f}\".format(int(hours), int(minutes), seconds)\n",
    "    return time_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_statistics = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for llm in LLMS:\n",
    "    duration_statistics[llm] = {}\n",
    "    for condition in FEW_SHOT_CONDITIONS:\n",
    "        duration_statistics[llm][condition] = {}\n",
    "        duration_statistics[llm][condition][\"time_no_retries\"] = []\n",
    "        duration_statistics[llm][condition][\"time_with_retries\"] = []\n",
    "        duration_statistics[llm][condition][\"avg_gen_time_no_retries\"] = []\n",
    "        duration_statistics[llm][condition][\"avg_gen_time_with_retries\"] = []\n",
    "        for split in range(N_SPLITS):\n",
    "            with open(f\"../07 train models/synth/{llm}/{condition}/split_{split}.json\", 'r') as file:\n",
    "                synth_data_split = json.load(file)\n",
    "            duration_statistics[llm][condition][\"time_no_retries\"] += [example[\"llm_prediction_duration\"] for example in synth_data_split]\n",
    "            duration_statistics[llm][condition][\"time_with_retries\"] += [example[\"llm_prediction_duration\"] for example in synth_data_split]\n",
    "            duration_statistics[llm][condition][\"time_with_retries\"] += [example[\"llm_prediction_duration\"] for main_example in synth_data_split for example in main_example[\"llm_retry_statistic\"]]\n",
    "  \n",
    "\n",
    "        duration_statistics[llm][condition][\"avg_gen_time_no_retries\"] = convert_seconds_to_time(np.mean(duration_statistics[llm][condition][\"time_no_retries\"]))\n",
    "        duration_statistics[llm][condition][\"avg_gen_time_with_retries\"] = convert_seconds_to_time(np.mean(duration_statistics[llm][condition][\"time_with_retries\"]))\n",
    "        duration_statistics[llm][condition][\"time_no_retries\"] = convert_seconds_to_time(np.sum(duration_statistics[llm][condition][\"time_no_retries\"]))\n",
    "        duration_statistics[llm][condition][\"time_with_retries\"] = convert_seconds_to_time(np.sum(duration_statistics[llm][condition][\"time_with_retries\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Llama70B': {'fixed': {'time_no_retries': '01:03:20.73',\n",
       "   'time_with_retries': '01:03:20.73',\n",
       "   'avg_gen_time_no_retries': '00:00:0.51',\n",
       "   'avg_gen_time_with_retries': '00:00:0.51'},\n",
       "  'random': {'time_no_retries': '01:02:20.77',\n",
       "   'time_with_retries': '01:02:20.77',\n",
       "   'avg_gen_time_no_retries': '00:00:0.50',\n",
       "   'avg_gen_time_with_retries': '00:00:0.50'}},\n",
       " 'GPT-3': {'fixed': {'time_no_retries': '01:02:16.22',\n",
       "   'time_with_retries': '01:02:16.22',\n",
       "   'avg_gen_time_no_retries': '00:00:0.50',\n",
       "   'avg_gen_time_with_retries': '00:00:0.50'},\n",
       "  'random': {'time_no_retries': '01:02:30.06',\n",
       "   'time_with_retries': '01:02:30.06',\n",
       "   'avg_gen_time_no_retries': '00:00:0.50',\n",
       "   'avg_gen_time_with_retries': '00:00:0.50'}}}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duration_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_m1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
