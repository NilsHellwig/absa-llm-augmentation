{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook: Analyse Language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.de.stop_words import STOP_WORDS\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "import Levenshtein\n",
    "import numpy as np\n",
    "import string\n",
    "import spacy\n",
    "import nltk\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/nils_hellwig/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load(\"de_core_news_lg\")\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASPECT_CATEGORIES = [\"GENERAL-IMPRESSION\",\n",
    "                     \"FOOD\", \"SERVICE\", \"AMBIENCE\", \"PRICE\"]\n",
    "LLMS = [\"GPT-3\", \"Llama70B\"]\n",
    "FS_CONDITIONS = [\"fixed\", \"random\"]\n",
    "PROMPTING_ENCODING = {\"fixed\": \"25 fixed examples\",\n",
    "                      \"random\": \"25 random examples\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tokens(texts):\n",
    "    token_counts = [] \n",
    "    for text in texts:\n",
    "        tokens = word_tokenize(text)\n",
    "        token_counts.append(len(tokens))\n",
    "    return token_counts\n",
    "\n",
    "def count_unique_lemmas(texts):\n",
    "    unique_lemmas = set()\n",
    "    for text in texts:\n",
    "        doc = nlp(text)\n",
    "        for token in doc:\n",
    "            unique_lemmas.add(token.lemma_)\n",
    "    return len(unique_lemmas)\n",
    "\n",
    "def remove_stopwords_and_punctuation(text):\n",
    "    doc = nlp(text)\n",
    "    cleaned_tokens = [token.lemma_ for token in doc if token.text.lower() not in STOP_WORDS and token.text not in string.punctuation and token.text.isalpha()]\n",
    "    cleaned_text = ' '.join(cleaned_tokens)\n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "def count_top_n_lemmas(texts, n):\n",
    "    lemma_counts = {}\n",
    "    for text in texts:\n",
    "        cleaned_text = remove_stopwords_and_punctuation(text)\n",
    "        doc = nlp(cleaned_text)\n",
    "        for token in doc:\n",
    "            lemma = token.lemma_\n",
    "            if lemma in lemma_counts:\n",
    "                lemma_counts[lemma] += 1\n",
    "            else:\n",
    "                lemma_counts[lemma] = 1\n",
    "    \n",
    "    sorted_lemmas = sorted(lemma_counts, key=lambda lemma: lemma_counts[lemma], reverse=True)\n",
    "    top_n_lemmas = sorted_lemmas[:n]\n",
    "    \n",
    "    return ', '.join(top_n_lemmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {\"synth\": {}, \"real\": []}\n",
    "\n",
    "# Load Synth\n",
    "for llm in LLMS:\n",
    "    dataset[\"synth\"][llm] = {}\n",
    "    for prompting in FS_CONDITIONS:\n",
    "        dataset[\"synth\"][llm][prompting] = []\n",
    "        for split in range(5):\n",
    "            with open(f\"../07 train models/synth/{llm}/{prompting}/split_{split}.json\", 'r', encoding='utf-8') as json_file:\n",
    "                split_data = json.load(json_file)\n",
    "            dataset[\"synth\"][llm][prompting].append(split_data)\n",
    "\n",
    "# Load Real\n",
    "for split in range(5):\n",
    "    with open(f\"../07 train models/real/split_{split}.json\", 'r', encoding='utf-8') as json_file:\n",
    "        split_data = json.load(json_file)\n",
    "    dataset[\"real\"].append(split_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Avg Number of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "GPT-3 fixed 9.68\n",
      "GPT-3 fixed [9.24, 9.72, 9.1, 10.32, 10.01]\n",
      "-----\n",
      "GPT-3 random 9.04\n",
      "GPT-3 random [8.97, 9.11, 8.84, 8.87, 9.4]\n",
      "-----\n",
      "Llama70B fixed 10.31\n",
      "Llama70B fixed [9.53, 10.93, 9.98, 10.31, 10.78]\n",
      "-----\n",
      "Llama70B random 10.16\n",
      "Llama70B random [10.02, 10.21, 9.85, 10.17, 10.54]\n"
     ]
    }
   ],
   "source": [
    "for llm in LLMS:\n",
    "    for prompting in FS_CONDITIONS:\n",
    "        print(\"-----\")\n",
    "        print(llm, prompting, round(np.mean(count_tokens(\n",
    "            [example[\"text\"] for split_data in dataset[\"synth\"][llm][prompting] for example in split_data])), 2))\n",
    "        print(llm, prompting, [round(np.mean(count_tokens(\n",
    "            [example[\"text\"] for example in dataset[\"synth\"][llm][prompting][split_id]])), 2) for split_id in range(0, 5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real 13.1\n"
     ]
    }
   ],
   "source": [
    "print(\"Real\", round(np.mean(count_tokens([example[\"text\"] for split_examples in dataset[\"real\"] for example in split_examples])), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unique Aspect Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_word_statistics(texts):\n",
    "    word_statistics = Counter()\n",
    "\n",
    "    for text in texts:\n",
    "        words = word_tokenize(text, language='german')\n",
    "        word_statistics.update(words)\n",
    "\n",
    "    return dict(word_statistics)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_original = [example[\"text\"] for split_examples in dataset[\"real\"] for example in split_examples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_synth = [example[\"text\"] for example in dataset[\"synth\"][\"GPT-3\"][\"fixed\"][0]][:1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Durchschnittliche Levenshtein-Distanz (Wortebene) aller Paare: 16.37945386154462\n"
     ]
    }
   ],
   "source": [
    "def tokenize_document(text, nlp):\n",
    "    doc = nlp(text)\n",
    "    return [token.text for token in doc]\n",
    "\n",
    "def calculate_levenshtein_distance_word_level(tokens1, tokens2):\n",
    "    return Levenshtein.distance(tokens1, tokens2)\n",
    "\n",
    "def average_word_level_levenshtein_distance(texts, nlp):\n",
    "    tokenized_texts = [tokenize_document(text, nlp) for text in texts]\n",
    "\n",
    "    total_distance = 0\n",
    "    pair_count = 0\n",
    "\n",
    "    for i in range(len(tokenized_texts)):\n",
    "        for j in range(i + 1, len(tokenized_texts)):\n",
    "            tokens1 = tokenized_texts[i]\n",
    "            tokens2 = tokenized_texts[j]\n",
    "            \n",
    "            distance = calculate_levenshtein_distance_word_level(tokens1, tokens2)\n",
    "            total_distance += distance\n",
    "            pair_count += 1\n",
    "\n",
    "    average_distance = total_distance / pair_count if pair_count > 0 else 0\n",
    "    return average_distance\n",
    "\n",
    "result = average_word_level_levenshtein_distance(texts_original, nlp)\n",
    "print(f\"Durchschnittliche Levenshtein-Distanz (Wortebene) aller Paare: {result}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most frequent terms\n",
    "\n",
    "Ähnlich wie bei den realen Daten Aspekte, die das Aspekt selber benennen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-3\n",
      "\n",
      " 25 fixed examples & GENERAL-IMPRESSION & \\textit{Restaurant} (357), \\textit{Eindruck} (175), \\textit{Gesamteindruck} (62), \\textit{allgemeine Impression} (27), \\textit{Atmosphäre} (23) \\\\\n",
      "\n",
      " & FOOD & \\textit{Essen} (2026), \\textit{Speisen} (61), \\textit{Dessert} (59), \\textit{Gericht} (37), \\textit{Pizza} (29) \\\\\n",
      "\n",
      " & SERVICE & \\textit{Service} (2072), \\textit{Personal} (312), \\textit{Bedienung} (71), \\textit{Servicepersonal} (55), \\textit{Kellner} (16) \\\\\n",
      "\n",
      " & AMBIENCE & \\textit{Ambiente} (1394), \\textit{Atmosphäre} (509), \\textit{Restaurant} (270), \\textit{Musik} (73), \\textit{Einrichtung} (62) \\\\\n",
      "\n",
      " & PRICE & \\textit{Preise} (1502), \\textit{Preis} (163), \\textit{Preis-Leistungs-Verhältnis} (161), \\textit{Preis-Leistungsverhältnis} (91), \\textit{Preisniveau} (39) \\\\ \\hline\n",
      "\n",
      " 25 random examples & GENERAL-IMPRESSION & \\textit{Restaurant} (253), \\textit{Eindruck} (51), \\textit{Gesamteindruck} (15), \\textit{Service} (10), \\textit{allgemeine Impression} (9) \\\\\n",
      "\n",
      " & FOOD & \\textit{Essen} (1145), \\textit{Speisen} (70), \\textit{Pizza} (34), \\textit{Gericht} (16), \\textit{Steak} (14) \\\\\n",
      "\n",
      " & SERVICE & \\textit{Service} (1282), \\textit{Personal} (144), \\textit{Bedienung} (84), \\textit{Servicepersonal} (15), \\textit{Kellner} (5) \\\\\n",
      "\n",
      " & AMBIENCE & \\textit{Ambiente} (819), \\textit{Atmosphäre} (402), \\textit{Restaurant} (221), \\textit{Einrichtung} (66), \\textit{Musik} (26) \\\\\n",
      "\n",
      " & PRICE & \\textit{Preise} (627), \\textit{Preis-Leistungs-Verhältnis} (120), \\textit{Preis} (108), \\textit{Preis-Leistungsverhältnis} (76), \\textit{Preisniveau} (29) \\\\ \\hline\n",
      "Llama70B\n",
      "\n",
      " 25 fixed examples & GENERAL-IMPRESSION & \\textit{Lokal} (204), \\textit{Essen} (204), \\textit{Restaurant} (195), \\textit{Ambiente} (137), \\textit{Atmosphäre} (132) \\\\\n",
      "\n",
      " & FOOD & \\textit{Essen} (1305), \\textit{Pizza} (165), \\textit{Speisen} (137), \\textit{Küche} (64), \\textit{Gerichte} (51) \\\\\n",
      "\n",
      " & SERVICE & \\textit{Service} (709), \\textit{Personal} (668), \\textit{Bedienung} (635), \\textit{Servicepersonal} (97), \\textit{Kellner} (95) \\\\\n",
      "\n",
      " & AMBIENCE & \\textit{Ambiente} (1110), \\textit{Atmosphäre} (672), \\textit{Lokal} (50), \\textit{Lage} (45), \\textit{Essen} (30) \\\\\n",
      "\n",
      " & PRICE & \\textit{Preise} (754), \\textit{Preis} (404), \\textit{Preis-Leistungsverhältnis} (246), \\textit{Essen} (139), \\textit{Preis/Leistung} (104) \\\\ \\hline\n",
      "\n",
      " 25 random examples & GENERAL-IMPRESSION & \\textit{Restaurant} (153), \\textit{Essen} (151), \\textit{Atmosphäre} (70), \\textit{Ambiente} (62), \\textit{LOC} (46) \\\\\n",
      "\n",
      " & FOOD & \\textit{Essen} (811), \\textit{Speisen} (150), \\textit{Pizza} (109), \\textit{Küche} (55), \\textit{Gerichte} (38) \\\\\n",
      "\n",
      " & SERVICE & \\textit{Service} (588), \\textit{Bedienung} (399), \\textit{Personal} (288), \\textit{Servicepersonal} (69), \\textit{Essen} (59) \\\\\n",
      "\n",
      " & AMBIENCE & \\textit{Ambiente} (765), \\textit{Atmosphäre} (438), \\textit{Terrasse} (24), \\textit{Umgebung} (23), \\textit{Lage} (22) \\\\\n",
      "\n",
      " & PRICE & \\textit{Preise} (495), \\textit{Preis} (387), \\textit{Preis-Leistungsverhältnis} (122), \\textit{Essen} (108), \\textit{Preis/Leistungsverhältnis} (53) \\\\ \\hline\n"
     ]
    }
   ],
   "source": [
    "for llm in LLMS:\n",
    "    print(llm)\n",
    "    for prompting in FS_CONDITIONS:\n",
    "        for ac_idx, aspect_category in enumerate(ASPECT_CATEGORIES):\n",
    "            aspect_terms = []\n",
    "            for split_idx in range(5):\n",
    "                for example in dataset[\"synth\"][llm][prompting][split_idx]:\n",
    "                    aspect_terms += [tag[\"text\"] for tag in example[\"tags\"] if tag[\"type\"]\n",
    "                                     == \"label-explicit\" and tag[\"label\"] == aspect_category]\n",
    "            aspect_term_counts = Counter(aspect_terms)\n",
    "            most_common_aspect_terms = aspect_term_counts.most_common(5)\n",
    "\n",
    "            term_list = [\n",
    "                f\"\\\\textit{{{term}}} ({count})\" for term, count in most_common_aspect_terms]\n",
    "            term_string = \", \".join(term_list)\n",
    "\n",
    "            if ac_idx == 0:\n",
    "                print(\n",
    "                    f\"\\n {PROMPTING_ENCODING[prompting]} & {aspect_category} & {term_string} \\\\\\\\\")\n",
    "            elif ac_idx == 4:\n",
    "                print(\n",
    "                    f\"\\n & {aspect_category} & {term_string} \\\\\\\\ \\\\hline\")\n",
    "            else:\n",
    "                print(\n",
    "                    f\"\\n & {aspect_category} & {term_string} \\\\\\\\\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prozentualer Anteil an Aspektbegriffe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-3 fixed total: 0.6528686946476704 splits: [0.5901639344262295, 0.5418544752092723, 0.7245912151330555, 0.623593699774992, 0.7827751196172249] 0.08846750333202695 0.007826499145802199\n",
      "GPT-3 random total: 0.5666410601113885 splits: [0.5739503816793893, 0.5501460564751705, 0.5521085797382452, 0.6105577689243028, 0.5485636114911081] 0.02362742458662041 0.0005582551925964346\n",
      "Llama70B fixed total: 0.7271791572853007 splits: [0.754650416933932, 0.6447751536719508, 0.7412407585985213, 0.7285300739787713, 0.7660462130937099] 0.04302372886341045 0.0018510412453122578\n",
      "Llama70B random total: 0.7420745139354468 splits: [0.7538022813688213, 0.7445255474452555, 0.7443318861553304, 0.7428998505231689, 0.7257039055404177] 0.00913414563314946 8.343261644758334e-05\n"
     ]
    }
   ],
   "source": [
    "for llm in LLMS:\n",
    "    for prompting in FS_CONDITIONS:\n",
    "        aspect_terms_total = []\n",
    "        n_aspects_total = 0\n",
    "        ratio_splits = []\n",
    "        for split_idx in range(5):\n",
    "            aspect_terms_split = []\n",
    "            n_aspects_split = 0\n",
    "            for example in dataset[\"synth\"][llm][prompting][split_idx]:\n",
    "                aspect_terms = [tag[\"text\"] for tag in example[\"tags\"] if tag[\"type\"] == \"label-explicit\"]\n",
    "                n_aspects_example = len([tag for tag in example[\"tags\"]])\n",
    "\n",
    "                aspect_terms_split += aspect_terms\n",
    "                n_aspects_split += n_aspects_example\n",
    "\n",
    "        \n",
    "            aspect_terms_total += aspect_terms_split\n",
    "            n_aspects_total += n_aspects_split\n",
    "            ratio_splits.append(len(aspect_terms_split) / n_aspects_split)\n",
    "                \n",
    "        print(llm, prompting, \"total:\", len(aspect_terms_total) / n_aspects_total, \"splits:\", ratio_splits, np.std(ratio_splits), np.var(ratio_splits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_m1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
