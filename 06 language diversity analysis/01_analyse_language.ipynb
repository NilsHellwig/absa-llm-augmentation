{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook: Analyse Language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from spacy.lang.de.stop_words import STOP_WORDS\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "import Levenshtein\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "import spacy\n",
    "import nltk\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASPECT_CATEGORIES = [\"GENERAL-IMPRESSION\",\n",
    "                     \"FOOD\", \"SERVICE\", \"AMBIENCE\", \"PRICE\"]\n",
    "LLMS = [\"GPT-3\", \"Llama70B\"]\n",
    "FS_CONDITIONS = [\"fixed\", \"random\"]\n",
    "PROMPTING_ENCODING = {\"fixed\": \"25 fixed examples\",\n",
    "                      \"random\": \"25 random examples\"}\n",
    "N_FOLDS = 3\n",
    "CRITERIA_RS = \"tag_with_polarity\"\n",
    "POLARITIES = [\"POSITIVE\", \"NEGATIVE\", \"NEUTRAL\"]\n",
    "MENTIONING_TYPE = [\"implicit\", \"explicit\"]\n",
    "COMBINATIONS = [f\"{aspect}-{polarity}\" for aspect in [\"SERVICE\", \"FOOD\", \"GENERAL-IMPRESSION\", \"AMBIENCE\", \"PRICE\"] for polarity in POLARITIES]\n",
    "RANDOM_STATE = 43"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/nils_hellwig/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"de_core_news_lg\")\n",
    "nltk.download('punkt')\n",
    "random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tokens(texts):\n",
    "    token_counts = []\n",
    "    for text in texts:\n",
    "        tokens = word_tokenize(text)\n",
    "        token_counts.append(len(tokens))\n",
    "    return token_counts\n",
    "\n",
    "\n",
    "def count_unique_tokens(tokens):\n",
    "    unique_tokens = set(token.text for token in tokens)\n",
    "    return len(unique_tokens)\n",
    "\n",
    "\n",
    "def count_unique_lemmas(tokens):\n",
    "    unique_lemmas = set(token.lemma_ for token in tokens)\n",
    "    return len(unique_lemmas)\n",
    "\n",
    "\n",
    "def remove_stopwords_and_punctuation(text):\n",
    "    doc = nlp(text)\n",
    "    cleaned_tokens = [token.lemma_ for token in doc if token.text.lower(\n",
    "    ) not in STOP_WORDS and token.text not in string.punctuation and token.text.isalpha()]\n",
    "    cleaned_text = ' '.join(cleaned_tokens)\n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "def count_top_n_lemmas(texts, n):\n",
    "    lemma_counts = {}\n",
    "    for text in texts:\n",
    "        cleaned_text = remove_stopwords_and_punctuation(text)\n",
    "        doc = nlp(cleaned_text)\n",
    "        for token in doc:\n",
    "            lemma = token.lemma_\n",
    "            if lemma in lemma_counts:\n",
    "                lemma_counts[lemma] += 1\n",
    "            else:\n",
    "                lemma_counts[lemma] = 1\n",
    "\n",
    "    sorted_lemmas = sorted(\n",
    "        lemma_counts, key=lambda lemma: lemma_counts[lemma], reverse=True)\n",
    "    top_n_lemmas = sorted_lemmas[:n]\n",
    "\n",
    "    return ', '.join(top_n_lemmas)\n",
    "\n",
    "\n",
    "def get_avg_unique_words_in_k_words(tokens, n_selection=100, n_repetitions=100000):\n",
    "    lemmas = [token.text for token in tokens]\n",
    "    iterations_n_unique_lemmas = []\n",
    "    for i in range(n_repetitions):\n",
    "        random_indices = random.sample(range(len(lemmas)), n_selection)\n",
    "        random_lemmas = [lemmas[index] for index in random_indices]\n",
    "        n_unique_lemmas = len(set(random_lemmas))\n",
    "        iterations_n_unique_lemmas.append(n_unique_lemmas)\n",
    "    return np.mean(iterations_n_unique_lemmas)\n",
    "\n",
    "\n",
    "def average_word_level_levenshtein_distance(docs, norm=False):\n",
    "    tokenized_texts = [\n",
    "        [token.text for token in doc[\"tokenized_text\"]] for doc in docs]\n",
    "\n",
    "    total_distance = 0\n",
    "    pair_count = 0\n",
    "\n",
    "    for i in range(len(tokenized_texts)):\n",
    "        for j in range(i + 1, len(tokenized_texts)):\n",
    "            tokens1 = tokenized_texts[i]\n",
    "            tokens2 = tokenized_texts[j]\n",
    "\n",
    "            if len(tokens1) >= len(tokens2):\n",
    "                max_tokens = len(tokens1)\n",
    "            else:\n",
    "                max_tokens = len(tokens2)\n",
    "\n",
    "            distance = Levenshtein.distance(tokens1, tokens2)\n",
    "            if norm:\n",
    "                distance = distance / max_tokens\n",
    "            total_distance += distance\n",
    "            pair_count += 1\n",
    "\n",
    "    average_distance = total_distance / pair_count if pair_count > 0 else 0\n",
    "    return average_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {\"synth\": {}, \"real\": []}\n",
    "\n",
    "# Load Synth\n",
    "for llm in LLMS:\n",
    "    dataset[\"synth\"][llm] = {}\n",
    "    for prompting in FS_CONDITIONS:\n",
    "        dataset[\"synth\"][llm][prompting] = []\n",
    "        for split in range(5):\n",
    "            with open(f\"../07 train models/synth/{llm}/{prompting}/split_{split}.json\", 'r', encoding='utf-8') as json_file:\n",
    "                split_data = json.load(json_file)\n",
    "            for example in split_data:\n",
    "                example[\"tokenized_text\"] = nlp(example[\"text\"])\n",
    "            dataset[\"synth\"][llm][prompting].append(split_data)\n",
    "\n",
    "# Load Real\n",
    "for split in range(5):\n",
    "    with open(f\"../07 train models/real/split_{split}.json\", 'r', encoding='utf-8') as json_file:\n",
    "        split_data = json.load(json_file)\n",
    "    for example in split_data:\n",
    "        example[\"tokenized_text\"] = nlp(example[\"text\"])\n",
    "    dataset[\"real\"].append(split_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_hot(subset):\n",
    "    labels_one_hot = []\n",
    "    for i in range(len(subset)):\n",
    "        tags_in_example = list(set([tag[CRITERIA_RS] for tag in subset[i][\"tags\"]]))\n",
    "        one_hot_encoded_combination = np.array([1 if tag in tags_in_example else 0 for tag in COMBINATIONS])\n",
    "        labels_one_hot.append(one_hot_encoded_combination)\n",
    "    return labels_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-3 fixed 0\n",
      "GPT-3 fixed 1\n",
      "GPT-3 fixed 2\n",
      "GPT-3 fixed 3\n",
      "GPT-3 fixed 4\n",
      "GPT-3 random 0\n",
      "GPT-3 random 1\n",
      "GPT-3 random 2\n",
      "GPT-3 random 3\n",
      "GPT-3 random 4\n",
      "Llama70B fixed 0\n",
      "Llama70B fixed 1\n",
      "Llama70B fixed 2\n",
      "Llama70B fixed 3\n",
      "Llama70B fixed 4\n",
      "Llama70B random 0\n",
      "Llama70B random 1\n",
      "Llama70B random 2\n",
      "Llama70B random 3\n",
      "Llama70B random 4\n"
     ]
    }
   ],
   "source": [
    "for llm in LLMS:\n",
    "    for few_shot_condition in FS_CONDITIONS:\n",
    "        for iteration in range(5):\n",
    "            print(llm, few_shot_condition, iteration)\n",
    "            if few_shot_condition == \"random\":\n",
    "                subset = dataset[\"synth\"][llm][few_shot_condition][iteration]\n",
    "            else:\n",
    "                subset = dataset[\"synth\"][llm][few_shot_condition][iteration][475:]\n",
    "\n",
    "            found_5_split = False\n",
    "            restart_idx = 0\n",
    "            while found_5_split == False:\n",
    "                mskf = MultilabelStratifiedKFold(\n",
    "                    n_splits=N_FOLDS, shuffle=True, random_state=RANDOM_STATE+restart_idx)\n",
    "                section = []\n",
    "                for train_index, test_index in mskf.split(subset, get_one_hot(subset)):\n",
    "                    split_500 = [subset[i] for i in test_index]\n",
    "                    section.append(split_500)\n",
    "\n",
    "                if len(section[0]) == 500 and len(section[1]) == 500 and len(section[2]) == 500:\n",
    "                    found_5_split = True\n",
    "\n",
    "                restart_idx += 1\n",
    "\n",
    "            dataset[\"synth\"][llm][few_shot_condition][iteration] = section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_examples = []\n",
    "for i in [0, 1, 2, 3, 4]:\n",
    "    real_examples.append([])\n",
    "    for k in [0, 1, 2]:\n",
    "        if (i+k) < 5:\n",
    "            t = i+k\n",
    "        else:\n",
    "            t = i+k - 5\n",
    "        real_examples[i].append(dataset[\"real\"][t])\n",
    "dataset[\"real\"] = real_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-3 & fixed & 500 & 289.6 & 208.2 & 47.87 & 9.79 & 0.79\n",
      "GPT-3 & fixed & 1000 & 369.6 & 264.4 & 47.84 & 9.79 & 0.79\n",
      "GPT-3 & fixed & 1500 & 428.4 & 307.0 & 48.0 & 9.8 & 0.79\n",
      "\\hline\n",
      "GPT-3 & random & 500 & 295.4 & 217.0 & 48.11 & 8.81 & 0.77\n",
      "GPT-3 & random & 1000 & 389.4 & 281.2 & 48.32 & 8.84 & 0.77\n",
      "GPT-3 & random & 1500 & 456.6 & 328.4 & 48.28 & 8.85 & 0.77\n",
      "\\hline\n",
      "Llama70B & fixed & 500 & 694.4 & 536.6 & 59.18 & 11.08 & 0.85\n",
      "Llama70B & fixed & 1000 & 1023.8 & 787.0 & 59.69 & 11.09 & 0.85\n",
      "Llama70B & fixed & 1500 & 1269.2 & 973.0 & 59.62 & 11.06 & 0.85\n",
      "\\hline\n",
      "Llama70B & random & 500 & 751.8 & 580.2 & 61.61 & 11.06 & 0.86\n",
      "Llama70B & random & 1000 & 1103.0 & 846.8 & 61.35 & 11.04 & 0.86\n",
      "Llama70B & random & 1500 & 1380.4 & 1054.0 & 61.23 & 10.98 & 0.86\n",
      "\\hline\n"
     ]
    }
   ],
   "source": [
    "for llm in LLMS:\n",
    "    for few_shot_condition in FS_CONDITIONS:\n",
    "        for n_sample in [500, 1000, 1500]:\n",
    "            iterations_n_unique_tokens = []\n",
    "            iterations_n_lemmas = []\n",
    "            iterations_avg_unique_words_in_k_words = []\n",
    "            iterations_avg_levenshtein_distance = []\n",
    "            iterations_avg_levenshtein_distance_norm = []\n",
    "            for it in range(5):\n",
    "                samples = [item for k in range(\n",
    "                    int(n_sample / 500)) for item in dataset[\"synth\"][llm][few_shot_condition][it][k]]\n",
    "                n_unique_tokens = count_unique_tokens(\n",
    "                    [token for example in samples for token in example[\"tokenized_text\"]])\n",
    "                n_unique_lemmas = count_unique_lemmas(\n",
    "                    [token for example in samples for token in example[\"tokenized_text\"]])\n",
    "                n_unique_words_in_k_words = get_avg_unique_words_in_k_words(\n",
    "                    [token for example in samples for token in example[\"tokenized_text\"]])\n",
    "                avg_levenshtein_distance = average_word_level_levenshtein_distance(\n",
    "                    samples)\n",
    "                avg_levenshtein_distance_norm = average_word_level_levenshtein_distance(\n",
    "                    samples, norm=True)\n",
    "\n",
    "                iterations_n_unique_tokens.append(n_unique_tokens)\n",
    "                iterations_n_lemmas.append(n_unique_lemmas)\n",
    "                iterations_avg_unique_words_in_k_words.append(\n",
    "                    n_unique_words_in_k_words)\n",
    "                iterations_avg_levenshtein_distance.append(\n",
    "                    avg_levenshtein_distance)\n",
    "                iterations_avg_levenshtein_distance_norm.append(\n",
    "                    avg_levenshtein_distance_norm)\n",
    "\n",
    "            print(llm, \"&\", few_shot_condition, \"&\", n_sample, \"&\",\n",
    "                  round(np.mean(iterations_n_unique_tokens), 2), \"&\",\n",
    "                  round(np.mean(iterations_n_lemmas), 2), \"&\",\n",
    "                  round(np.mean(iterations_avg_unique_words_in_k_words), 2), \"&\",\n",
    "                  round(np.mean(iterations_avg_levenshtein_distance), 2), \"&\",\n",
    "                  round(np.mean(iterations_avg_levenshtein_distance_norm), 2))\n",
    "        print(\"\\\\hline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- & - & 500 & 1914.8 & 1492.8 & 78.19 & 16.37 & 0.93\n",
      "- & - & 1000 & 3054.6 & 2345.0 & 78.19 & 16.38 & 0.93\n",
      "- & - & 1500 & 3986.4 & 3032.0 & 78.2 & 16.38 & 0.93\n",
      "\\hline\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for n_sample in [500, 1000, 1500]:\n",
    "    iterations_n_unique_tokens = []\n",
    "    iterations_n_lemmas = []\n",
    "    iterations_avg_unique_words_in_k_words = []\n",
    "    iterations_avg_levenshtein_distance = []\n",
    "    iterations_avg_levenshtein_distance_norm = []\n",
    "    for it in range(5):\n",
    "        samples = [item for k in range(\n",
    "            int(n_sample / 500)) for item in dataset[\"real\"][it][k]]\n",
    "        n_unique_tokens = count_unique_tokens(\n",
    "            [token for example in samples for token in example[\"tokenized_text\"]])\n",
    "        n_unique_lemmas = count_unique_lemmas(\n",
    "            [token for example in samples for token in example[\"tokenized_text\"]])\n",
    "        n_unique_words_in_k_words = get_avg_unique_words_in_k_words(\n",
    "            [token for example in samples for token in example[\"tokenized_text\"]])\n",
    "        avg_levenshtein_distance = average_word_level_levenshtein_distance(\n",
    "            samples)\n",
    "        avg_levenshtein_distance_norm = average_word_level_levenshtein_distance(\n",
    "            samples, norm=True)\n",
    "\n",
    "        iterations_n_unique_tokens.append(n_unique_tokens)\n",
    "        iterations_n_lemmas.append(n_unique_lemmas)\n",
    "        iterations_avg_unique_words_in_k_words.append(\n",
    "            n_unique_words_in_k_words)\n",
    "        iterations_avg_levenshtein_distance.append(\n",
    "            avg_levenshtein_distance)\n",
    "        iterations_avg_levenshtein_distance_norm.append(\n",
    "            avg_levenshtein_distance_norm)\n",
    "\n",
    "    print(\"-\", \"&\", \"-\", \"&\", n_sample, \"&\",\n",
    "          round(np.mean(iterations_n_unique_tokens), 2), \"&\",\n",
    "          round(np.mean(iterations_n_lemmas), 2), \"&\",\n",
    "          round(np.mean(iterations_avg_unique_words_in_k_words), 2), \"&\",\n",
    "          round(np.mean(iterations_avg_levenshtein_distance), 2), \"&\",\n",
    "          round(np.mean(iterations_avg_levenshtein_distance_norm), 2))\n",
    "print(\"\\\\hline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_m1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
