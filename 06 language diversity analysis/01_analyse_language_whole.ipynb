{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook: Analyse Language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from spacy.lang.de.stop_words import STOP_WORDS\n",
    "from collections import Counter\n",
    "import Levenshtein\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "import spacy\n",
    "import nltk\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASPECT_CATEGORIES = [\"GENERAL-IMPRESSION\",\n",
    "                     \"FOOD\", \"SERVICE\", \"AMBIENCE\", \"PRICE\"]\n",
    "LLMS = [\"GPT-3\", \"Llama70B\"]\n",
    "FS_CONDITIONS = [\"fixed\", \"random\"]\n",
    "PROMPTING_ENCODING = {\"fixed\": \"25 fixed examples\",\n",
    "                      \"random\": \"25 random examples\"}\n",
    "N_FOLDS = 3\n",
    "CRITERIA_RS = \"tag_with_polarity\"\n",
    "POLARITIES = [\"POSITIVE\", \"NEGATIVE\", \"NEUTRAL\"]\n",
    "MENTIONING_TYPE = [\"implicit\", \"explicit\"]\n",
    "COMBINATIONS = [f\"{aspect}-{polarity}\" for aspect in [\"SERVICE\", \"FOOD\",\n",
    "                                                      \"GENERAL-IMPRESSION\", \"AMBIENCE\", \"PRICE\"] for polarity in POLARITIES]\n",
    "RANDOM_STATE = 43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODE_CONDITION = {\"fixed\": \"25 fixed examples\", \"random\": \"25 random examples\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/nils_hellwig/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"de_core_news_lg\")\n",
    "nltk.download('punkt')\n",
    "random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_raw = {\"synth\": {}, \"real\": []}\n",
    "\n",
    "# Load Synth\n",
    "for llm in LLMS:\n",
    "    dataset_raw[\"synth\"][llm] = {}\n",
    "    for prompting in FS_CONDITIONS:\n",
    "        dataset_raw[\"synth\"][llm][prompting] = []\n",
    "        for split in range(5):\n",
    "            with open(f\"../07 train models/synth/{llm}/{prompting}/split_{split}.json\", 'r', encoding='utf-8') as json_file:\n",
    "                split_data = json.load(json_file)\n",
    "            for example in split_data:\n",
    "                example[\"tokenized_text\"] = nlp(example[\"text\"])\n",
    "            dataset_raw[\"synth\"][llm][prompting].append(split_data)\n",
    "\n",
    "# Load Real\n",
    "for split in range(6):\n",
    "    with open(f\"../07 train models/real/split_{split}.json\", 'r', encoding='utf-8') as json_file:\n",
    "        split_data = json.load(json_file)\n",
    "    for example in split_data:\n",
    "        example[\"tokenized_text\"] = nlp(example[\"text\"])\n",
    "    dataset_raw[\"real\"].append(split_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Token in Sentence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Synthetic Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1975"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([example[\"tokenized_text\"][0].pos_ for example in dataset_raw[\"synth\"][\"Llama70B\"][\"fixed\"][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prozentsatz der Artikel (GPT-3, random): 91.47 %\n",
      "Prozentsatz der Artikel (GPT-3, random): 91.67 %\n",
      "Prozentsatz der Artikel (Llama70B, random): 57.72 %\n",
      "Prozentsatz der Artikel (Llama70B, random): 57.33 %\n"
     ]
    }
   ],
   "source": [
    "for llm in LLMS:\n",
    "    for few_shot_condition in FS_CONDITIONS:\n",
    "        first_tokens = [example[\"tokenized_text\"][0].pos_ for split_id in range(5) for example in dataset_raw[\"synth\"][llm][few_shot_condition][split_id]]\n",
    "        pos_counts = Counter(first_tokens)\n",
    "        article_percentage = (pos_counts[\"DET\"] / len(first_tokens)) * 100\n",
    "        print(\n",
    "            f\"Prozentsatz der Artikel ({llm}, {prompting}): {round(article_percentage, 2)} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Real Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prozentsatz der Artikel Real: 27.6 %\n"
     ]
    }
   ],
   "source": [
    "first_tokens = [example[\"tokenized_text\"][0].pos_ for split_idx in range(\n",
    "    5) for example in dataset_raw[\"real\"][split_idx]]\n",
    "pos_counts = Counter(first_tokens)\n",
    "article_percentage = (pos_counts[\"DET\"] / len(first_tokens)) * 100\n",
    "print(\n",
    "    f\"Prozentsatz der Artikel Real: {round(article_percentage, 3)} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AVG Number of Tokens in Sentence for each Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9875"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([len(example[\"tokenized_text\"]) for split_idx in range(5) for example in dataset_raw[\"synth\"][\"Llama70B\"][\"fixed\"][split_idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-3 & fixed & 9.68 [9.24, 9.72, 9.1, 10.32, 10.01] 0.458\n",
      "GPT-3 & random & 9.04 [8.97, 9.11, 8.84, 8.87, 9.4] 0.204\n",
      "Llama70B & fixed & 10.35 [9.56, 10.98, 10.0, 10.42, 10.8] 0.52\n",
      "Llama70B & random & 10.2 [10.06, 10.26, 9.89, 10.24, 10.57] 0.227\n"
     ]
    }
   ],
   "source": [
    "for llm in LLMS:\n",
    "    for few_shot_condition in FS_CONDITIONS:\n",
    "        word_counts = [len(example[\"tokenized_text\"]) for split_idx in range(5) for example in dataset_raw[\"synth\"][llm][few_shot_condition][split_idx]]\n",
    "\n",
    "        word_counts_splits = []\n",
    "        for idx in range(5):\n",
    "            word_counts_splits.append(round(np.mean([len(example[\"tokenized_text\"]) for example in dataset_raw[\"synth\"][llm][few_shot_condition][idx]]), 2))\n",
    "\n",
    "        print(llm, \"&\", ENCODE_CONDITION[few_shot_condition], \"&\", round(\n",
    "            np.mean(word_counts), 2), word_counts_splits, round(np.std(word_counts_splits), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Real Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real 13.12\n"
     ]
    }
   ],
   "source": [
    "word_counts = [len(example[\"tokenized_text\"]) for idx in range(6) for example in dataset_raw[\"real\"][idx]]\n",
    "\n",
    "print(\"Real\", round(np.mean(word_counts),2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_m1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
