{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0d22bba-6bd8-4cf5-a82d-8902e533973c",
   "metadata": {},
   "source": [
    "# Notebook: Analyse Language Diversity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0dcfb1-6eab-4730-bda2-ca3a90d80987",
   "metadata": {},
   "source": [
    "Dieses Notebook analysiert fünf Splits und berechnet Statistiken zur Sprache."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa234d8-c34b-4aa5-a156-a7faf6555811",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e001435c-ddc2-4522-9c2f-5cb7ec941aac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import nltk\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b526110f-23cd-481d-a46e-c237e2b19721",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.de.stop_words import STOP_WORDS\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c272eaaa-e283-4a2d-89d0-65cfa446bd7a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/nils_hellwig/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fc5537f-e0b7-4d17-9d98-7c8a3c9f8f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"de_core_news_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c26256-a86f-4545-94a0-da98d5cf9d01",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d62364c6-b0f8-42c7-b6ff-99da24cecb8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "N_SYNTH = 500\n",
    "LABELS_FIXED = True\n",
    "N_REAL = 0\n",
    "MODEL = \"Llama13B\" # \"Llama70B\", \"GPT-3\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbaad2de-f0ef-47f6-88bf-2570077f48a2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739e0c47-8f1b-45bc-ab9c-a3c996e2cd1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4cba7e45-2617-4526-8bd4-f479848f628f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7eeb129b-44e0-455f-ba71-83ac329f2abe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_tokens(texts):\n",
    "    token_counts = [] \n",
    "    for text in texts:\n",
    "        tokens = word_tokenize(text)\n",
    "        token_counts.append(len(tokens))\n",
    "    return token_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e2254fe-973c-4513-a4ea-7040202381a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_unique_lemmas(texts):\n",
    "    unique_lemmas = set()\n",
    "    for text in texts:\n",
    "        doc = nlp(text)\n",
    "        for token in doc:\n",
    "            unique_lemmas.add(token.lemma_)\n",
    "    return len(unique_lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "935d6b48-6643-47b7-a634-bd454375fe53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_stopwords_and_punctuation(text):\n",
    "    doc = nlp(text)\n",
    "    cleaned_tokens = [token.lemma_ for token in doc if token.text.lower() not in STOP_WORDS and token.text not in string.punctuation]\n",
    "    cleaned_text = ' '.join(cleaned_tokens)\n",
    "    return cleaned_text\n",
    "\n",
    "def count_top_n_lemmas(texts, n):\n",
    "    lemma_counts = {}\n",
    "    for text in texts:\n",
    "        print(text)\n",
    "        cleaned_text = remove_stopwords_and_punctuation(text)\n",
    "        doc = nlp(cleaned_text)\n",
    "        for token in doc:\n",
    "            lemma = token.lemma_\n",
    "            if lemma in lemma_counts:\n",
    "                lemma_counts[lemma] += 1\n",
    "            else:\n",
    "                lemma_counts[lemma] = 1\n",
    "    \n",
    "    sorted_lemmas = sorted(lemma_counts, key=lambda lemma: lemma_counts[lemma], reverse=True)\n",
    "    top_n_lemmas = sorted_lemmas[:n]\n",
    "    \n",
    "    return ', '.join(top_n_lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8bffd3d-477a-4dc1-94c0-bd22adaead1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die Speisen waren ok, und das Ambiente auch.\n",
      "Im Service und Preis waren wir schon fast nicht überrascht.\n",
      "Für mich war es auch kein guter Preis - dafür aber ein Gemütlichkeit und ein Service auf dem Niveau, auf das ich mich auch nicht mehr eingestellt hätte.\n",
      "Hausbackshase war nicht so lecker wie an Fechter.\n",
      "Preise und Service war eher mittelmäßig, das Essen hingegen super.\n",
      "Die Speisen waren ok, und das Ambiente auch.\n",
      "Im Service und Preis waren wir schon fast nicht überrascht.\n",
      "Für mich war es auch kein guter Preis - dafür aber ein Gemütlichkeit und ein Service auf dem Niveau, auf das ich mich auch nicht mehr eingestellt hätte.\n",
      "Hausbackshase war nicht so lecker wie an Fechter.\n",
      "Preise und Service war eher mittelmäßig, das Essen hingegen super.\n",
      "Die Speisen waren ok, und das Ambiente auch.\n",
      "Im Service und Preis waren wir schon fast nicht überrascht.\n",
      "Für mich war es auch kein guter Preis - dafür aber ein Gemütlichkeit und ein Service auf dem Niveau, auf das ich mich auch nicht mehr eingestellt hätte.\n",
      "Hausbackshase war nicht so lecker wie an Fechter.\n",
      "Preise und Service war eher mittelmäßig, das Essen hingegen super.\n",
      "Die Speisen waren ok, und das Ambiente auch.\n",
      "Im Service und Preis waren wir schon fast nicht überrascht.\n",
      "Für mich war es auch kein guter Preis - dafür aber ein Gemütlichkeit und ein Service auf dem Niveau, auf das ich mich auch nicht mehr eingestellt hätte.\n",
      "Hausbackshase war nicht so lecker wie an Fechter.\n",
      "Preise und Service war eher mittelmäßig, das Essen hingegen super.\n",
      "Die Speisen waren ok, und das Ambiente auch.\n",
      "Im Service und Preis waren wir schon fast nicht überrascht.\n",
      "Für mich war es auch kein guter Preis - dafür aber ein Gemütlichkeit und ein Service auf dem Niveau, auf das ich mich auch nicht mehr eingestellt hätte.\n",
      "Hausbackshase war nicht so lecker wie an Fechter.\n",
      "Preise und Service war eher mittelmäßig, das Essen hingegen super.\n"
     ]
    }
   ],
   "source": [
    "total_texts = []\n",
    "unique_lemma_counts = []\n",
    "texts_token_counts = []\n",
    "n_aspects_total = []\n",
    "n_implicit_aspects_total = []\n",
    "n_explicit_aspects_total = []\n",
    "\n",
    "for i in range(0, 5):\n",
    "    examples_in_split = []\n",
    "    \n",
    "    # Load Real Split\n",
    "    real_path = f\"../03 dataset split/real/real_{i}.json\"\n",
    "    with open(real_path, 'r') as file:\n",
    "        real_data = json.load(file)[:N_REAL]\n",
    "        examples_in_split = real_data\n",
    "    \n",
    "    # Load Synth Split\n",
    "    fake_path = f\"../04 llm synthesis/synth/{MODEL}/{'fixed' if LABELS_FIXED else 'random'}/split_{i}.json\"\n",
    "    with open(fake_path, 'r') as file:\n",
    "        fake_data = json.load(file)[:N_SYNTH]\n",
    "        examples_in_split = fake_data\n",
    "    \n",
    "    texts = [example[\"text\"] for example in fake_data]\n",
    "    \n",
    "    \n",
    "    # Calculate n tokens in texts\n",
    "    texts_token_count = count_tokens(texts)\n",
    "    for count in texts_token_count:\n",
    "        texts_token_counts.append(count)\n",
    "    \n",
    "    # Calcuate unique lemmas in text\n",
    "    unique_lemma_count = count_unique_lemmas(texts)\n",
    "    unique_lemma_counts.append(unique_lemma_count)\n",
    "    \n",
    "    # Calculate number of aspects (implicit+explicit)\n",
    "    n_aspects = len([tag[\"text\"] for example in fake_data for tag in example[\"tags\"]])\n",
    "    n_aspects_total.append(n_aspects)\n",
    "    \n",
    "    \n",
    "    # Calculate number of implicit aspects\n",
    "    n_implicit_aspects = len([tag[\"text\"] for example in fake_data for tag in example[\"tags\"] if tag[\"text\"] is None])\n",
    "    n_implicit_aspects_total.append(n_implicit_aspects)\n",
    "    \n",
    "    # Calculate number of unique aspect terms\n",
    "    explicit_aspects = [tag[\"text\"] for example in fake_data for tag in example[\"tags\"] if tag[\"text\"] is not None]\n",
    "    n_unique_aspect_terms = len(set(explicit_aspects))\n",
    "    n_explicit_aspects_total.append(n_unique_aspect_terms)\n",
    "    \n",
    "    \n",
    "    # Add to total text collection\n",
    "    total_texts.extend(texts)\n",
    "\n",
    "top_n_lemmas = count_top_n_lemmas(total_texts, 5)\n",
    "unique_lemmas_avg = np.mean(unique_lemma_counts)\n",
    "texts_token_counts_avg = np.mean(texts_token_counts)\n",
    "n_aspects_avg = np.mean(n_aspects_total)\n",
    "n_implicit_aspects_avg = np.mean(n_implicit_aspects_total) / (np.mean(n_implicit_aspects_total) + np.mean(n_explicit_aspects_total))\n",
    "n_explicit_aspects_avg = np.mean(n_explicit_aspects_total) / (np.mean(n_implicit_aspects_total) + np.mean(n_explicit_aspects_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d9bed01-6640-483e-a759-7528239a8618",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Service, Preis, Speise, ok, Ambiente'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_n_lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e193457-3769-4118-8cda-24e69211cd88",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_lemmas_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad20d0c9-ca7a-4709-a1e5-dcb5c791ea5a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.4"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_token_counts_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed8343eb-b521-4c4a-bba0-c5a4c063e634",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_aspects_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a95eff0-9960-402d-bd85-73651ffc9c06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_implicit_aspects_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "14a9befc-22ae-4049-b1f5-90178c89dd53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_explicit_aspects_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "36020d47-a679-4bc8-be86-aa50689e86aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_implicit_aspects_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff8c46e-457a-47de-aa41-46257e4b7476",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
