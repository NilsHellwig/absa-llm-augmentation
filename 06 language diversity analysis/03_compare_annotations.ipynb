{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook: Convert to Formatted JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, multilabel_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../03 dataset split/'))\n",
    "from format_labelstudio_json import format_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath('../07 train classifier/'))\n",
    "from TASD.evaluation import calculate_metrics_for_examples\n",
    "import constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"Llama13B\"\n",
    "FEW_SHOT = \"random\"\n",
    "N_EXAMPLES = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"annotation_datasets/synth_annotation_labelstudio_output/annotation_{MODEL}_{FEW_SHOT}_{N_EXAMPLES}.json\", 'r') as json_file:\n",
    "    synthetic_data = json.load(json_file)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_llm_labels = []\n",
    "for split_id in range(5):\n",
    "    with open(f\"../07 train classifier/synth/{MODEL}/{FEW_SHOT}/split_{split_id}.json\", 'r') as json_file:\n",
    "       synthetic_data_split = json.load(json_file)\n",
    "       for example in  synthetic_data_split:\n",
    "           synth_llm_labels.append(example)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ground truth - annotations\n",
    "synth_annotated = format_json(synthetic_data)\n",
    "synth_annotated_ids = [example[\"id\"] for example in synth_annotated]\n",
    "\n",
    "# label from llm\n",
    "synth_llm_labels = [example for example in synth_llm_labels if example[\"id\"] in synth_annotated_ids]\n",
    "def get_index(example):\n",
    "    return synth_annotated_ids.index(example[\"id\"])\n",
    "synth_llm_labels = sorted(synth_llm_labels, key=get_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(synth_llm_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], 'Ja, das ist sicher eine Nostalgie für uns.')"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synth_annotated[1][\"tags\"], synth_annotated[1][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'text': 'Nostalgie',\n",
       "   'start': 24,\n",
       "   'end': 33,\n",
       "   'tag_with_polarity': 'GENERAL-IMPRESSION-POSITIVE',\n",
       "   'tag_with_polarity_and_type': 'GENERAL-IMPRESSION-POSITIVE-explicit',\n",
       "   'type': 'label-explicit',\n",
       "   'label': 'GENERAL-IMPRESSION',\n",
       "   'polarity': 'POSITIVE'}],\n",
       " 'Ja, das ist sicher eine Nostalgie für uns.')"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synth_llm_labels[1][\"tags\"], synth_llm_labels[1][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_llm_labels = [[{\"aspect_category\": tag[\"label\"], \"aspect_polarity\": tag[\"polarity\"], \"aspect_term\": tag[\"text\"]} for tag in example[\"tags\"]] for example in synth_llm_labels]\n",
    "synth_annotated = [[{\"aspect_category\": tag[\"label\"], \"aspect_polarity\": tag[\"polarity\"], \"aspect_term\": tag[\"text\"] if tag[\"text\"] != 'NULL' else None} for tag in example[\"tags\"]] for example in synth_annotated]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test: Check how many Triplets could be identified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1': 0.4193548387096774,\n",
       " 'recall': 0.5416666666666666,\n",
       " 'precision': 0.34210526315789475,\n",
       " 'accuracy': 0.2653061224489796,\n",
       " 'tp': 13,\n",
       " 'tn': 0,\n",
       " 'fp': 25,\n",
       " 'fn': 11}"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_metrics_for_examples(synth_annotated, synth_llm_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test: Compare aspect category annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_list_to_label(cat_list):\n",
    "    return [1 if cat in cat_list else 0 for cat in constants.ASPECT_CATEGORIES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_llm_labels_categories = [category_list_to_label([tag[\"aspect_category\"] for tag in example]) for example in synth_llm_labels]\n",
    "synth_annotated_categories = [category_list_to_label([tag[\"aspect_category\"] for tag in example]) for example in synth_annotated]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.56\n"
     ]
    }
   ],
   "source": [
    "true_classes = synth_annotated_categories\n",
    "predicted_classes = synth_llm_labels_categories\n",
    "\n",
    "accuracy = accuracy_score(true_classes, predicted_classes)\n",
    "# Accuracy ist korrekt, wenn alle fünf klassen eines Beispiels korrekt predicted wurden\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "confusion = multilabel_confusion_matrix(true_classes, predicted_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERAL-IMPRESSION \n",
      "| True Positives:  2 | True Negatives:  18 | False Positives:  4 | False Negatives:  1 | Accuracy:  0.8 | Precision:  0.333 | Recall:  0.667 | F1-Score:  0.444 |\n",
      "FOOD \n",
      "| True Positives:  4 | True Negatives:  17 | False Positives:  3 | False Negatives:  1 | Accuracy:  0.84 | Precision:  0.571 | Recall:  0.8 | F1-Score:  0.667 |\n",
      "SERVICE \n",
      "| True Positives:  2 | True Negatives:  20 | False Positives:  2 | False Negatives:  1 | Accuracy:  0.88 | Precision:  0.5 | Recall:  0.667 | F1-Score:  0.571 |\n",
      "AMBIENCE \n",
      "| True Positives:  8 | True Negatives:  15 | False Positives:  2 | False Negatives:  0 | Accuracy:  0.92 | Precision:  0.8 | Recall:  1.0 | F1-Score:  0.889 |\n",
      "PRICE \n",
      "| True Positives:  5 | True Negatives:  17 | False Positives:  3 | False Negatives:  0 | Accuracy:  0.88 | Precision:  0.625 | Recall:  1.0 | F1-Score:  0.769 |\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(constants.ASPECT_CATEGORIES)):\n",
    "    tp, tn, fp, fn = confusion[i][1][1], confusion[i][0][0], confusion[i][0][1], confusion[i][1][0]\n",
    "\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "    acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "\n",
    "    # Runden auf drei Nachkommastellen\n",
    "    precision = round(precision, 3)\n",
    "    recall = round(recall, 3)\n",
    "    f1_score = round(f1_score, 3)\n",
    "    acc = round(acc, 3)\n",
    "\n",
    "    print(constants.ASPECT_CATEGORIES[i], \"\\n| True Positives: \", tp, \"| True Negatives: \", tn, \"| False Positives: \", fp, \"| False Negatives: \", fn, \"| Accuracy: \", acc, \"| Precision: \", precision, \"| Recall: \", recall, \"| F1-Score: \", f1_score, \"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test: Check if category and polarity detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "AC_POLARITY_COMBINATIONS = [cat+\"_\"+polarity for cat in constants.ASPECT_CATEGORIES for polarity in constants.POLARITIES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_polarity_list_to_label(cat_pol_list):\n",
    "    return [1 if ac_pol in cat_pol_list else 0 for ac_pol in AC_POLARITY_COMBINATIONS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_llm_labels_categories = [category_polarity_list_to_label(\n",
    "    [tag[\"aspect_category\"]+\"_\"+tag[\"aspect_polarity\"] for tag in example]) for example in synth_llm_labels]\n",
    "synth_annotated_categories = [category_polarity_list_to_label(\n",
    "    [tag[\"aspect_category\"]+\"_\"+tag[\"aspect_polarity\"] for tag in example]) for example in synth_annotated]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.32\n"
     ]
    }
   ],
   "source": [
    "true_classes = synth_annotated_categories\n",
    "predicted_classes = synth_llm_labels_categories\n",
    "\n",
    "accuracy = accuracy_score(true_classes, predicted_classes)\n",
    "# Accuracy ist korrekt, wenn alle fünf klassen eines Beispiels korrekt predicted wurden\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "confusion = multilabel_confusion_matrix(true_classes, predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERAL-IMPRESSION_POSITIVE \n",
      "| True Positives:  0 | True Negatives:  23 | False Positives:  2 | False Negatives:  0 | Accuracy:  0.92 | Precision:  0.0 | Recall:  0.0 | F1-Score:  0.0 |\n",
      "GENERAL-IMPRESSION_NEUTRAL \n",
      "| True Positives:  0 | True Negatives:  23 | False Positives:  2 | False Negatives:  0 | Accuracy:  0.92 | Precision:  0.0 | Recall:  0.0 | F1-Score:  0.0 |\n",
      "GENERAL-IMPRESSION_NEGATIVE \n",
      "| True Positives:  2 | True Negatives:  22 | False Positives:  0 | False Negatives:  1 | Accuracy:  0.96 | Precision:  1.0 | Recall:  0.667 | F1-Score:  0.8 |\n",
      "FOOD_POSITIVE \n",
      "| True Positives:  1 | True Negatives:  22 | False Positives:  1 | False Negatives:  1 | Accuracy:  0.92 | Precision:  0.5 | Recall:  0.5 | F1-Score:  0.5 |\n",
      "FOOD_NEUTRAL \n",
      "| True Positives:  0 | True Negatives:  23 | False Positives:  2 | False Negatives:  0 | Accuracy:  0.92 | Precision:  0.0 | Recall:  0.0 | F1-Score:  0.0 |\n",
      "FOOD_NEGATIVE \n",
      "| True Positives:  2 | True Negatives:  22 | False Positives:  1 | False Negatives:  0 | Accuracy:  0.96 | Precision:  0.667 | Recall:  1.0 | F1-Score:  0.8 |\n",
      "SERVICE_POSITIVE \n",
      "| True Positives:  1 | True Negatives:  23 | False Positives:  0 | False Negatives:  1 | Accuracy:  0.96 | Precision:  1.0 | Recall:  0.5 | F1-Score:  0.667 |\n",
      "SERVICE_NEUTRAL \n",
      "| True Positives:  0 | True Negatives:  22 | False Positives:  3 | False Negatives:  0 | Accuracy:  0.88 | Precision:  0.0 | Recall:  0.0 | F1-Score:  0.0 |\n",
      "SERVICE_NEGATIVE \n",
      "| True Positives:  0 | True Negatives:  24 | False Positives:  0 | False Negatives:  1 | Accuracy:  0.96 | Precision:  0.0 | Recall:  0.0 | F1-Score:  0.0 |\n",
      "AMBIENCE_POSITIVE \n",
      "| True Positives:  2 | True Negatives:  18 | False Positives:  1 | False Negatives:  4 | Accuracy:  0.8 | Precision:  0.667 | Recall:  0.333 | F1-Score:  0.444 |\n",
      "AMBIENCE_NEUTRAL \n",
      "| True Positives:  0 | True Negatives:  21 | False Positives:  4 | False Negatives:  0 | Accuracy:  0.84 | Precision:  0.0 | Recall:  0.0 | F1-Score:  0.0 |\n",
      "AMBIENCE_NEGATIVE \n",
      "| True Positives:  2 | True Negatives:  22 | False Positives:  1 | False Negatives:  0 | Accuracy:  0.96 | Precision:  0.667 | Recall:  1.0 | F1-Score:  0.8 |\n",
      "PRICE_POSITIVE \n",
      "| True Positives:  2 | True Negatives:  20 | False Positives:  3 | False Negatives:  0 | Accuracy:  0.88 | Precision:  0.4 | Recall:  1.0 | F1-Score:  0.571 |\n",
      "PRICE_NEUTRAL \n",
      "| True Positives:  1 | True Negatives:  23 | False Positives:  1 | False Negatives:  0 | Accuracy:  0.96 | Precision:  0.5 | Recall:  1.0 | F1-Score:  0.667 |\n",
      "PRICE_NEGATIVE \n",
      "| True Positives:  2 | True Negatives:  22 | False Positives:  1 | False Negatives:  0 | Accuracy:  0.96 | Precision:  0.667 | Recall:  1.0 | F1-Score:  0.8 |\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(AC_POLARITY_COMBINATIONS)):\n",
    "    tp, tn, fp, fn = confusion[i][1][1], confusion[i][0][0], confusion[i][0][1], confusion[i][1][0]\n",
    "\n",
    "    precision = round(tp / (tp + fp) if (tp + fp) > 0 else 0.0, 3)\n",
    "    recall = round(tp / (tp + fn) if (tp + fn) > 0 else 0.0, 3)\n",
    "    f1_score = round(2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0, 3)\n",
    "    acc = round((tp + tn) / (tp + tn + fp + fn), 3)\n",
    "\n",
    "    print(AC_POLARITY_COMBINATIONS[i], \"\\n| True Positives: \", tp, \"| True Negatives: \", tn, \"| False Positives: \", fp, \"| False Negatives: \", fn, \"| Accuracy: \", acc, \"| Precision: \", precision, \"| Recall: \", recall, \"| F1-Score: \", f1_score, \"|\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_m1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
