{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook: Analyse Language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T07:18:14.841832Z",
     "iopub.status.busy": "2024-02-28T07:18:14.841058Z",
     "iopub.status.idle": "2024-02-28T07:18:16.858912Z",
     "shell.execute_reply": "2024-02-28T07:18:16.857777Z"
    }
   },
   "outputs": [],
   "source": [
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from spacy.lang.de.stop_words import STOP_WORDS\n",
    "from collections import Counter\n",
    "import Levenshtein\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "import spacy\n",
    "import nltk\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T07:18:16.863276Z",
     "iopub.status.busy": "2024-02-28T07:18:16.863042Z",
     "iopub.status.idle": "2024-02-28T07:18:16.867114Z",
     "shell.execute_reply": "2024-02-28T07:18:16.866567Z"
    }
   },
   "outputs": [],
   "source": [
    "ASPECT_CATEGORIES = [\"GENERAL-IMPRESSION\",\n",
    "                     \"FOOD\", \"SERVICE\", \"AMBIENCE\", \"PRICE\"]\n",
    "LLMS = [\"Llama2_70B\", \"Llama3_70B\", \"GPT-3\"]\n",
    "FS_CONDITIONS = [\"fixed\", \"random\"]\n",
    "CRITERIA_RS = \"tag_with_polarity\"\n",
    "POLARITIES = [\"POSITIVE\", \"NEGATIVE\", \"NEUTRAL\"]\n",
    "MENTIONING_TYPE = [\"implicit\", \"explicit\"]\n",
    "COMBINATIONS = [f\"{aspect}-{polarity}\" for aspect in [\"SERVICE\", \"FOOD\",\n",
    "                                                      \"GENERAL-IMPRESSION\", \"AMBIENCE\", \"PRICE\"] for polarity in POLARITIES]\n",
    "RANDOM_STATE = 43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T07:18:16.870594Z",
     "iopub.status.busy": "2024-02-28T07:18:16.870402Z",
     "iopub.status.idle": "2024-02-28T07:18:16.873266Z",
     "shell.execute_reply": "2024-02-28T07:18:16.872718Z"
    }
   },
   "outputs": [],
   "source": [
    "LLMS_ENCODED = {\"GPT-3\": \"\\\\textbf{GPT-3.5-turbo}\", \"Llama2_70B\": \"\\\\textbf{Llama-2-70B}\", \"Llama3_70B\": \"\\\\textbf{Llama-3-70B}\"}\n",
    "ENCODE_CONDITION = {\"fixed\": \"\\\\textbf{LRS\\\\textsubscript{25}}\",\n",
    "                    \"random\": \"\\\\textbf{LRS\\\\textsubscript{500}}\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T07:18:16.876949Z",
     "iopub.status.busy": "2024-02-28T07:18:16.876771Z",
     "iopub.status.idle": "2024-02-28T07:18:18.330912Z",
     "shell.execute_reply": "2024-02-28T07:18:18.330184Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/nils_hellwig/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"de_core_news_lg\")\n",
    "nltk.download('punkt')\n",
    "random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T07:18:18.371641Z",
     "iopub.status.busy": "2024-02-28T07:18:18.371241Z",
     "iopub.status.idle": "2024-02-28T07:18:18.382024Z",
     "shell.execute_reply": "2024-02-28T07:18:18.381237Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_unique_sentences(sentences):\n",
    "    unique_sentences = set(sentences)\n",
    "    return len(unique_sentences)\n",
    "\n",
    "\n",
    "def count_unique_tokens(tokens):\n",
    "    unique_tokens = set(token.text for token in tokens)\n",
    "    return len(unique_tokens)\n",
    "\n",
    "\n",
    "def count_unique_lemmas(tokens):\n",
    "    unique_lemmas = set(token.lemma_ for token in tokens)\n",
    "    return len(unique_lemmas)\n",
    "\n",
    "\n",
    "def get_avg_unique_words_in_k_words(tokens, n_selection=100, n_repetitions=1000000):\n",
    "    iterations_n_unique_words = []\n",
    "    for i in range(n_repetitions):\n",
    "        random_indices = random.sample(range(len(tokens)), n_selection)\n",
    "        random_words = [tokens[index] for index in random_indices]\n",
    "        n_unique_words = len(set(random_words))\n",
    "        iterations_n_unique_words.append(n_unique_words)\n",
    "    return np.mean(iterations_n_unique_words)\n",
    "\n",
    "\n",
    "def average_word_level_levenshtein_distance(docs, norm=False):\n",
    "    tokenized_texts = [\n",
    "        [token.text for token in doc[\"tokenized_text\"]] for doc in docs]\n",
    "\n",
    "    total_distance = 0\n",
    "    pair_count = 0\n",
    "\n",
    "    for i in range(len(tokenized_texts)):\n",
    "        for j in range(i + 1, len(tokenized_texts)):\n",
    "            tokens1 = tokenized_texts[i]\n",
    "            tokens2 = tokenized_texts[j]\n",
    "\n",
    "            if len(tokens1) >= len(tokens2):\n",
    "                max_tokens = len(tokens1)\n",
    "            else:\n",
    "                max_tokens = len(tokens2)\n",
    "\n",
    "            distance = Levenshtein.distance(tokens1, tokens2)\n",
    "            if norm:\n",
    "                distance = distance / max_tokens\n",
    "            total_distance += distance\n",
    "            pair_count += 1\n",
    "\n",
    "    average_distance = total_distance / pair_count if pair_count > 0 else 0\n",
    "    return average_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T07:18:18.384595Z",
     "iopub.status.busy": "2024-02-28T07:18:18.384282Z",
     "iopub.status.idle": "2024-02-28T07:18:18.390502Z",
     "shell.execute_reply": "2024-02-28T07:18:18.389829Z"
    }
   },
   "outputs": [],
   "source": [
    "def round_number(num, decimal_places=None):\n",
    "    if decimal_places == None:\n",
    "        if num <= 10:\n",
    "            decimal_places = 2\n",
    "        elif num <= 100:\n",
    "            decimal_places = 1\n",
    "        else :\n",
    "            decimal_places = 0\n",
    "    formatted_num = \"{:.{}f}\".format(num, decimal_places)\n",
    "    rounded_num_str = \"{:.{}f}\".format(float(formatted_num), decimal_places)\n",
    "    return rounded_num_str\n",
    "\n",
    "def add_thousand_dots(n_sample):\n",
    "    if isinstance(n_sample, str):\n",
    "        if '.' in n_sample:\n",
    "            integer_part, decimal_part = n_sample.split('.')\n",
    "            formatted_integer_part = \"{:,}\".format(int(integer_part))\n",
    "            result = f\"{formatted_integer_part}.{decimal_part}\"\n",
    "        else:\n",
    "            result = \"{:,}\".format(int(n_sample))\n",
    "    elif isinstance(n_sample, np.float64):\n",
    "        result = \"{:,}\".format(round(n_sample, 1))\n",
    "    else:\n",
    "        result = n_sample\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T07:18:18.393295Z",
     "iopub.status.busy": "2024-02-28T07:18:18.392982Z",
     "iopub.status.idle": "2024-02-28T07:22:04.192301Z",
     "shell.execute_reply": "2024-02-28T07:22:04.191661Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m                 split_data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(json_file)\n\u001b[1;32m     11\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m example \u001b[38;5;129;01min\u001b[39;00m split_data:\n\u001b[0;32m---> 12\u001b[0m                 example[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokenized_text\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mnlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m             dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msynth\u001b[39m\u001b[38;5;124m\"\u001b[39m][llm][prompting]\u001b[38;5;241m.\u001b[39mappend(split_data)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Load Real\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow_m1/lib/python3.11/site-packages/spacy/language.py:1042\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m   1040\u001b[0m     error_handler \u001b[38;5;241m=\u001b[39m proc\u001b[38;5;241m.\u001b[39mget_error_handler()\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1042\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[43mproc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcomponent_cfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m   1043\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1044\u001b[0m     \u001b[38;5;66;03m# This typically happens if a component is not initialized\u001b[39;00m\n\u001b[1;32m   1045\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE109\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow_m1/lib/python3.11/site-packages/spacy/pipeline/trainable_pipe.pyx:52\u001b[0m, in \u001b[0;36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow_m1/lib/python3.11/site-packages/spacy/pipeline/transition_parser.pyx:263\u001b[0m, in \u001b[0;36mspacy.pipeline.transition_parser.Parser.predict\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow_m1/lib/python3.11/site-packages/spacy/pipeline/transition_parser.pyx:284\u001b[0m, in \u001b[0;36mspacy.pipeline.transition_parser.Parser.greedy_parse\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow_m1/lib/python3.11/site-packages/thinc/model.py:334\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m OutT:\n\u001b[1;32m    331\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function with `is_train=False`, and return\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;124;03m    only the output, instead of the `(output, callback)` tuple.\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 334\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow_m1/lib/python3.11/site-packages/spacy/ml/tb_framework.py:34\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(model, X, is_train):\n\u001b[0;32m---> 34\u001b[0m     step_model \u001b[38;5;241m=\u001b[39m \u001b[43mParserStepModel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[43munseen_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43munseen_classes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_upper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhas_upper\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m step_model, step_model\u001b[38;5;241m.\u001b[39mfinish_steps\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow_m1/lib/python3.11/site-packages/spacy/ml/parser_model.pyx:256\u001b[0m, in \u001b[0;36mspacy.ml.parser_model.ParserStepModel.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow_m1/lib/python3.11/site-packages/spacy/ml/parser_model.pyx:397\u001b[0m, in \u001b[0;36mspacy.ml.parser_model.precompute_hiddens.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow_m1/lib/python3.11/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow_m1/lib/python3.11/site-packages/spacy/ml/_precomputable_affine.py:27\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Preallocate array for layer output, including padding.\u001b[39;00m\n\u001b[1;32m     26\u001b[0m Yf \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39malloc2f(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, nF \u001b[38;5;241m*\u001b[39m nO \u001b[38;5;241m*\u001b[39m nP, zeros\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 27\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgemm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnF\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnO\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnP\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnI\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrans2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mYf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m Yf \u001b[38;5;241m=\u001b[39m Yf\u001b[38;5;241m.\u001b[39mreshape((Yf\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], nF, nO, nP))\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Set padding. Padding has shape (1, nF, nO, nP). Unfortunately, we cannot\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# change its shape to (nF, nO, nP) without breaking existing models. So\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# we'll squeeze the first dimension here.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset = {\"synth\": {}, \"real\": []}\n",
    "\n",
    "# Load Synth\n",
    "for llm in LLMS:\n",
    "    dataset[\"synth\"][llm] = {}\n",
    "    for prompting in FS_CONDITIONS:\n",
    "        dataset[\"synth\"][llm][prompting] = []\n",
    "        for split in range(6):\n",
    "            with open(f\"../07 train models/synth/{llm}/{prompting}/split_{split}.json\", 'r', encoding='utf-8') as json_file:\n",
    "                split_data = json.load(json_file)\n",
    "            for example in split_data:\n",
    "                example[\"tokenized_text\"] = nlp(example[\"text\"])\n",
    "            dataset[\"synth\"][llm][prompting].append(split_data)\n",
    "\n",
    "# Load Real\n",
    "for split in range(6):\n",
    "    with open(f\"../07 train models/real/split_{split}.json\", 'r', encoding='utf-8') as json_file:\n",
    "        split_data = json.load(json_file)\n",
    "    for example in split_data:\n",
    "        example[\"tokenized_text\"] = nlp(example[\"text\"])\n",
    "    dataset[\"real\"].append(split_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T07:22:04.196191Z",
     "iopub.status.busy": "2024-02-28T07:22:04.196041Z",
     "iopub.status.idle": "2024-02-28T07:22:04.199687Z",
     "shell.execute_reply": "2024-02-28T07:22:04.199155Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_one_hot(subset):\n",
    "    labels_one_hot = []\n",
    "    for i in range(len(subset)):\n",
    "        tags_in_example = list(set([tag[CRITERIA_RS]\n",
    "                               for tag in subset[i][\"tags\"]]))\n",
    "        one_hot_encoded_combination = np.array(\n",
    "            [1 if tag in tags_in_example else 0 for tag in COMBINATIONS])\n",
    "        labels_one_hot.append(one_hot_encoded_combination)\n",
    "    return labels_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T07:22:04.202997Z",
     "iopub.status.busy": "2024-02-28T07:22:04.202876Z",
     "iopub.status.idle": "2024-02-28T07:24:04.075462Z",
     "shell.execute_reply": "2024-02-28T07:24:04.074479Z"
    }
   },
   "outputs": [],
   "source": [
    "for llm in LLMS:\n",
    "    for few_shot_condition in FS_CONDITIONS:\n",
    "        for iteration in range(6):\n",
    "            if few_shot_condition == \"random\":\n",
    "                subset = dataset[\"synth\"][llm][few_shot_condition][iteration]\n",
    "            else:\n",
    "                subset = dataset[\"synth\"][llm][few_shot_condition][iteration][475:]\n",
    "\n",
    "            found_3_split = False\n",
    "            restart_idx = 0\n",
    "            while found_3_split == False:\n",
    "                mskf = MultilabelStratifiedKFold(\n",
    "                    n_splits=3, shuffle=True, random_state=RANDOM_STATE+restart_idx)\n",
    "                section = []\n",
    "                for train_index, test_index in mskf.split(subset, get_one_hot(subset)):\n",
    "                    split_500 = [subset[i] for i in test_index]\n",
    "                    section.append(split_500)\n",
    "\n",
    "                if len(section[0]) == 500 and len(section[1]) == 500 and len(section[2]) == 500:\n",
    "                    found_3_split = True\n",
    "\n",
    "                restart_idx += 1\n",
    "\n",
    "            dataset[\"synth\"][llm][few_shot_condition][iteration] = section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T07:24:04.080195Z",
     "iopub.status.busy": "2024-02-28T07:24:04.079838Z",
     "iopub.status.idle": "2024-02-28T07:24:04.085143Z",
     "shell.execute_reply": "2024-02-28T07:24:04.084429Z"
    }
   },
   "outputs": [],
   "source": [
    "real_examples = []\n",
    "for i in [0, 1, 2, 3, 4, 5]:\n",
    "    real_examples.append([])\n",
    "    for k in [0, 1, 2]:\n",
    "        if (i+k) < 6:\n",
    "            t = i+k\n",
    "        else:\n",
    "            t = i+k - 6\n",
    "        real_examples[i].append(dataset[\"real\"][t])\n",
    "dataset[\"real\"] = real_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Synthetic Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T07:24:04.089551Z",
     "iopub.status.busy": "2024-02-28T07:24:04.089235Z",
     "iopub.status.idle": "2024-02-28T07:24:06.237146Z",
     "shell.execute_reply": "2024-02-28T07:24:06.236569Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\multirow{6}{*}{\\textbf{Llama-2-70B}} & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{25}}} & 500 & 480 & 712 & 546 \\\\\n",
      " &  & 1,000 & 933 & 1,048 & 802 \\\\\n",
      " &  & 1,500 & 1,383 & 1,300 & 994 \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-6}\\arrayrulecolor{black}\n",
      " & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{500}}} & 500 & 486 & 754 & 583 \\\\\n",
      " &  & 1,000 & 948 & 1,108 & 849 \\\\\n",
      " &  & 1,500 & 1,397 & 1,380 & 1,055 \\\\\n",
      "\\hline\n",
      "\\multirow{6}{*}{\\textbf{GPT-3.5-turbo}} & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{25}}} & 500 & 308 & 296 & 216 \\\\\n",
      " &  & 1,000 & 553 & 377 & 275 \\\\\n",
      " &  & 1,500 & 778 & 440 & 319 \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-6}\\arrayrulecolor{black}\n",
      " & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{500}}} & 500 & 318 & 294 & 216 \\\\\n",
      " &  & 1,000 & 560 & 387 & 280 \\\\\n",
      " &  & 1,500 & 784 & 454 & 327 \\\\\n",
      "\\hline\n"
     ]
    }
   ],
   "source": [
    "for idx_llm, llm in enumerate(LLMS):\n",
    "    for idx_fsc, few_shot_condition in enumerate(FS_CONDITIONS):\n",
    "        for idx_sample, n_sample in enumerate([500, 1000, 1500]):\n",
    "            iterations_n_unique_tokens = []\n",
    "            iterations_n_lemmas = []\n",
    "            iterations_avg_unique_sentences = []\n",
    "            for it in range(6):\n",
    "                samples = [item for k in range(\n",
    "                    int(n_sample / 500)) for item in dataset[\"synth\"][llm][few_shot_condition][it][k]]\n",
    "                n_unique_tokens = count_unique_tokens(\n",
    "                    [token for example in samples for token in example[\"tokenized_text\"]])\n",
    "                n_unique_lemmas = count_unique_lemmas(\n",
    "                    [token for example in samples for token in example[\"tokenized_text\"]])\n",
    "                n_unique_sentences = count_unique_sentences(\n",
    "                    [example[\"text\"] for example in samples])\n",
    "\n",
    "                iterations_n_unique_tokens.append(n_unique_tokens)\n",
    "                iterations_n_lemmas.append(n_unique_lemmas)\n",
    "                iterations_avg_unique_sentences.append(n_unique_sentences)\n",
    "\n",
    "            llm_print = \"\\multirow{6}{*}{\" + \\\n",
    "                LLMS_ENCODED[llm] + \\\n",
    "                \"}\" if idx_sample == 0 and idx_fsc == 0 else \"\"\n",
    "            fs_condition_print = \"\\multirow{3}{*}{\" + \\\n",
    "                ENCODE_CONDITION[few_shot_condition] + \\\n",
    "                \"}\" if idx_sample == 0 else \"\"\n",
    "\n",
    "            print(llm_print, \"&\", fs_condition_print, \"&\", add_thousand_dots(str(n_sample)), \"&\",\n",
    "                  add_thousand_dots(\n",
    "                      round_number(np.mean(iterations_avg_unique_sentences), 0)), \"&\",\n",
    "                  add_thousand_dots(\n",
    "                      round_number(np.mean(iterations_n_unique_tokens), 0)), \"&\",\n",
    "                  add_thousand_dots(round_number(np.mean(iterations_n_lemmas), 0)), \"\\\\\\\\\")\n",
    "        if idx_fsc == 0:\n",
    "            print(\"\\\\arrayrulecolor{gray}\\cline{2-6}\\\\arrayrulecolor{black}\")\n",
    "        else:\n",
    "            print(\"\\\\hline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T07:24:06.458404Z",
     "iopub.status.busy": "2024-02-28T07:24:06.457474Z",
     "iopub.status.idle": "2024-02-28T07:24:06.465064Z",
     "shell.execute_reply": "2024-02-28T07:24:06.464011Z"
    }
   },
   "outputs": [],
   "source": [
    "# for idx_llm, llm in enumerate(LLMS):\n",
    "#     for idx_fsc, few_shot_condition in enumerate(FS_CONDITIONS):\n",
    "#         for idx_sample, n_sample in enumerate([500, 1000, 1500]):\n",
    "#             iterations_avg_unique_words_in_k_words = []\n",
    "#             iterations_avg_levenshtein_distance = []\n",
    "#             iterations_avg_levenshtein_distance_norm = []\n",
    "#             for it in range(6):\n",
    "#                 samples = [item for k in range(\n",
    "#                     int(n_sample / 500)) for item in dataset[\"synth\"][llm][few_shot_condition][it][k]]\n",
    "#                 n_unique_words_in_k_words = get_avg_unique_words_in_k_words(\n",
    "#                     [token.text for example in samples for token in example[\"tokenized_text\"]])\n",
    "#                 avg_levenshtein_distance = average_word_level_levenshtein_distance(\n",
    "#                     samples)\n",
    "#                 avg_levenshtein_distance_norm = average_word_level_levenshtein_distance(\n",
    "#                     samples, norm=True)\n",
    "\n",
    "#                 iterations_avg_unique_words_in_k_words.append(\n",
    "#                     n_unique_words_in_k_words)\n",
    "#                 iterations_avg_levenshtein_distance.append(\n",
    "#                     avg_levenshtein_distance)\n",
    "#                 iterations_avg_levenshtein_distance_norm.append(\n",
    "#                     avg_levenshtein_distance_norm)\n",
    "                \n",
    "#             llm_print = \"\\multirow{6}{*}{\" + \\\n",
    "#                 LLMS_ENCODED[llm] + \\\n",
    "#                 \"}\" if idx_sample == 0 and idx_fsc == 0 else \"\"\n",
    "#             fs_condition_print = \"\\multirow{3}{*}{\" + \\\n",
    "#                 ENCODE_CONDITION[few_shot_condition] + \\\n",
    "#                 \"}\" if idx_sample == 0 else \"\"\n",
    "\n",
    "#             print(llm_print, \"&\", fs_condition_print, \"&\", add_thousand_dots(n_sample), \"&\",\n",
    "#                   add_thousand_dots(round_number(np.mean(iterations_avg_unique_words_in_k_words), 2)), \"&\",\n",
    "#                   add_thousand_dots(round_number(np.mean(iterations_avg_levenshtein_distance), 2)), \"&\",\n",
    "#                   add_thousand_dots(round_number(np.mean(iterations_avg_levenshtein_distance_norm), 2)))\n",
    "        \n",
    "#         if idx_fsc == 0:\n",
    "#             print(\"\\\\arrayrulecolor{gray}\\cline{2-6}\\\\arrayrulecolor{black}\")\n",
    "#         else:\n",
    "#             print(\"\\\\hline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Real Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T07:24:06.469822Z",
     "iopub.status.busy": "2024-02-28T07:24:06.469425Z",
     "iopub.status.idle": "2024-02-28T07:24:08.463212Z",
     "shell.execute_reply": "2024-02-28T07:24:08.462807Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\multirow{3}{*}{\\textbf{Real Examples}} & \\multirow{3}{*}{-} & 500 & 497 & 1,918 & 1,493 \\\\\n",
      " &  & 1,000 & 990 & 3,061 & 2,349 \\\\\n",
      " &  & 1,500 & 1,481 & 3,996 & 3,038 \\\\\n",
      "\\hline\n"
     ]
    }
   ],
   "source": [
    "for idx_sample, n_sample in enumerate([500, 1000, 1500]):\n",
    "    iterations_n_unique_tokens = []\n",
    "    iterations_n_lemmas = []\n",
    "    iterations_avg_unique_sentences = []\n",
    "\n",
    "    for it in range(6):\n",
    "        samples = [item for k in range(\n",
    "            int(n_sample / 500)) for item in dataset[\"real\"][it][k]]\n",
    "        n_unique_tokens = count_unique_tokens(\n",
    "            [token for example in samples for token in example[\"tokenized_text\"]])\n",
    "        n_unique_lemmas = count_unique_lemmas(\n",
    "            [token for example in samples for token in example[\"tokenized_text\"]])\n",
    "        n_unique_sentences = count_unique_sentences(\n",
    "            [example[\"text\"] for example in samples])\n",
    "\n",
    "        iterations_n_unique_tokens.append(n_unique_tokens)\n",
    "        iterations_n_lemmas.append(n_unique_lemmas)\n",
    "        iterations_avg_unique_sentences.append(n_unique_sentences)\n",
    "\n",
    "    data_source_print = \"\\multirow{3}{*}{\\\\textbf{Real Examples}}\" if idx_sample == 0 else \"\"\n",
    "\n",
    "    fs_condition_print = \"\\multirow{3}{*}{-}\" if idx_sample == 0 else \"\"\n",
    "\n",
    "    print(data_source_print, \"&\", fs_condition_print, \"&\", add_thousand_dots(str(n_sample)), \"&\",\n",
    "          add_thousand_dots(round_number(np.mean(iterations_avg_unique_sentences), 0)), \"&\",\n",
    "          add_thousand_dots(round_number(np.mean(iterations_n_unique_tokens), 0)), \"&\",\n",
    "          add_thousand_dots(round_number(np.mean(iterations_n_lemmas), 0)), \"\\\\\\\\\")\n",
    "print(\"\\\\hline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T07:24:08.466760Z",
     "iopub.status.busy": "2024-02-28T07:24:08.466623Z",
     "iopub.status.idle": "2024-02-28T07:24:08.469913Z",
     "shell.execute_reply": "2024-02-28T07:24:08.469112Z"
    }
   },
   "outputs": [],
   "source": [
    "# for idx_sample, n_sample in enumerate([500, 1000, 1500]):\n",
    "#     iterations_avg_unique_words_in_k_words = []\n",
    "#     iterations_avg_levenshtein_distance = []\n",
    "#     iterations_avg_levenshtein_distance_norm = []\n",
    "#     for it in range(6):\n",
    "#         samples = [item for k in range(\n",
    "#             int(n_sample / 500)) for item in dataset[\"real\"][it][k]]\n",
    "\n",
    "#         n_unique_words_in_k_words = get_avg_unique_words_in_k_words(\n",
    "#             [token.text for example in samples for token in example[\"tokenized_text\"]])\n",
    "#         avg_levenshtein_distance = average_word_level_levenshtein_distance(\n",
    "#             samples)\n",
    "#         avg_levenshtein_distance_norm = average_word_level_levenshtein_distance(\n",
    "#             samples, norm=True)\n",
    "\n",
    "#         iterations_avg_unique_words_in_k_words.append(\n",
    "#             n_unique_words_in_k_words)\n",
    "#         iterations_avg_levenshtein_distance.append(\n",
    "#             avg_levenshtein_distance)\n",
    "#         iterations_avg_levenshtein_distance_norm.append(\n",
    "#             avg_levenshtein_distance_norm)\n",
    "        \n",
    "#     data_source_print = \"\\multirow{3}{*}{\\\\textbf{Real Examples}}\" if idx_sample == 0 else \"\"\n",
    "#     fs_condition_print = \"\\multirow{3}{*}{-}\" if idx_sample == 0 else \"\"\n",
    "\n",
    "#     print(data_source_print, \"&\", fs_condition_print, \"&\", add_thousand_dots(n_sample), \"&\",\n",
    "#           add_thousand_dots(\n",
    "#               round_number(np.mean(iterations_avg_unique_words_in_k_words), 2)), \"&\",\n",
    "#           add_thousand_dots(\n",
    "#               round_number(np.mean(iterations_avg_levenshtein_distance), 2)), \"&\",\n",
    "#           add_thousand_dots(round_number(np.mean(iterations_avg_levenshtein_distance_norm), 2)), \"\\\\\\\\\")\n",
    "# print(\"\\\\hline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aspect Term Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T07:24:08.472719Z",
     "iopub.status.busy": "2024-02-28T07:24:08.472102Z",
     "iopub.status.idle": "2024-02-28T07:24:08.477037Z",
     "shell.execute_reply": "2024-02-28T07:24:08.476301Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_k_unique_at(unique_counts, max_count):\n",
    "    if None in unique_counts:\n",
    "        return \"-\"\n",
    "    return add_thousand_dots(round_number(np.mean(unique_counts), 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T07:24:08.479977Z",
     "iopub.status.busy": "2024-02-28T07:24:08.479603Z",
     "iopub.status.idle": "2024-02-28T13:34:31.445212Z",
     "shell.execute_reply": "2024-02-28T13:34:31.444625Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\multirow{6}{*}{\\textbf{Llama-2-70B}} & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{25}}} & 500 & 797 & 28.5\\pm4.73\\% & 570 & 107.7 & 34.8 & 54.0 & 98.9 & - \\\\\n",
      " &  & 1,000 & 1,592 & 29.1\\pm4.93\\% & 1,128 & 176.2 & 34.9 & 54.4 & 100.6 & 162.7 \\\\\n",
      " &  & 1,500 & 2,388 & 29.3\\pm4.92\\% & 1,688 & 229.3 & 34.5 & 53.5 & 98.7 & 159.7 \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-11}\\arrayrulecolor{black}\n",
      " & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{500}}} & 500 & 703 & 26.3\\pm1.94\\% & 518 & 115.2 & 37.5 & 59.7 & - & - \\\\\n",
      " &  & 1,000 & 1,406 & 26.2\\pm1.62\\% & 1,037 & 193.0 & 38.5 & 61.6 & 116.1 & - \\\\\n",
      " &  & 1,500 & 2,106 & 26.5\\pm1.05\\% & 1,548 & 254.0 & 38.4 & 61.2 & 115.3 & 187.2 \\\\\n",
      "\\hline\n",
      "\\multirow{6}{*}{\\textbf{GPT-3.5-turbo}} & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{25}}} & 500 & 797 & 36.4\\pm8.90\\% & 506 & 40.5 & 18.6 & 25.8 & - & - \\\\\n",
      " &  & 1,000 & 1,592 & 36.5\\pm9.02\\% & 1,011 & 52.3 & 18.3 & 25.0 & 38.1 & - \\\\\n",
      " &  & 1,500 & 2,388 & 36.4\\pm8.56\\% & 1,518 & 64.5 & 18.1 & 24.9 & 38.3 & 53.1 \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-11}\\arrayrulecolor{black}\n",
      " & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{500}}} & 500 & 703 & 44.8\\pm3.59\\% & 388 & 32.0 & 17.8 & 23.9 & - & - \\\\\n",
      " &  & 1,000 & 1,406 & 44.7\\pm2.68\\% & 778 & 43.0 & 17.5 & 23.5 & 35.1 & - \\\\\n",
      " &  & 1,500 & 2,106 & 44.1\\pm2.38\\% & 1,177 & 52.7 & 17.4 & 23.5 & 35.2 & 48.7 \\\\\n",
      "\\hline\n"
     ]
    }
   ],
   "source": [
    "for idx_llm, llm in enumerate(LLMS):\n",
    "    for idx_fsc, few_shot_condition in enumerate(FS_CONDITIONS):\n",
    "        for idx_sample, n_sample in enumerate([500, 1000, 1500]):\n",
    "            tags_from_splits_count = []\n",
    "            tags_from_splits_count_implicit = []\n",
    "            tags_from_splits_count_explicit = []\n",
    "            count_unique_aspect_terms_in_split = []\n",
    "            count_unique_aspect_terms_in_100_aspect_terms = []\n",
    "            count_unique_aspect_terms_in_200_aspect_terms = []\n",
    "            count_unique_aspect_terms_in_500_aspect_terms = []\n",
    "            count_unique_aspect_terms_in_1000_aspect_terms = []\n",
    "\n",
    "            for it in range(6):\n",
    "                tags = [tag for k in range(\n",
    "                    int(n_sample / 500)) for example in dataset[\"synth\"][llm][few_shot_condition][it][k] for tag in example[\"tags\"]]\n",
    "                tags_explicit = [tag[\"text\"]\n",
    "                                 for tag in tags if tag[\"type\"] == \"label-explicit\"]\n",
    "                tags_from_splits_count.append(len(tags))\n",
    "                tags_from_splits_count_explicit.append(\n",
    "                    len([tag for tag in tags if tag[\"type\"] == \"label-explicit\"]))\n",
    "                tags_from_splits_count_implicit.append(\n",
    "                    len([tag for tag in tags if tag[\"type\"] == \"label-implicit\"]))\n",
    "\n",
    "                unique_tags = len(set(tags_explicit))\n",
    "\n",
    "                # Calculate number of unique tokens in k aspect terms\n",
    "                count_unique_aspect_terms_in_100_aspect_terms.append(\n",
    "                    get_avg_unique_words_in_k_words(tags_explicit, n_selection=100))\n",
    "                count_unique_aspect_terms_in_200_aspect_terms.append(\n",
    "                    get_avg_unique_words_in_k_words(tags_explicit, n_selection=200))\n",
    "                if len(tags_explicit) >= 500:\n",
    "                    count_unique_aspect_terms_in_500_aspect_terms.append(\n",
    "                        get_avg_unique_words_in_k_words(tags_explicit, n_selection=500))\n",
    "                else:\n",
    "                    count_unique_aspect_terms_in_500_aspect_terms.append(None)\n",
    "\n",
    "                if len(tags_explicit) >= 1000:\n",
    "                    count_unique_aspect_terms_in_1000_aspect_terms.append(\n",
    "                        get_avg_unique_words_in_k_words(tags_explicit, n_selection=1000))\n",
    "                else:\n",
    "                    count_unique_aspect_terms_in_1000_aspect_terms.append(None)\n",
    "\n",
    "                count_unique_aspect_terms_in_split.append(unique_tags)\n",
    "\n",
    "            llm_print = \"\\multirow{6}{*}{\" + \\\n",
    "                LLMS_ENCODED[llm] + \\\n",
    "                \"}\" if idx_sample == 0 and idx_fsc == 0 else \"\"\n",
    "            fs_condition_print = \"\\multirow{3}{*}{\" + \\\n",
    "                ENCODE_CONDITION[few_shot_condition] + \\\n",
    "                \"}\" if idx_sample == 0 else \"\"\n",
    "\n",
    "            print(llm_print, \"&\", fs_condition_print,\n",
    "                  \"&\", add_thousand_dots(str(n_sample)),  # n samples\n",
    "                  \"&\", add_thousand_dots(\n",
    "                      round_number(np.mean(tags_from_splits_count), 0)),  # n aspects\n",
    "                  \"&\", add_thousand_dots(\n",
    "                      round_number(np.mean(tags_from_splits_count_implicit) / np.mean(tags_from_splits_count) * 100, 1)) + \"\\\\pm\" + add_thousand_dots(round_number(np.std([a / b * 100 for a, b in zip(\n",
    "                      tags_from_splits_count_implicit, tags_from_splits_count)]), 2)) + \"\\\\%\",\n",
    "                  \"&\", add_thousand_dots(\n",
    "                      round_number(np.mean(tags_from_splits_count_explicit), 0)),  # n aspects\n",
    "                  \"&\", add_thousand_dots(\n",
    "                      round_number(np.mean(count_unique_aspect_terms_in_split), 1)),  # n unique\n",
    "                  \"&\", add_thousand_dots(\n",
    "                      round_number(np.mean(count_unique_aspect_terms_in_100_aspect_terms), 1)),\n",
    "                  \"&\", add_thousand_dots(\n",
    "                      round_number(np.mean(count_unique_aspect_terms_in_200_aspect_terms), 1)),\n",
    "                  \"&\",\n",
    "                  print_k_unique_at(\n",
    "                      count_unique_aspect_terms_in_500_aspect_terms, 500),\n",
    "                  \"&\",\n",
    "                  print_k_unique_at(\n",
    "                      count_unique_aspect_terms_in_1000_aspect_terms, 1000),\n",
    "                  \"\\\\\\\\\")\n",
    "\n",
    "        if idx_fsc == 0:\n",
    "            print(\"\\\\arrayrulecolor{gray}\\cline{2-11}\\\\arrayrulecolor{black}\")\n",
    "        else:\n",
    "            print(\"\\\\hline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T13:34:31.449041Z",
     "iopub.status.busy": "2024-02-28T13:34:31.448903Z",
     "iopub.status.idle": "2024-02-28T15:15:39.473417Z",
     "shell.execute_reply": "2024-02-28T15:15:39.472835Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\multirow{3}{*}{\\textbf{Real Examples}} & \\multirow{3}{*}{-} & 500 & 702 & 26.8\\pm1.30\\% & 513.50 & 254.7 & 68.0 & 120.0 & - & - \\\\\n",
      " &  & 1,000 & 1,404 & 26.8\\pm0.67\\% & 1,027.00 & 437.0 & 68.0 & 119.9 & 249.1 & - \\\\\n",
      " &  & 1,500 & 2,106 & 26.8\\pm0.19\\% & 1,540.50 & 595.7 & 68.0 & 120.0 & 249.3 & 427.8 \\\\\n",
      "\\hline\n"
     ]
    }
   ],
   "source": [
    "for idx_sample, n_sample in enumerate([500, 1000, 1500]):\n",
    "    tags_from_splits_count = []\n",
    "    tags_from_splits_count_implicit = []\n",
    "    tags_from_splits_count_explicit = []\n",
    "    count_unique_aspect_terms_in_split = []\n",
    "    count_unique_aspect_terms_in_100_aspect_terms = []\n",
    "    count_unique_aspect_terms_in_200_aspect_terms = []\n",
    "    count_unique_aspect_terms_in_500_aspect_terms = []\n",
    "    count_unique_aspect_terms_in_1000_aspect_terms = []\n",
    "\n",
    "    for it in range(6):\n",
    "        tags = [tag for k in range(int(n_sample / 500))\n",
    "                for example in dataset[\"real\"][it][k] for tag in example[\"tags\"]]\n",
    "        tags_explicit = [tag[\"text\"]\n",
    "                         for tag in tags if tag[\"type\"] == \"label-explicit\"]\n",
    "        tags_from_splits_count.append(len(tags))\n",
    "        tags_from_splits_count_explicit.append(\n",
    "            len([tag for tag in tags if tag[\"type\"] == \"label-explicit\"]))\n",
    "        tags_from_splits_count_implicit.append(\n",
    "            len([tag for tag in tags if tag[\"type\"] == \"label-implicit\"]))\n",
    "\n",
    "        unique_tags = len(set(tags_explicit))\n",
    "\n",
    "        # Calculate number of unique tokens in k aspect terms\n",
    "        count_unique_aspect_terms_in_100_aspect_terms.append(\n",
    "            get_avg_unique_words_in_k_words(tags_explicit, n_selection=100))\n",
    "        count_unique_aspect_terms_in_200_aspect_terms.append(\n",
    "            get_avg_unique_words_in_k_words(tags_explicit, n_selection=200))\n",
    "        if len(tags_explicit) >= 500:\n",
    "            count_unique_aspect_terms_in_500_aspect_terms.append(\n",
    "                get_avg_unique_words_in_k_words(tags_explicit, n_selection=500))\n",
    "        else:\n",
    "            count_unique_aspect_terms_in_500_aspect_terms.append(None)\n",
    "\n",
    "        if len(tags_explicit) >= 1000:\n",
    "            count_unique_aspect_terms_in_1000_aspect_terms.append(\n",
    "                get_avg_unique_words_in_k_words(tags_explicit, n_selection=1000))\n",
    "        else:\n",
    "            count_unique_aspect_terms_in_1000_aspect_terms.append(None)\n",
    "\n",
    "        count_unique_aspect_terms_in_split.append(unique_tags)\n",
    "\n",
    "    data_source_print = \"\\multirow{3}{*}{\\\\textbf{Real Examples}}\" if idx_sample == 0 else \"\"\n",
    "    fs_condition_print = \"\\multirow{3}{*}{-}\" if idx_sample == 0 else \"\"\n",
    "\n",
    "    print(data_source_print, \"&\", fs_condition_print,\n",
    "          \"&\", add_thousand_dots(str(n_sample)),  # n samples\n",
    "          \"&\", add_thousand_dots(\n",
    "              round_number(np.mean(tags_from_splits_count), 0)),  # n aspects\n",
    "          \"&\", add_thousand_dots(\n",
    "              round_number(np.mean(tags_from_splits_count_implicit) / np.mean(tags_from_splits_count) * 100, 1)) + \"\\\\pm\" + add_thousand_dots(round_number(np.std([a / b * 100 for a, b in zip(\n",
    "              tags_from_splits_count_implicit, tags_from_splits_count)]), 2)) + \"\\\\%\",\n",
    "          \"&\", add_thousand_dots(\n",
    "              round_number(np.mean(tags_from_splits_count_explicit), 2)),  # n aspects explicit\n",
    "          \"&\", add_thousand_dots(\n",
    "              round_number(np.mean(count_unique_aspect_terms_in_split), 1)),  # n unique\n",
    "          \"&\", add_thousand_dots(\n",
    "              round_number(np.mean(count_unique_aspect_terms_in_100_aspect_terms), 1)),\n",
    "          \"&\", add_thousand_dots(\n",
    "              round_number(np.mean(count_unique_aspect_terms_in_200_aspect_terms), 1)),\n",
    "          \"&\", print_k_unique_at(\n",
    "              count_unique_aspect_terms_in_500_aspect_terms, 500),\n",
    "          \"&\", print_k_unique_at(\n",
    "              count_unique_aspect_terms_in_1000_aspect_terms, 1000), \"\\\\\\\\\")\n",
    "print(\"\\\\hline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aspect Term Analysis (With Aspect Category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synth Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T15:15:39.477384Z",
     "iopub.status.busy": "2024-02-28T15:15:39.477247Z",
     "iopub.status.idle": "2024-02-28T15:15:39.480396Z",
     "shell.execute_reply": "2024-02-28T15:15:39.479859Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_k_unique_at(unique_counts, max_count):\n",
    "    if None in unique_counts:\n",
    "        return \"-\"\n",
    "    return add_thousand_dots(round_number(np.mean(unique_counts), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T15:15:39.483261Z",
     "iopub.status.busy": "2024-02-28T15:15:39.483060Z",
     "iopub.status.idle": "2024-02-28T21:59:30.180848Z",
     "shell.execute_reply": "2024-02-28T21:59:30.180249Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\multirow{30}{*}{\\textbf{\\textbf{Llama-2-70B}}} & \\multirow{15}{*}{\\textbf{LRS\\textsubscript{25}}} & \\multirow{3}{*}{\\texttt{GENERAL-IMPRESSION}} & 500 & 159.7 & 45.9\\pm5.51\\% & 86.3 & 33.83 & 7.4 & 23.4 & - & - & - \\\\\n",
      " &  &  & 1,000 & 319.8 & 46.9\\pm5.62\\% & 169.8 & 56.00 & 7.5 & 23.8 & 38.7 & - & - \\\\\n",
      " &  &  & 1,500 & 479.0 & 45.5\\pm6.58\\% & 261.2 & 77.00 & 7.5 & 23.7 & 38.5 & 63.7 & - \\\\\n",
      "\\arrayrulecolor{gray}\\cline{3-13}\\arrayrulecolor{black}\n",
      " &  & \\multirow{3}{*}{\\texttt{FOOD}} & 500 & 158.7 & 22.0\\pm4.79\\% & 123.8 & 34.33 & 5.5 & 17.8 & 29.5 & - & - \\\\\n",
      " &  &  & 1,000 & 318.5 & 24.1\\pm5.98\\% & 241.7 & 57.00 & 5.4 & 18.0 & 30.0 & 49.8 & - \\\\\n",
      " &  &  & 1,500 & 478.0 & 25.0\\pm5.78\\% & 358.7 & 72.00 & 5.4 & 17.5 & 29.0 & 47.8 & 63.7 \\\\\n",
      "\\arrayrulecolor{gray}\\cline{3-13}\\arrayrulecolor{black}\n",
      " &  & \\multirow{3}{*}{\\texttt{SERVICE}} & 500 & 160.7 & 21.1\\pm7.31\\% & 126.8 & 18.00 & 4.6 & 10.2 & 15.5 & - & - \\\\\n",
      " &  &  & 1,000 & 318.5 & 20.9\\pm6.23\\% & 251.8 & 27.00 & 4.6 & 10.3 & 15.3 & 23.4 & - \\\\\n",
      " &  &  & 1,500 & 477.0 & 21.2\\pm5.32\\% & 376.0 & 34.67 & 4.6 & 10.3 & 15.2 & 23.1 & 30.1 \\\\\n",
      "\\arrayrulecolor{gray}\\cline{3-13}\\arrayrulecolor{black}\n",
      " &  & \\multirow{3}{*}{\\texttt{AMBIENCE}} & 500 & 159.8 & 21.9\\pm4.25\\% & 124.8 & 26.00 & 4.7 & 13.5 & 22.2 & - & - \\\\\n",
      " &  &  & 1,000 & 317.2 & 21.7\\pm5.12\\% & 248.5 & 41.83 & 4.6 & 13.1 & 21.6 & 35.9 & - \\\\\n",
      " &  &  & 1,500 & 477.0 & 23.1\\pm4.88\\% & 366.8 & 54.83 & 4.6 & 13.1 & 21.6 & 35.6 & 47.5 \\\\\n",
      "\\arrayrulecolor{gray}\\cline{3-13}\\arrayrulecolor{black}\n",
      " &  & \\multirow{3}{*}{\\texttt{PRICE}} & 500 & 158.2 & 31.5\\pm9.38\\% & 108.3 & 21.83 & 5.5 & 14.0 & - & - & - \\\\\n",
      " &  &  & 1,000 & 317.7 & 32.0\\pm7.94\\% & 216.0 & 34.67 & 5.4 & 13.8 & 21.4 & - & - \\\\\n",
      " &  &  & 1,500 & 477.0 & 31.9\\pm7.58\\% & 325.0 & 43.67 & 5.3 & 13.4 & 20.6 & 32.3 & - \\\\\n",
      "\\cline{2-13}\n",
      " & \\multirow{15}{*}{\\textbf{LRS\\textsubscript{500}}} & \\multirow{3}{*}{\\texttt{GENERAL-IMPRESSION}} & 500 & 141.7 & 49.9\\pm3.95\\% & 71.0 & 34.33 & 8.1 & 27.1 & - & - & - \\\\\n",
      " &  &  & 1,000 & 281.5 & 48.7\\pm2.24\\% & 144.3 & 55.33 & 8.0 & 26.5 & 43.0 & - & - \\\\\n",
      " &  &  & 1,500 & 422.0 & 49.6\\pm2.02\\% & 212.8 & 74.67 & 8.1 & 26.9 & 43.6 & - & - \\\\\n",
      "\\arrayrulecolor{gray}\\cline{3-13}\\arrayrulecolor{black}\n",
      " &  & \\multirow{3}{*}{\\texttt{FOOD}} & 500 & 139.3 & 20.1\\pm2.14\\% & 111.3 & 32.67 & 5.6 & 17.9 & 30.0 & - & - \\\\\n",
      " &  &  & 1,000 & 282.2 & 21.1\\pm2.28\\% & 222.7 & 55.00 & 5.5 & 18.1 & 30.3 & 50.8 & - \\\\\n",
      " &  &  & 1,500 & 422.0 & 21.2\\pm1.65\\% & 332.5 & 75.83 & 5.5 & 18.3 & 30.7 & 51.9 & 70.3 \\\\\n",
      "\\arrayrulecolor{gray}\\cline{3-13}\\arrayrulecolor{black}\n",
      " &  & \\multirow{3}{*}{\\texttt{SERVICE}} & 500 & 141.0 & 18.1\\pm4.95\\% & 115.5 & 18.83 & 5.0 & 11.7 & 17.4 & - & - \\\\\n",
      " &  &  & 1,000 & 281.0 & 17.4\\pm2.79\\% & 232.2 & 29.67 & 5.0 & 11.9 & 17.7 & 27.0 & - \\\\\n",
      " &  &  & 1,500 & 421.0 & 17.9\\pm2.20\\% & 345.8 & 40.00 & 5.1 & 12.0 & 17.9 & 27.6 & 36.2 \\\\\n",
      "\\arrayrulecolor{gray}\\cline{3-13}\\arrayrulecolor{black}\n",
      " &  & \\multirow{3}{*}{\\texttt{AMBIENCE}} & 500 & 140.7 & 17.5\\pm4.17\\% & 116.0 & 26.17 & 4.6 & 13.9 & 23.5 & - & - \\\\\n",
      " &  &  & 1,000 & 280.3 & 17.2\\pm2.85\\% & 232.0 & 47.50 & 4.9 & 15.2 & 25.8 & 42.8 & - \\\\\n",
      " &  &  & 1,500 & 420.5 & 17.3\\pm2.41\\% & 347.7 & 62.50 & 4.8 & 14.9 & 25.3 & 42.3 & 56.3 \\\\\n",
      "\\arrayrulecolor{gray}\\cline{3-13}\\arrayrulecolor{black}\n",
      " &  & \\multirow{3}{*}{\\texttt{PRICE}} & 500 & 140.5 & 25.6\\pm5.41\\% & 104.5 & 23.83 & 5.4 & 14.6 & - & - & - \\\\\n",
      " &  &  & 1,000 & 281.0 & 26.6\\pm3.95\\% & 206.2 & 38.83 & 5.6 & 15.3 & 23.9 & - & - \\\\\n",
      " &  &  & 1,500 & 420.0 & 26.4\\pm3.49\\% & 309.2 & 47.33 & 5.5 & 14.7 & 22.8 & 35.6 & - \\\\\n",
      "\\hline\n",
      "\\multirow{30}{*}{\\textbf{\\textbf{GPT-3.5-turbo}}} & \\multirow{15}{*}{\\textbf{LRS\\textsubscript{25}}} & \\multirow{3}{*}{\\texttt{GENERAL-IMPRESSION}} & 500 & 159.7 & 72.8\\pm11.95\\% & 43.5 & 12.17 & 5.3 & - & - & - & - \\\\\n",
      " &  &  & 1,000 & 319.8 & 73.4\\pm11.73\\% & 85.2 & 17.33 & 5.3 & - & - & - & - \\\\\n",
      " &  &  & 1,500 & 479.0 & 73.7\\pm11.91\\% & 126.0 & 21.50 & 5.4 & 13.6 & - & - & - \\\\\n",
      "\\arrayrulecolor{gray}\\cline{3-13}\\arrayrulecolor{black}\n",
      " &  & \\multirow{3}{*}{\\texttt{FOOD}} & 500 & 158.7 & 26.2\\pm9.97\\% & 117.2 & 12.67 & 2.7 & 7.4 & 11.6 & - & - \\\\\n",
      " &  &  & 1,000 & 318.5 & 26.4\\pm9.55\\% & 234.3 & 17.50 & 2.7 & 7.4 & 11.2 & 16.2 & - \\\\\n",
      " &  &  & 1,500 & 478.0 & 25.8\\pm8.97\\% & 354.5 & 22.33 & 2.6 & 7.3 & 11.2 & 16.6 & - \\\\\n",
      "\\arrayrulecolor{gray}\\cline{3-13}\\arrayrulecolor{black}\n",
      " &  & \\multirow{3}{*}{\\texttt{SERVICE}} & 500 & 160.7 & 25.1\\pm12.52\\% & 120.3 & 4.50 & 1.9 & 3.4 & - & - & - \\\\\n",
      " &  &  & 1,000 & 318.5 & 23.3\\pm10.52\\% & 244.3 & 6.00 & 2.1 & 3.6 & 4.5 & - & - \\\\\n",
      " &  &  & 1,500 & 477.0 & 22.5\\pm9.62\\% & 369.8 & 7.50 & 2.1 & 3.6 & 4.5 & 5.8 & - \\\\\n",
      "\\arrayrulecolor{gray}\\cline{3-13}\\arrayrulecolor{black}\n",
      " &  & \\multirow{3}{*}{\\texttt{AMBIENCE}} & 500 & 159.8 & 22.6\\pm8.93\\% & 123.7 & 10.83 & 3.7 & 7.2 & 9.8 & - & - \\\\\n",
      " &  &  & 1,000 & 317.2 & 23.8\\pm9.55\\% & 241.7 & 13.00 & 3.6 & 6.6 & 8.7 & 11.9 & - \\\\\n",
      " &  &  & 1,500 & 477.0 & 23.9\\pm8.73\\% & 363.0 & 16.17 & 3.5 & 6.5 & 8.7 & 12.1 & 14.7 \\\\\n",
      "\\arrayrulecolor{gray}\\cline{3-13}\\arrayrulecolor{black}\n",
      " &  & \\multirow{3}{*}{\\texttt{PRICE}} & 500 & 158.2 & 35.6\\pm14.24\\% & 101.8 & 6.83 & 2.7 & 5.3 & - & - & - \\\\\n",
      " &  &  & 1,000 & 317.7 & 35.4\\pm13.94\\% & 205.2 & 8.67 & 2.7 & 5.0 & 6.5 & - & - \\\\\n",
      " &  &  & 1,500 & 477.0 & 36.1\\pm13.62\\% & 304.8 & 10.17 & 2.7 & 4.9 & 6.5 & 8.9 & - \\\\\n",
      "\\cline{2-13}\n",
      " & \\multirow{15}{*}{\\textbf{LRS\\textsubscript{500}}} & \\multirow{3}{*}{\\texttt{GENERAL-IMPRESSION}} & 500 & 141.7 & 82.5\\pm4.05\\% & 24.8 & 6.83 & 4.0 & - & - & - & - \\\\\n",
      " &  &  & 1,000 & 281.5 & 82.2\\pm3.02\\% & 50.0 & 10.17 & 3.9 & - & - & - & - \\\\\n",
      " &  &  & 1,500 & 422.0 & 81.8\\pm3.07\\% & 76.8 & 13.17 & 3.9 & 10.1 & - & - & - \\\\\n",
      "\\arrayrulecolor{gray}\\cline{3-13}\\arrayrulecolor{black}\n",
      " &  & \\multirow{3}{*}{\\texttt{FOOD}} & 500 & 139.3 & 37.7\\pm2.61\\% & 86.8 & 8.33 & 2.5 & 6.2 & - & - & - \\\\\n",
      " &  &  & 1,000 & 282.2 & 36.1\\pm1.95\\% & 180.3 & 14.33 & 2.5 & 6.7 & 10.2 & - & - \\\\\n",
      " &  &  & 1,500 & 422.0 & 34.4\\pm2.11\\% & 276.7 & 18.17 & 2.5 & 6.8 & 10.4 & 15.3 & - \\\\\n",
      "\\arrayrulecolor{gray}\\cline{3-13}\\arrayrulecolor{black}\n",
      " &  & \\multirow{3}{*}{\\texttt{SERVICE}} & 500 & 141.0 & 25.4\\pm4.55\\% & 105.2 & 5.00 & 2.3 & 4.0 & - & - & - \\\\\n",
      " &  &  & 1,000 & 281.0 & 26.3\\pm2.42\\% & 207.2 & 5.50 & 2.3 & 3.8 & 4.5 & - & - \\\\\n",
      " &  &  & 1,500 & 421.0 & 26.2\\pm2.03\\% & 310.8 & 7.33 & 2.2 & 3.9 & 4.8 & 6.1 & - \\\\\n",
      "\\arrayrulecolor{gray}\\cline{3-13}\\arrayrulecolor{black}\n",
      " &  & \\multirow{3}{*}{\\texttt{AMBIENCE}} & 500 & 140.7 & 25.4\\pm7.19\\% & 105.0 & 7.67 & 3.5 & 5.8 & - & - & - \\\\\n",
      " &  &  & 1,000 & 280.3 & 25.7\\pm4.14\\% & 208.2 & 9.33 & 3.5 & 5.6 & 7.1 & - & - \\\\\n",
      " &  &  & 1,500 & 420.5 & 25.6\\pm3.13\\% & 312.7 & 11.17 & 3.5 & 5.6 & 7.0 & 9.2 & 10.9 \\\\\n",
      "\\arrayrulecolor{gray}\\cline{3-13}\\arrayrulecolor{black}\n",
      " &  & \\multirow{3}{*}{\\texttt{PRICE}} & 500 & 140.5 & 52.7\\pm8.35\\% & 66.5 & 7.67 & 3.5 & 6.7 & - & - & - \\\\\n",
      " &  &  & 1,000 & 281.0 & 52.8\\pm7.58\\% & 132.5 & 9.33 & 3.4 & 6.2 & 8.1 & - & - \\\\\n",
      " &  &  & 1,500 & 420.0 & 52.5\\pm7.25\\% & 199.7 & 11.17 & 3.4 & 6.2 & 8.1 & - & - \\\\\n",
      "\\hline\n"
     ]
    }
   ],
   "source": [
    "for idx_llm, llm in enumerate(LLMS):\n",
    "    for idx_fsc, few_shot_condition in enumerate(FS_CONDITIONS):\n",
    "        for idx_ac, aspect_category in enumerate(ASPECT_CATEGORIES):\n",
    "            for idx_sample, n_sample in enumerate([500, 1000, 1500]):\n",
    "                tags_from_splits_count = []\n",
    "                tags_from_splits_count_implicit = []\n",
    "                tags_from_splits_count_explicit = []\n",
    "                count_unique_aspect_terms_in_split = []\n",
    "                count_unique_aspect_terms_in_10_aspect_terms = []\n",
    "                count_unique_aspect_terms_in_50_aspect_terms = []\n",
    "                count_unique_aspect_terms_in_100_aspect_terms = []\n",
    "                count_unique_aspect_terms_in_200_aspect_terms = []\n",
    "                count_unique_aspect_terms_in_300_aspect_terms = []\n",
    "                for it in range(6):\n",
    "                    tags = [tag for k in range(\n",
    "                        int(n_sample / 500)) for example in dataset[\"synth\"][llm][few_shot_condition][it][k] for tag in example[\"tags\"] if tag[\"label\"] == aspect_category]\n",
    "                    tags_explicit = [tag[\"text\"]\n",
    "                                     for tag in tags if tag[\"type\"] == \"label-explicit\"]\n",
    "                    tags_from_splits_count.append(len(tags))\n",
    "                    tags_from_splits_count_explicit.append(\n",
    "                        len([tag for tag in tags if tag[\"type\"] == \"label-explicit\"]))\n",
    "                    tags_from_splits_count_implicit.append(\n",
    "                        len([tag for tag in tags if tag[\"type\"] == \"label-implicit\"]))\n",
    "\n",
    "                    unique_tags = len(set(tags_explicit))\n",
    "\n",
    "\n",
    "                    if len(tags_explicit) >= 10:\n",
    "                        count_unique_aspect_terms_in_10_aspect_terms.append(\n",
    "                            get_avg_unique_words_in_k_words(tags_explicit, n_selection=10))\n",
    "                    else:\n",
    "                        count_unique_aspect_terms_in_10_aspect_terms.append(None)\n",
    "\n",
    "                    if len(tags_explicit) >= 50:\n",
    "                        count_unique_aspect_terms_in_50_aspect_terms.append(\n",
    "                            get_avg_unique_words_in_k_words(tags_explicit, n_selection=50))\n",
    "                    else:\n",
    "                        count_unique_aspect_terms_in_50_aspect_terms.append(None)\n",
    "\n",
    "                    if len(tags_explicit) >= 100:\n",
    "                        count_unique_aspect_terms_in_100_aspect_terms.append(\n",
    "                            get_avg_unique_words_in_k_words(tags_explicit, n_selection=100))\n",
    "                    else:\n",
    "                        count_unique_aspect_terms_in_100_aspect_terms.append(None)\n",
    "\n",
    "                    if len(tags_explicit) >= 200:\n",
    "                        count_unique_aspect_terms_in_200_aspect_terms.append(\n",
    "                            get_avg_unique_words_in_k_words(tags_explicit, n_selection=200))\n",
    "                    else:\n",
    "                        count_unique_aspect_terms_in_200_aspect_terms.append(None)\n",
    "\n",
    "                    if len(tags_explicit) >= 300:\n",
    "                        count_unique_aspect_terms_in_300_aspect_terms.append(\n",
    "                            get_avg_unique_words_in_k_words(tags_explicit, n_selection=300))\n",
    "                    else:\n",
    "                        count_unique_aspect_terms_in_300_aspect_terms.append(None)                    \n",
    "\n",
    "                    count_unique_aspect_terms_in_split.append(unique_tags)\n",
    "\n",
    "                llm_print = \"\\multirow{30}{*}{\\\\textbf{\" + \\\n",
    "                    LLMS_ENCODED[llm] + \\\n",
    "                    \"}}\" if idx_sample == 0 and idx_fsc == 0 and idx_ac == 0 else \"\"\n",
    "                fs_condition_print = \"\\multirow{15}{*}{\" + \\\n",
    "                    ENCODE_CONDITION[few_shot_condition] + \\\n",
    "                    \"}\" if idx_sample == 0 and idx_ac == 0 else \"\"\n",
    "                ac_print = \"\\multirow{3}{*}{\\\\texttt{\" + \\\n",
    "                    aspect_category + \"}}\" if idx_sample == 0 else \"\"\n",
    "\n",
    "                # print(idx_llm, idx_fsc, idx_ac, idx_sample)\n",
    "\n",
    "                print(llm_print, \"&\", fs_condition_print, \"&\", ac_print,\n",
    "                      \"&\", add_thousand_dots(str(n_sample)),\n",
    "                      \"&\", add_thousand_dots(\n",
    "                          round_number(np.mean(tags_from_splits_count), 1)),\n",
    "                      \"&\", add_thousand_dots(\n",
    "                          round_number(np.mean(tags_from_splits_count_implicit) / np.mean(tags_from_splits_count) * 100, 1)) + \"\\\\pm\" + add_thousand_dots(round_number(np.std([a / b * 100 for a, b in zip(\n",
    "                          tags_from_splits_count_implicit, tags_from_splits_count)]), 2)) + \"\\\\%\",\n",
    "                      \"&\", add_thousand_dots(\n",
    "                          round_number(np.mean(tags_from_splits_count_explicit), 1)),\n",
    "                      \"&\", add_thousand_dots(round_number(\n",
    "                          np.mean(count_unique_aspect_terms_in_split), 2)),\n",
    "                      \"&\", print_k_unique_at(count_unique_aspect_terms_in_10_aspect_terms, 10), \n",
    "                      \"&\", print_k_unique_at(count_unique_aspect_terms_in_50_aspect_terms, 50),\n",
    "                      \"&\", print_k_unique_at(count_unique_aspect_terms_in_100_aspect_terms, 100),\n",
    "                      \"&\", print_k_unique_at(count_unique_aspect_terms_in_200_aspect_terms, 200),\n",
    "                      \"&\", print_k_unique_at(count_unique_aspect_terms_in_300_aspect_terms, 300), \"\\\\\\\\\")\n",
    "            # print(idx_llm, idx_fsc, idx_ac)\n",
    "            if idx_fsc == 1 and idx_ac == 4:\n",
    "                print(\"\\\\hline\")\n",
    "            elif idx_ac == 4:\n",
    "                print(\"\\\\cline{2-13}\")\n",
    "            else:\n",
    "                print(\n",
    "                    \"\\\\arrayrulecolor{gray}\\cline{3-13}\\\\arrayrulecolor{black}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T21:59:30.183367Z",
     "iopub.status.busy": "2024-02-28T21:59:30.183227Z",
     "iopub.status.idle": "2024-02-28T23:31:04.923349Z",
     "shell.execute_reply": "2024-02-28T23:31:04.922767Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\multirow{15}{*}{\\textbf{Real Examples}} & \\multirow{15}{*}{-} & \\multirow{3}{*}{\\texttt{GENERAL-IMPRESSION}} & 500 & 126.2 & 78.5\\pm2.65\\% & 27.2 & 13.83 & 6.9 & - & - & - & - \\\\\n",
      " &  &  & 1,000 & 252.3 & 78.5\\pm1.61\\% & 54.3 & 23.00 & 7.0 & 21.6 & - & - & - \\\\\n",
      " &  &  & 1,500 & 378.5 & 78.5\\pm0.89\\% & 81.5 & 31.33 & 7.0 & 21.7 & - & - & - \\\\\n",
      "\\arrayrulecolor{gray}\\cline{3-13}\\arrayrulecolor{black}\n",
      " &  & \\multirow{3}{*}{\\texttt{FOOD}} & 500 & 279.3 & 11.2\\pm1.00\\% & 248.2 & 142.50 & 8.7 & 36.6 & 66.7 & 119.1 & - \\\\\n",
      " &  &  & 1,000 & 558.7 & 11.2\\pm0.79\\% & 496.3 & 246.83 & 8.7 & 36.6 & 66.6 & 118.5 & 164.6 \\\\\n",
      " &  &  & 1,500 & 838.0 & 11.2\\pm0.58\\% & 744.5 & 338.83 & 8.7 & 36.6 & 66.6 & 118.5 & 164.4 \\\\\n",
      "\\arrayrulecolor{gray}\\cline{3-13}\\arrayrulecolor{black}\n",
      " &  & \\multirow{3}{*}{\\texttt{SERVICE}} & 500 & 175.5 & 22.3\\pm2.51\\% & 136.3 & 51.83 & 7.1 & 23.6 & 40.7 & - & - \\\\\n",
      " &  &  & 1,000 & 351.0 & 22.3\\pm1.30\\% & 272.7 & 87.17 & 7.1 & 23.5 & 40.5 & 69.1 & - \\\\\n",
      " &  &  & 1,500 & 526.5 & 22.3\\pm0.80\\% & 409.0 & 116.67 & 7.1 & 23.5 & 40.4 & 69.0 & 93.3 \\\\\n",
      "\\arrayrulecolor{gray}\\cline{3-13}\\arrayrulecolor{black}\n",
      " &  & \\multirow{3}{*}{\\texttt{AMBIENCE}} & 500 & 79.0 & 14.1\\pm2.39\\% & 67.8 & 38.33 & 7.8 & 29.8 & - & - & - \\\\\n",
      " &  &  & 1,000 & 158.0 & 14.1\\pm1.64\\% & 135.7 & 68.00 & 7.8 & 29.8 & 53.0 & - & - \\\\\n",
      " &  &  & 1,500 & 237.0 & 14.1\\pm1.09\\% & 203.5 & 94.33 & 7.8 & 29.8 & 53.0 & - & - \\\\\n",
      "\\arrayrulecolor{gray}\\cline{3-13}\\arrayrulecolor{black}\n",
      " &  & \\multirow{3}{*}{\\texttt{PRICE}} & 500 & 41.8 & 18.7\\pm7.84\\% & 34.0 & 23.00 & 8.3 & - & - & - & - \\\\\n",
      " &  &  & 1,000 & 83.7 & 18.7\\pm5.69\\% & 68.0 & 39.67 & 8.4 & 30.9 & - & - & - \\\\\n",
      " &  &  & 1,500 & 125.5 & 18.7\\pm4.44\\% & 102.0 & 54.17 & 8.4 & 30.8 & - & - & - \\\\\n",
      "\\arrayrulecolor{gray}\\cline{3-13}\\arrayrulecolor{black}\n",
      "\\hline\n"
     ]
    }
   ],
   "source": [
    "for idx_ac, aspect_category in enumerate(ASPECT_CATEGORIES):\n",
    "    for idx_sample, n_sample in enumerate([500, 1000, 1500]):\n",
    "        tags_from_splits_count = []\n",
    "        tags_from_splits_count_implicit = []\n",
    "        tags_from_splits_count_explicit = []\n",
    "        count_unique_aspect_terms_in_split = []\n",
    "        count_unique_aspect_terms_in_10_aspect_terms = []\n",
    "        count_unique_aspect_terms_in_50_aspect_terms = []\n",
    "        count_unique_aspect_terms_in_100_aspect_terms = []\n",
    "        count_unique_aspect_terms_in_200_aspect_terms = []\n",
    "        count_unique_aspect_terms_in_300_aspect_terms = []\n",
    "\n",
    "        for it in range(6):\n",
    "            tags = [tag for k in range(int(n_sample / 500))\n",
    "                    for example in dataset[\"real\"][it][k] for tag in example[\"tags\"] if tag[\"label\"] == aspect_category]\n",
    "            tags_explicit = [tag[\"text\"]\n",
    "                             for tag in tags if tag[\"type\"] == \"label-explicit\"]\n",
    "            tags_from_splits_count.append(len(tags))\n",
    "            tags_from_splits_count_explicit.append(\n",
    "                len([tag for tag in tags if tag[\"type\"] == \"label-explicit\"]))\n",
    "            tags_from_splits_count_implicit.append(\n",
    "                len([tag for tag in tags if tag[\"type\"] == \"label-implicit\"]))\n",
    "\n",
    "            unique_tags = len(set(tags_explicit))\n",
    "\n",
    "            if len(tags_explicit) >= 10:\n",
    "                count_unique_aspect_terms_in_10_aspect_terms.append(\n",
    "                    get_avg_unique_words_in_k_words(tags_explicit, n_selection=10))\n",
    "            else:\n",
    "                count_unique_aspect_terms_in_10_aspect_terms.append(None)\n",
    "\n",
    "            if len(tags_explicit) >= 50:\n",
    "                count_unique_aspect_terms_in_50_aspect_terms.append(\n",
    "                    get_avg_unique_words_in_k_words(tags_explicit, n_selection=50))\n",
    "            else:\n",
    "                count_unique_aspect_terms_in_50_aspect_terms.append(None)\n",
    "\n",
    "            if len(tags_explicit) >= 100:\n",
    "                count_unique_aspect_terms_in_100_aspect_terms.append(\n",
    "                    get_avg_unique_words_in_k_words(tags_explicit, n_selection=100))\n",
    "            else:\n",
    "                count_unique_aspect_terms_in_100_aspect_terms.append(None)\n",
    "\n",
    "            if len(tags_explicit) >= 200:\n",
    "                count_unique_aspect_terms_in_200_aspect_terms.append(\n",
    "                    get_avg_unique_words_in_k_words(tags_explicit, n_selection=200))\n",
    "            else:\n",
    "                count_unique_aspect_terms_in_200_aspect_terms.append(None)\n",
    "\n",
    "            if len(tags_explicit) >= 300:\n",
    "                count_unique_aspect_terms_in_300_aspect_terms.append(\n",
    "                    get_avg_unique_words_in_k_words(tags_explicit, n_selection=300))\n",
    "            else:\n",
    "                count_unique_aspect_terms_in_300_aspect_terms.append(None)\n",
    "\n",
    "            count_unique_aspect_terms_in_split.append(unique_tags)\n",
    "\n",
    "        # print(idx_ac, idx_sample)\n",
    "        data_source_print = \"\\multirow{15}{*}{\\\\textbf{Real Examples}}\" if idx_sample == 0 and idx_ac == 0 else \"\"\n",
    "        fs_condition_print = \"\\multirow{15}{*}{-}\" if idx_sample == 0 and idx_ac == 0 else \"\"\n",
    "        ac_print = \"\\multirow{3}{*}{\\\\texttt{\" + \\\n",
    "            aspect_category + \"}}\" if idx_sample == 0 else \"\"\n",
    "\n",
    "        print(data_source_print, \"&\", fs_condition_print, \"&\", ac_print,\n",
    "              \"&\", add_thousand_dots(str(n_sample)),\n",
    "              \"&\", add_thousand_dots(\n",
    "                  round_number(np.mean(tags_from_splits_count), 1)),\n",
    "              \"&\", add_thousand_dots(\n",
    "                  round_number(np.mean(tags_from_splits_count_implicit) / np.mean(tags_from_splits_count) * 100, 1)) + \"\\\\pm\" + add_thousand_dots(round_number(np.std([a / b * 100 for a, b in zip(\n",
    "                  tags_from_splits_count_implicit, tags_from_splits_count)]), 2)) + \"\\\\%\",\n",
    "              \"&\", add_thousand_dots(\n",
    "                  round_number(np.mean(tags_from_splits_count_explicit), 1)),\n",
    "              \"&\", add_thousand_dots(round_number(\n",
    "                  np.mean(count_unique_aspect_terms_in_split), 2)),\n",
    "              \"&\", print_k_unique_at(\n",
    "                  count_unique_aspect_terms_in_10_aspect_terms, 10),\n",
    "              \"&\", print_k_unique_at(\n",
    "                  count_unique_aspect_terms_in_50_aspect_terms, 50),\n",
    "              \"&\", print_k_unique_at(\n",
    "                  count_unique_aspect_terms_in_100_aspect_terms, 100),\n",
    "              \"&\", print_k_unique_at(\n",
    "                  count_unique_aspect_terms_in_200_aspect_terms, 200),\n",
    "              \"&\", print_k_unique_at(count_unique_aspect_terms_in_300_aspect_terms, 300), \"\\\\\\\\\")\n",
    "    print(\"\\\\arrayrulecolor{gray}\\cline{3-13}\\\\arrayrulecolor{black}\")\n",
    "print(\"\\\\hline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
