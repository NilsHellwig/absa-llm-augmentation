{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "aspect_categories_array = np.load('aspect_categories.npy')\n",
    "predictions_array = np.load('predictions.npy')\n",
    "true_labels_array = np.load('true_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import constants\n",
    "from OTE.evaluation import compute_metrics_for_subset, compute_popular_metrics\n",
    "\n",
    "\n",
    "def calculate_f1_micro(metrics):\n",
    "    tp_total = sum([metrics[f\"tp_{ac}\"] for ac in constants.ASPECT_CATEGORIES])\n",
    "    fp_total = sum([metrics[f\"fp_{ac}\"] for ac in constants.ASPECT_CATEGORIES])\n",
    "    fn_total = sum([metrics[f\"fn_{ac}\"] for ac in constants.ASPECT_CATEGORIES])\n",
    "    precision_total = tp_total / (tp_total + fp_total)\n",
    "    recall_total = tp_total / (tp_total + fn_total)\n",
    "\n",
    "    return 2 * (precision_total * recall_total) / (precision_total + recall_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics():\n",
    "    aspect_categories = aspect_categories_array\n",
    "    predictions = predictions_array\n",
    "    true_labels = true_labels_array\n",
    "\n",
    "    metrics = {}\n",
    "\n",
    "    for ac in constants.ASPECT_CATEGORIES:\n",
    "        # Select all examples of a given aspect category\n",
    "        ac_predictions = np.array([predictions[i] for i in range(\n",
    "            len(predictions)) if aspect_categories[i] == ac])\n",
    "        ac_predictions = (ac_predictions == ac_predictions.max(\n",
    "            axis=2)[:, :, np.newaxis]).astype(int)\n",
    "\n",
    "        ac_labels = np.array([true_labels[i] for i in range(\n",
    "            len(true_labels)) if aspect_categories[i] == ac])\n",
    "\n",
    "        tp, tn, fp, fn = compute_metrics_for_subset(\n",
    "            ac_predictions, ac_labels)\n",
    "\n",
    "        precision, recall, f1 = compute_popular_metrics(tp, tn, fp, fn)\n",
    "        metrics[f\"f1_{ac}\"] = f1\n",
    "        metrics[f\"precision_{ac}\"] = precision\n",
    "        metrics[f\"recall_{ac}\"] = recall\n",
    "        metrics[f\"tp_{ac}\"] = tp\n",
    "        metrics[f\"tn_{ac}\"] = tn\n",
    "        metrics[f\"fp_{ac}\"] = fp\n",
    "        metrics[f\"fn_{ac}\"] = fn\n",
    "        metrics[f\"n_samples_{ac}\"] = len(ac_predictions)\n",
    "\n",
    "    # Calculate f1_micro\n",
    "    metrics[\"f1_micro\"] = calculate_f1_micro(metrics)\n",
    "\n",
    "    print([metrics[key] for key in [f\"f1_{ac}\" for ac in constants.ASPECT_CATEGORIES]], (len(\n",
    "        constants.ASPECT_CATEGORIES) - 1))\n",
    "\n",
    "    # Calculate F1 macro score\n",
    "    metrics[\"f1_macro\"] = sum(metrics[key] for key in [\n",
    "                              f\"f1_{ac}\" for ac in constants.ASPECT_CATEGORIES]) / len(constants.ASPECT_CATEGORIES)\n",
    "\n",
    "    # Calculate toal scores\n",
    "    tp, tn, fp, fn = compute_metrics_for_subset((predictions == predictions.max(\n",
    "        axis=2)[:, :, np.newaxis]).astype(int), true_labels)\n",
    "    metrics[\"precision\"], metrics[\"recall\"], metrics[\"f1\"] = compute_popular_metrics(\n",
    "        tp, tn, fp, fn)\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 0.9076086956521738, 1.0, 1.0, 1.0] 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'f1_GENERAL-IMPRESSION': 1.0,\n",
       " 'precision_GENERAL-IMPRESSION': 1.0,\n",
       " 'recall_GENERAL-IMPRESSION': 1.0,\n",
       " 'tp_GENERAL-IMPRESSION': 33,\n",
       " 'tn_GENERAL-IMPRESSION': 0,\n",
       " 'fp_GENERAL-IMPRESSION': 0,\n",
       " 'fn_GENERAL-IMPRESSION': 0,\n",
       " 'n_samples_GENERAL-IMPRESSION': 33,\n",
       " 'f1_FOOD': 0.9076086956521738,\n",
       " 'precision_FOOD': 0.8308457711442786,\n",
       " 'recall_FOOD': 1.0,\n",
       " 'tp_FOOD': 167,\n",
       " 'tn_FOOD': 0,\n",
       " 'fp_FOOD': 34,\n",
       " 'fn_FOOD': 0,\n",
       " 'n_samples_FOOD': 167,\n",
       " 'f1_SERVICE': 1.0,\n",
       " 'precision_SERVICE': 1.0,\n",
       " 'recall_SERVICE': 1.0,\n",
       " 'tp_SERVICE': 166,\n",
       " 'tn_SERVICE': 0,\n",
       " 'fp_SERVICE': 0,\n",
       " 'fn_SERVICE': 0,\n",
       " 'n_samples_SERVICE': 166,\n",
       " 'f1_AMBIENCE': 1.0,\n",
       " 'precision_AMBIENCE': 1.0,\n",
       " 'recall_AMBIENCE': 1.0,\n",
       " 'tp_AMBIENCE': 131,\n",
       " 'tn_AMBIENCE': 0,\n",
       " 'fp_AMBIENCE': 0,\n",
       " 'fn_AMBIENCE': 0,\n",
       " 'n_samples_AMBIENCE': 100,\n",
       " 'f1_PRICE': 1.0,\n",
       " 'precision_PRICE': 1.0,\n",
       " 'recall_PRICE': 1.0,\n",
       " 'tp_PRICE': 33,\n",
       " 'tn_PRICE': 0,\n",
       " 'fp_PRICE': 0,\n",
       " 'fn_PRICE': 0,\n",
       " 'n_samples_PRICE': 33,\n",
       " 'f1_micro': 0.9689213893967094,\n",
       " 'f1_macro': 0.9815217391304347,\n",
       " 'precision': 0.9397163120567376,\n",
       " 'recall': 1.0,\n",
       " 'f1': 0.9689213893967094}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_m1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
