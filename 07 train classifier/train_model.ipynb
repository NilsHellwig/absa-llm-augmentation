{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f1c00eb-3042-4e94-8e47-e082bcb29577",
   "metadata": {},
   "source": [
    "# Notebook: Train Model for a given Condition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e96d9f-4b8d-41c6-bd36-6a4dda52903a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e64ba35-a40d-44e6-bdc3-771db5285113",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ACD import aspect_category_labels_to_one_hot, CustomDatasetACD, preprocess_data_ACD, create_model_ACD, compute_metrics_ACD, get_trainer_ACD\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from sklearn.metrics import f1_score, accuracy_score, hamming_loss, precision_score, recall_score\n",
    "from torch.utils.data import Dataset as TorchDataset\n",
    "from helper import format_seconds_to_time_string\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import set_seed\n",
    "from scipy.special import expit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import warnings\n",
    "import random\n",
    "import torch\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a5cb7e4-ff64-44d3-a5e6-d9386eb7bc3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"transformers.optimization\")\n",
    "torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79af370b-cdd6-4733-92c2-067358ea0736",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a4c2f77-2f1c-40c8-9244-28b546a38584",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LLM_NAME = \"Llama13B\"\n",
    "N_REAL = 500\n",
    "N_SYNTH = 0\n",
    "TARGET = \"aspect_term\"\n",
    "LLM_SAMPLING = \"fixed\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc42300f-d3ea-4578-8450-02b2639c0af2",
   "metadata": {},
   "source": [
    "## Settings (do not change!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de0ce2d7-a009-43ca-9b99-5b874a25a4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FOLDS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c48866c-3549-4d05-b0a9-f0b737ee6231",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT_LOOP = [0, 1, 2, 3, 4, 0, 1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df4a5385-2a90-4033-9c12-b662f07d0279",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 43\n",
    "random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c55d7f95-4c76-4352-9f66-96a55a0caf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "ASPECT_CATEGORIES  = [\"GENERAL-IMPRESSION\", \"FOOD\", \"SERVICE\", \"AMBIENCE\", \"PRICE\"]\n",
    "POLARITIES = [\"POSITIVE\", \"NEUTRAL\", \"NEGATIVE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7fecf01-0c40-40ff-840d-d0c4b7f57cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8986e14-70e2-4a52-9cba-1456bc9be94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4853cd8-c455-4f03-9b67-589fdd620768",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c67dad-6b5e-464c-9928-277c9c2bc844",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77c32e3b-2258-4244-8d1e-9fecd81372cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load Real Dataset\n",
    "splits_real = []\n",
    "for i in range(N_FOLDS):\n",
    "    with open(f'../03 dataset split/real/real_{i}.json', 'r') as json_datei:\n",
    "        real_split = json.load(json_datei)[:N_REAL]\n",
    "        splits_real.append(real_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bb0500e-e89d-4ebb-afba-53c3d3867161",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load Synth Dataset\n",
    "splits_synth = []\n",
    "for i in range(N_FOLDS):\n",
    "    with open(f'../04 llm synthesis/synth/{LLM_NAME}/{LLM_SAMPLING}/split_{i}.json', 'r') as json_datei:\n",
    "        synth_split = json.load(json_datei)[:N_SYNTH]\n",
    "        splits_synth.append(synth_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3466979-b9c5-421d-887e-ebebadafcd42",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_splits_map = {\n",
    "    500: 1,\n",
    "    1000: 2,\n",
    "    2000: 4\n",
    "}\n",
    "n_splits_required_real = n_splits_map.get(N_REAL, 0)\n",
    "n_splits_required_synth = n_splits_map.get(N_SYNTH, 0)\n",
    "n_splits_required_real, n_splits_required_synth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee0e5093-b0dc-4c6a-818a-26f2346c781f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Five indexes, each for one cross valdiation run\n",
    "train_dataset = []\n",
    "test_dataset = []\n",
    "\n",
    "for i in range(N_FOLDS):\n",
    "    test_data = splits_real[i]\n",
    "    train_data = []\n",
    "    \n",
    "    if N_REAL > 0:\n",
    "        for split_idx in SPLIT_LOOP[i+1: i+1+n_splits_required_real]:\n",
    "            for example in splits_real[split_idx]:\n",
    "                train_data.append(example)\n",
    " \n",
    "    if N_SYNTH > 0:\n",
    "        for split_idx in SPLIT_LOOP[i+1: i+1+n_splits_required_synth]:\n",
    "            for example in splits_synth[split_idx]:\n",
    "                train_data.append(example)\n",
    "                \n",
    "    random.shuffle(train_data)\n",
    "    \n",
    "    train_dataset.append(train_data)\n",
    "    test_dataset.append(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bbcbc1-5c95-4ccb-b90e-fa14b4268439",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### ACD Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d82fdd55-f02d-49e9-9b70-d9e487e301f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ACD_model():\n",
    "    results = {\n",
    "        \"LLM_NAME\": LLM_NAME,\n",
    "        \"N_REAL\": N_REAL,\n",
    "        \"N_SYNTH\": N_SYNTH,\n",
    "        \"TARGET\": TARGET,\n",
    "        \"LLM_SAMPLING\": LLM_SAMPLING,\n",
    "    }\n",
    "\n",
    "    f1_micro_scores = []\n",
    "    f1_macro_scores = []\n",
    "    f1_weighted_scores = []\n",
    "    accuracy_scores = []\n",
    "    class_f1_scores = []\n",
    "    loss = []\n",
    "    hamming = []\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"deepset/gbert-large\")\n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "    for cross_idx in range(N_FOLDS):\n",
    "        # Load Data\n",
    "        train_data = preprocess_data_ACD(train_dataset[cross_idx], tokenizer)\n",
    "        test_data = preprocess_data_ACD(test_dataset[cross_idx], tokenizer)\n",
    "\n",
    "        # Load Model\n",
    "        model_ACD = create_model_ACD()\n",
    "\n",
    "        # Train Model\n",
    "        trainer = get_trainer_ACD(model_ACD, train_data, test_data, tokenizer)\n",
    "        trainer.train()\n",
    "\n",
    "        # Save Evaluation of Test Data\n",
    "        eval_metrics = trainer.evaluate()\n",
    "\n",
    "        # Save Metrics for fold\n",
    "        f1_micro_scores.append(eval_metrics[\"eval_f1_micro\"])\n",
    "        f1_macro_scores.append(eval_metrics[\"eval_f1_macro\"])\n",
    "        f1_weighted_scores.append(eval_metrics[\"eval_f1_weighted\"])\n",
    "        accuracy_scores.append(eval_metrics[\"eval_accuracy\"])\n",
    "        class_f1_scores.append(eval_metrics[\"eval_class_f1_scores\"])\n",
    "        loss.append(eval_metrics[\"eval_loss\"])\n",
    "        hamming.append(eval_metrics[\"eval_hamming_loss\"])\n",
    "\n",
    "    runtime = time.time() - start_time\n",
    "\n",
    "    results[\"loss\"] = np.mean(loss)\n",
    "    results[\"hamming\"] = np.mean(hamming)\n",
    "    results[\"accuracy\"] = np.mean(accuracy_scores)\n",
    "    results[\"f1_micro\"] = np.mean(f1_micro_scores)\n",
    "    results[\"f1_macro\"] = np.mean(f1_macro_scores)\n",
    "    results[\"f1_weighted\"] = np.mean(f1_weighted_scores)\n",
    "    results[\"runtime\"] = runtime\n",
    "    results[\"runtime_formatted\"] = format_seconds_to_time_string(runtime)\n",
    "    return results\n",
    "\n",
    "if TARGET == \"aspect_category\":\n",
    "   results = train_ACD_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0739ccd-edd1-45af-aa28-9f56f3247211",
   "metadata": {},
   "source": [
    "### OTE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "124c8d9b-d400-40cc-a068-fc9601c55262",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[0][0][\"text\"], train_dataset[0][0][\"tags\"]\n",
    "\n",
    "\n",
    "for cross_idx in range(N_FOLDS)[0:]:\n",
    "    # Load Data\n",
    "    train_data = train_dataset[cross_idx]\n",
    "    test_data = test_dataset[cross_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "365fa78b-93cd-4ff3-a8b7-b30595aff42a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tags': [{'end': 28,\n",
       "   'start': 21,\n",
       "   'tag_with_polarity': 'SERVICE-NEGATIVE',\n",
       "   'tag_with_polarity_and_type': 'SERVICE-NEGATIVE-explicit',\n",
       "   'text': 'Kellner',\n",
       "   'type': 'label-explicit',\n",
       "   'label': 'SERVICE',\n",
       "   'polarity': 'NEGATIVE'},\n",
       "  {'end': 118,\n",
       "   'start': 110,\n",
       "   'tag_with_polarity': 'FOOD-NEUTRAL',\n",
       "   'tag_with_polarity_and_type': 'FOOD-NEUTRAL-explicit',\n",
       "   'text': 'Getränke',\n",
       "   'type': 'label-explicit',\n",
       "   'label': 'FOOD',\n",
       "   'polarity': 'NEUTRAL'}],\n",
       " 'text': 'Irgendwann kam unser Kellner nicht mehr, wir mussten andere Kellner ansprechen, damit sie ihn holten, um noch Getränke bestellen zu können.',\n",
       " 'two_or_more_sentences': False,\n",
       " 'id': 'bc142ab2-b3c7-4b30-88d3-5d87f055c53d',\n",
       " 'city': 'münchen',\n",
       " 'date': '2022-11-09',\n",
       " 'title': 'Super Essen, Service fragwürdig, Biere nicht voll.',\n",
       " 'rating': 3.0,\n",
       " 'review_id': 867815811,\n",
       " 'page_index': 2,\n",
       " 'author_name': '_BenitaFi-',\n",
       " 'sentence_idx': 4,\n",
       " 'language_code': 'de',\n",
       " 'restaurant_id': 807825,\n",
       " 'author_location': '',\n",
       " 'restaurant_name': 'Augustiner-Keller',\n",
       " 'detected_language': 'de',\n",
       " 'text_noanonymization': 'Wir waren zu dritt zur Mittagszeit für ca 3 Stunden vor Ort. Das Essen und Ambiente waren wirklich perfekt. Aber der Service ließ zu Wünschen übrig. Anfangs, sehr zuvorkommen, höflich. Irgendwann kam unser Kellner nicht mehr, wir mussten andere Kellner ansprechen, damit sie ihn holten, um noch Getränke bestellen zu können. Die Biere waren leider nie bis zum Eichstirch voll. Es fehlt grundsätzlich mindestens 1 Finger breit bis zum Eichstrich. Beim Bezahlen gaben wir dem Kellner dann Trinkgeld, was scheinbar nicht ausreichend war, weil er uns mit den Worten „ach heute ist nicht mehr drin?“ verabschiedete. Daher 2 Punkte Abzug.'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24030dcd-dcdb-4dfa-943d-77df2419a437",
   "metadata": {},
   "source": [
    "### Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7fe16c-9a30-4cb7-9a41-2c7268441a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "results=[{}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a605e1c-0838-4362-baff-ac314887b5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'results_json/results_{LLM_NAME}_real{N_REAL}_synth{N_SYNTH}_{TARGET}_{LLM_SAMPLING}.json', 'w') as json_file:\n",
    "    json.dump(results, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4361c90b-9974-4482-b122-580cc52c7675",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([results])\n",
    "df.to_csv(f'results_csv/results_{LLM_NAME}_real{N_REAL}_synth{N_SYNTH}_{TARGET}_{LLM_SAMPLING}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c568fc9-bab5-431f-8640-3549d39929c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
