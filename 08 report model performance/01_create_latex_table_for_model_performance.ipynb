{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook: Convert Model Results to Latex\n",
    "\n",
    "This notebook is used to load the .json files with the model performance in order to convert them into a latex table for the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo: Schauen, ob es die Metriken auch bei anderen Modellen gibt\n",
    "# Todo: 1.000 <- Punkte einfÃ¼gen\n",
    "# Todo: Soll bei nur Real gehen\n",
    "# Todo: Soll bei allen Tasks gehen\n",
    "# Todo: bei f1 micro etc 3 nachkommastellen\n",
    "# Schauen, dass es bei jedem Task \"eval_f1_micro\", \"eval_f1_macro\", \"accuracy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings / Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_PATH_BASE = \"../07 train models/results_json/results_\"\n",
    "LLMS = [\"Llama70B\", \"GPT-3\"]\n",
    "# , \"aspect_category_sentiment\", \"end_2_end_absa\" ,\"target_aspect_sentiment_detection\"]\n",
    "ABSA_TASKS = [\"aspect_category\", \"aspect_category_sentiment\",\n",
    "              \"end_2_end_absa\", \"target_aspect_sentiment_detection\"]\n",
    "SYNTH_COMBINATIONS = {\n",
    "    \"fixed\": [\n",
    "        {\"real\": 25, \"synth\": 475},\n",
    "        {\"real\": 25, \"synth\": 975},\n",
    "        {\"real\": 25, \"synth\": 1975}\n",
    "    ],\n",
    "    \"random\": [\n",
    "        {\"real\": 500, \"synth\": 500},\n",
    "        {\"real\": 500, \"synth\": 1000},\n",
    "        {\"real\": 500, \"synth\": 1500}\n",
    "    ]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "LLMS_ENCODED = {\"GPT-3\": \"\\\\textbf{GPT-3.5-turbo}\", \"Llama70B\": \"\\\\textbf{Llama-2-70B}\"}\n",
    "ENCODE_CONDITION = {\"fixed\": \"\\\\textbf{LRS\\\\textsubscript{25}}\",\n",
    "                    \"random\": \"\\\\textbf{LRS\\\\textsubscript{500}}\"}\n",
    "\n",
    "N_METRICS = {\"aspect_category\": 6, \"aspect_category_sentiment\": 6,\n",
    "             \"end_2_end_absa\": 6, \"target_aspect_sentiment_detection\": 5}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_number(num, decimal_places):\n",
    "    formatted_num = \"{:.{}f}\".format(num, decimal_places)\n",
    "    rounded_num_str = \"{:.{}f}\".format(float(formatted_num), decimal_places)\n",
    "    return rounded_num_str\n",
    "\n",
    "def add_thousand_dots(n_sample):\n",
    "    if isinstance(n_sample, str):\n",
    "        if '.' in n_sample:\n",
    "            integer_part, decimal_part = n_sample.split('.')\n",
    "            formatted_integer_part = \"{:,}\".format(int(integer_part))\n",
    "            result = f\"{formatted_integer_part}.{decimal_part}\"\n",
    "        else:\n",
    "            result = \"{:,}\".format(int(n_sample))\n",
    "    elif isinstance(n_sample, np.float64):\n",
    "        result = \"{:,}\".format(round(n_sample, 1))\n",
    "    else:\n",
    "        result = n_sample\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report Main Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metric(metric_name, results):\n",
    "    main_metric = add_thousand_dots(round_number(results[metric_name]*100, 2))\n",
    "    std_metric = round_number(np.std([res[metric_name] * 100 for res in results[\"single_split_results\"]]), 2)\n",
    "    return main_metric + \"\\\\textsubscript{\" + std_metric + \"}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_category :\n",
      "\n",
      " -------#-----#-----#-------\n",
      "\\multirow{3}{*}{\\textbf{Real Examples}} & \\multirow{3}{*}{-} & 500 & 0 & 90.90\\textsubscript{1.37} & 89.97\\textsubscript{1.66} & 83.80\\textsubscript{2.01} \\\\\n",
      " &  & 1,000 & 0 & 92.02\\textsubscript{1.19} & 91.10\\textsubscript{1.46} & 86.07\\textsubscript{1.63} \\\\\n",
      " &  & 2,000 & 0 & 92.35\\textsubscript{1.15} & 91.53\\textsubscript{1.31} & 86.23\\textsubscript{1.86} \\\\\n",
      "\\hline\n",
      "\\multirow{6}{*}{\\textbf{Llama-2-70B}} & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{25}}} & 25 & 475 & 77.57\\textsubscript{2.16} & 76.79\\textsubscript{2.53} & 62.60\\textsubscript{3.27} \\\\\n",
      " &  & 25 & 975 & 77.82\\textsubscript{2.18} & 76.24\\textsubscript{2.13} & 63.83\\textsubscript{3.92} \\\\\n",
      " &  & 25 & 1,975 & 78.35\\textsubscript{1.99} & 76.88\\textsubscript{1.55} & 66.37\\textsubscript{2.24} \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-7}\\arrayrulecolor{black}\n",
      " & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{500}}} & 500 & 500 & 88.60\\textsubscript{1.54} & 87.36\\textsubscript{1.44} & 79.77\\textsubscript{2.42} \\\\\n",
      " &  & 500 & 1,000 & 87.17\\textsubscript{0.87} & 85.78\\textsubscript{0.87} & 78.40\\textsubscript{1.91} \\\\\n",
      " &  & 500 & 1,500 & 87.92\\textsubscript{0.49} & 86.85\\textsubscript{0.37} & 79.20\\textsubscript{1.00} \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-7}\\arrayrulecolor{black}\n",
      "\\hline\n",
      "\\multirow{6}{*}{\\textbf{GPT-3.5-turbo}} & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{25}}} & 25 & 475 & 79.80\\textsubscript{2.57} & 79.13\\textsubscript{2.15} & 66.93\\textsubscript{3.43} \\\\\n",
      " &  & 25 & 975 & 79.52\\textsubscript{3.32} & 78.80\\textsubscript{3.58} & 66.93\\textsubscript{3.78} \\\\\n",
      " &  & 25 & 1,975 & 79.63\\textsubscript{3.17} & 79.11\\textsubscript{3.49} & 67.27\\textsubscript{3.89} \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-7}\\arrayrulecolor{black}\n",
      " & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{500}}} & 500 & 500 & 90.85\\textsubscript{0.91} & 89.89\\textsubscript{1.16} & 84.17\\textsubscript{1.30} \\\\\n",
      " &  & 500 & 1,000 & 90.52\\textsubscript{1.33} & 89.81\\textsubscript{1.42} & 83.30\\textsubscript{2.18} \\\\\n",
      " &  & 500 & 1,500 & 89.68\\textsubscript{0.96} & 88.77\\textsubscript{1.23} & 81.93\\textsubscript{1.30} \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-7}\\arrayrulecolor{black}\n",
      "\\hline\n",
      "\n",
      "\n",
      "\n",
      "aspect_category_sentiment :\n",
      "\n",
      " -------#-----#-----#-------\n",
      "\\multirow{3}{*}{\\textbf{Real Examples}} & \\multirow{3}{*}{-} & 500 & 0 & 84.54\\textsubscript{1.14} & 57.46\\textsubscript{2.05} & 75.97\\textsubscript{1.96} \\\\\n",
      " &  & 1,000 & 0 & 88.60\\textsubscript{1.29} & 72.02\\textsubscript{3.72} & 81.80\\textsubscript{2.02} \\\\\n",
      " &  & 2,000 & 0 & 89.40\\textsubscript{1.37} & 76.15\\textsubscript{5.51} & 82.83\\textsubscript{1.64} \\\\\n",
      "\\hline\n",
      "\\multirow{6}{*}{\\textbf{Llama-2-70B}} & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{25}}} & 25 & 475 & 52.72\\textsubscript{5.65} & 43.07\\textsubscript{5.56} & 36.33\\textsubscript{4.89} \\\\\n",
      " &  & 25 & 975 & 59.64\\textsubscript{2.42} & 48.88\\textsubscript{3.45} & 45.57\\textsubscript{3.33} \\\\\n",
      " &  & 25 & 1,975 & 60.47\\textsubscript{0.92} & 49.47\\textsubscript{1.97} & 46.93\\textsubscript{1.73} \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-7}\\arrayrulecolor{black}\n",
      " & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{500}}} & 500 & 500 & 81.43\\textsubscript{1.44} & 64.92\\textsubscript{4.01} & 72.57\\textsubscript{2.07} \\\\\n",
      " &  & 500 & 1,000 & 79.61\\textsubscript{1.23} & 63.53\\textsubscript{3.92} & 69.90\\textsubscript{2.21} \\\\\n",
      " &  & 500 & 1,500 & 77.46\\textsubscript{0.94} & 61.76\\textsubscript{3.46} & 67.40\\textsubscript{1.91} \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-7}\\arrayrulecolor{black}\n",
      "\\hline\n",
      "\\multirow{6}{*}{\\textbf{GPT-3.5-turbo}} & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{25}}} & 25 & 475 & 60.18\\textsubscript{6.20} & 49.29\\textsubscript{6.60} & 42.37\\textsubscript{5.88} \\\\\n",
      " &  & 25 & 975 & 70.95\\textsubscript{4.35} & 60.60\\textsubscript{7.31} & 55.03\\textsubscript{4.15} \\\\\n",
      " &  & 25 & 1,975 & 71.71\\textsubscript{3.59} & 61.65\\textsubscript{5.50} & 56.77\\textsubscript{3.12} \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-7}\\arrayrulecolor{black}\n",
      " & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{500}}} & 500 & 500 & 86.70\\textsubscript{2.03} & 76.47\\textsubscript{8.99} & 79.27\\textsubscript{2.71} \\\\\n",
      " &  & 500 & 1,000 & 86.60\\textsubscript{1.36} & 75.81\\textsubscript{6.61} & 78.83\\textsubscript{1.76} \\\\\n",
      " &  & 500 & 1,500 & 85.94\\textsubscript{1.45} & 75.91\\textsubscript{5.88} & 78.10\\textsubscript{1.69} \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-7}\\arrayrulecolor{black}\n",
      "\\hline\n",
      "\n",
      "\n",
      "\n",
      "end_2_end_absa :\n",
      "\n",
      " -------#-----#-----#-------\n",
      "\\multirow{3}{*}{\\textbf{Real Examples}} & \\multirow{3}{*}{-} & 500 & 0 & 77.16\\textsubscript{1.77} & 70.07\\textsubscript{5.01} & 62.84\\textsubscript{2.33} \\\\\n",
      " &  & 1,000 & 0 & 80.69\\textsubscript{1.65} & 75.03\\textsubscript{2.61} & 67.66\\textsubscript{2.34} \\\\\n",
      " &  & 2,000 & 0 & 82.00\\textsubscript{3.68} & 78.83\\textsubscript{4.89} & 69.66\\textsubscript{5.18} \\\\\n",
      "\\hline\n",
      "\\multirow{6}{*}{\\textbf{Llama-2-70B}} & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{25}}} & 25 & 475 & 48.24\\textsubscript{4.02} & 41.17\\textsubscript{4.65} & 31.88\\textsubscript{3.52} \\\\\n",
      " &  & 25 & 975 & 52.41\\textsubscript{2.52} & 44.85\\textsubscript{4.03} & 35.55\\textsubscript{2.36} \\\\\n",
      " &  & 25 & 1,975 & 57.14\\textsubscript{2.31} & 47.58\\textsubscript{3.65} & 40.03\\textsubscript{2.26} \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-7}\\arrayrulecolor{black}\n",
      " & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{500}}} & 500 & 500 & 72.25\\textsubscript{2.39} & 63.40\\textsubscript{1.99} & 56.61\\textsubscript{2.95} \\\\\n",
      " &  & 500 & 1,000 & 71.99\\textsubscript{0.89} & 62.43\\textsubscript{2.15} & 56.24\\textsubscript{1.08} \\\\\n",
      " &  & 500 & 1,500 & 70.64\\textsubscript{1.13} & 61.30\\textsubscript{3.58} & 54.62\\textsubscript{1.35} \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-7}\\arrayrulecolor{black}\n",
      "\\hline\n",
      "\\multirow{6}{*}{\\textbf{GPT-3.5-turbo}} & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{25}}} & 25 & 475 & 59.15\\textsubscript{4.39} & 52.61\\textsubscript{5.08} & 42.14\\textsubscript{4.41} \\\\\n",
      " &  & 25 & 975 & 58.65\\textsubscript{4.70} & 52.66\\textsubscript{5.71} & 41.65\\textsubscript{4.69} \\\\\n",
      " &  & 25 & 1,975 & 61.32\\textsubscript{3.87} & 58.15\\textsubscript{3.81} & 44.33\\textsubscript{4.04} \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-7}\\arrayrulecolor{black}\n",
      " & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{500}}} & 500 & 500 & 76.79\\textsubscript{3.89} & 72.27\\textsubscript{3.78} & 62.48\\textsubscript{5.13} \\\\\n",
      " &  & 500 & 1,000 & 75.96\\textsubscript{3.26} & 72.55\\textsubscript{2.91} & 61.35\\textsubscript{4.17} \\\\\n",
      " &  & 500 & 1,500 & 76.14\\textsubscript{3.54} & 71.67\\textsubscript{3.02} & 61.59\\textsubscript{4.46} \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-7}\\arrayrulecolor{black}\n",
      "\\hline\n",
      "\n",
      "\n",
      "\n",
      "target_aspect_sentiment_detection :\n",
      "\n",
      " -------#-----#-----#-------\n",
      "\\multirow{3}{*}{\\textbf{Real Examples}} & \\multirow{3}{*}{-} & 500 & 0 & 64.77\\textsubscript{1.67} & 56.50\\textsubscript{7.05} & 47.92\\textsubscript{1.80} \\\\\n",
      " &  & 1,000 & 0 & 67.33\\textsubscript{1.37} & 57.57\\textsubscript{4.65} & 50.76\\textsubscript{1.54} \\\\\n",
      " &  & 2,000 & 0 & 70.11\\textsubscript{0.96} & 61.62\\textsubscript{4.46} & 53.98\\textsubscript{1.13} \\\\\n",
      "\\hline\n",
      "\\multirow{6}{*}{\\textbf{Llama-2-70B}} & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{25}}} & 25 & 475 & 34.29\\textsubscript{2.55} & 26.46\\textsubscript{2.33} & 20.72\\textsubscript{1.86} \\\\\n",
      " &  & 25 & 975 & 34.84\\textsubscript{1.63} & 26.16\\textsubscript{1.62} & 21.11\\textsubscript{1.20} \\\\\n",
      " &  & 25 & 1,975 & 34.91\\textsubscript{3.12} & 27.37\\textsubscript{3.08} & 21.19\\textsubscript{2.25} \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-7}\\arrayrulecolor{black}\n",
      " & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{500}}} & 500 & 500 & 58.25\\textsubscript{0.77} & 46.09\\textsubscript{3.99} & 41.10\\textsubscript{0.76} \\\\\n",
      " &  & 500 & 1,000 & 54.45\\textsubscript{0.92} & 42.76\\textsubscript{2.99} & 37.41\\textsubscript{0.87} \\\\\n",
      " &  & 500 & 1,500 & 53.28\\textsubscript{1.94} & 41.63\\textsubscript{2.78} & 36.34\\textsubscript{1.78} \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-7}\\arrayrulecolor{black}\n",
      "\\hline\n",
      "\\multirow{6}{*}{\\textbf{GPT-3.5-turbo}} & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{25}}} & 25 & 475 & 38.88\\textsubscript{2.71} & 32.53\\textsubscript{3.03} & 24.16\\textsubscript{2.11} \\\\\n",
      " &  & 25 & 975 & 37.44\\textsubscript{4.23} & 28.80\\textsubscript{3.02} & 23.11\\textsubscript{3.18} \\\\\n",
      " &  & 25 & 1,975 & 35.47\\textsubscript{2.89} & 27.16\\textsubscript{2.62} & 21.60\\textsubscript{2.12} \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-7}\\arrayrulecolor{black}\n",
      " & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{500}}} & 500 & 500 & 61.52\\textsubscript{1.20} & 51.26\\textsubscript{6.09} & 44.43\\textsubscript{1.26} \\\\\n",
      " &  & 500 & 1,000 & 59.91\\textsubscript{1.56} & 49.17\\textsubscript{7.75} & 42.79\\textsubscript{1.59} \\\\\n",
      " &  & 500 & 1,500 & 59.67\\textsubscript{1.04} & 48.14\\textsubscript{3.80} & 42.53\\textsubscript{1.05} \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-7}\\arrayrulecolor{black}\n",
      "\\hline\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for absa_task in ABSA_TASKS:\n",
    "    print(absa_task, \":\\n\\n\", \"-------#-----#-----#-------\")\n",
    "    for n_real_idx, n_real in enumerate([500, 1000, 2000]):\n",
    "        if n_real_idx == 0:\n",
    "            condition_print = \"\\\\multirow{3}{*}{\\\\textbf{Real Examples}} & \\\\multirow{3}{*}{-}\"\n",
    "        else:\n",
    "            condition_print = \" & \"\n",
    "\n",
    "        json_path = RESULTS_PATH_BASE + \\\n",
    "            f\"only_real_real{n_real}_synth0_{absa_task}_random.json\"\n",
    "\n",
    "        with open(json_path, 'r') as json_file:\n",
    "            results = json.load(json_file)\n",
    "\n",
    "        if absa_task != \"target_aspect_sentiment_detection\":\n",
    "            print(\n",
    "                f\"{condition_print} & {add_thousand_dots(str(n_real))} & 0 & {get_metric('eval_f1_micro', results)} & {get_metric('eval_f1_macro', results)} & {get_metric('eval_accuracy', results)} \\\\\\\\\")\n",
    "        else:\n",
    "            print(\n",
    "                f\"{condition_print} & {add_thousand_dots(str(n_real))} & 0 & {get_metric('eval_f1', results)} & {get_metric('eval_f1_macro', results)} & {get_metric('eval_accuracy', results)} \\\\\\\\\")\n",
    "    print(\"\\\\hline\")\n",
    "    for llm_idx, llm in enumerate(LLMS):\n",
    "        for fs_idx, few_shot_condition in enumerate([\"fixed\", \"random\"]):\n",
    "            for freq_idx, freq in enumerate(SYNTH_COMBINATIONS[few_shot_condition]):\n",
    "                n_real = freq[\"real\"]\n",
    "                n_synth = freq[\"synth\"]\n",
    "                json_path = RESULTS_PATH_BASE + llm + \\\n",
    "                    f\"_real{n_real}_synth{n_synth}_{absa_task}_{few_shot_condition}.json\"\n",
    "                with open(json_path, 'r') as json_file:\n",
    "                    results = json.load(json_file)\n",
    "\n",
    "                if fs_idx == 0 and freq_idx == 0:\n",
    "                    llm_print = \"\\\\multirow{6}{*}{\"+LLMS_ENCODED[llm]+\"}\"\n",
    "                else:\n",
    "                    llm_print = \"\"\n",
    "\n",
    "                if freq_idx == 0:\n",
    "                    condition_print = \"\\\\multirow{3}{*}{\" + \\\n",
    "                        ENCODE_CONDITION[few_shot_condition]+\"}\"\n",
    "                else:\n",
    "                    condition_print = \"\"\n",
    "\n",
    "                if absa_task != \"target_aspect_sentiment_detection\":\n",
    "                    f1_metrics = f\"{get_metric('eval_f1_micro', results)} & {get_metric('eval_f1_macro', results)}\"\n",
    "                else:\n",
    "                    f1_metrics = f\"{get_metric('eval_f1', results)} & {get_metric('eval_f1_macro', results)}\"\n",
    "                print(\n",
    "                    f\"{llm_print} & {condition_print} & {add_thousand_dots(str(n_real))} & {add_thousand_dots(str(n_synth))} & {f1_metrics} & {get_metric('eval_accuracy', results)} \\\\\\\\\")\n",
    "\n",
    "                # print(llm_idx, fs_idx, freq_idx)\n",
    "            if freq_idx == 2:\n",
    "                print(\n",
    "                    \"\\\\arrayrulecolor{gray}\\cline{2-\"+str(7)+\"}\\\\arrayrulecolor{black}\")\n",
    "            else:\n",
    "                print(\"\\\\hline\")\n",
    "        print(\"\\hline\")\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report Metrics Fine-Grained Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ACD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\multirow{3}{*}{\\textbf{Real Examples}} & \\multirow{3}{*}{-} & 500 & 0 & 85.23\\textsubscript{3.71} &93.00\\textsubscript{1.60} &93.57\\textsubscript{0.90} &94.47\\textsubscript{0.78} &93.03\\textsubscript{1.84} &95.43\\textsubscript{1.35} &87.25\\textsubscript{3.80} &96.43\\textsubscript{1.16} &90.78\\textsubscript{3.57} &98.53\\textsubscript{0.60}  \\\\\n",
      " &  & 1,000 & 0 & 86.68\\textsubscript{2.65} &93.53\\textsubscript{1.30} &94.71\\textsubscript{0.92} &95.47\\textsubscript{0.85} &94.15\\textsubscript{1.33} &96.17\\textsubscript{0.93} &88.21\\textsubscript{2.87} &96.70\\textsubscript{0.89} &91.74\\textsubscript{2.42} &98.70\\textsubscript{0.47}  \\\\\n",
      " &  & 2,000 & 0 & 87.41\\textsubscript{2.77} &93.80\\textsubscript{1.18} &94.92\\textsubscript{0.82} &95.67\\textsubscript{0.76} &94.41\\textsubscript{1.10} &96.37\\textsubscript{0.79} &88.34\\textsubscript{2.96} &96.70\\textsubscript{0.98} &92.56\\textsubscript{3.00} &98.83\\textsubscript{0.53}  \\\\\n",
      "\\hline\n",
      "\\multirow{6}{*}{\\textbf{Llama-2-70B}} & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{25}}} & 25 & 475 & 67.64\\textsubscript{5.24} &79.83\\textsubscript{2.75} &82.27\\textsubscript{2.94} &85.47\\textsubscript{2.02} &84.84\\textsubscript{2.94} &90.77\\textsubscript{1.78} &70.13\\textsubscript{2.45} &90.50\\textsubscript{1.38} &79.06\\textsubscript{8.91} &95.93\\textsubscript{2.52}  \\\\\n",
      " &  & 25 & 975 & 69.19\\textsubscript{4.54} &81.00\\textsubscript{3.29} &82.54\\textsubscript{1.81} &85.77\\textsubscript{1.18} &85.03\\textsubscript{2.37} &91.00\\textsubscript{1.45} &72.37\\textsubscript{4.08} &91.50\\textsubscript{2.21} &72.08\\textsubscript{6.59} &94.40\\textsubscript{2.43}  \\\\\n",
      " &  & 25 & 1,975 & 71.36\\textsubscript{3.45} &82.23\\textsubscript{2.48} &84.08\\textsubscript{2.82} &87.43\\textsubscript{2.03} &81.51\\textsubscript{4.27} &89.50\\textsubscript{1.77} &73.05\\textsubscript{3.09} &92.60\\textsubscript{1.22} &74.43\\textsubscript{6.47} &95.63\\textsubscript{1.67}  \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-14}\\arrayrulecolor{black}\n",
      " & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{500}}} & 500 & 500 & 82.13\\textsubscript{2.59} &90.97\\textsubscript{1.10} &92.04\\textsubscript{2.18} &93.33\\textsubscript{1.79} &91.38\\textsubscript{2.55} &94.53\\textsubscript{1.48} &84.08\\textsubscript{2.55} &95.60\\textsubscript{0.57} &87.16\\textsubscript{3.51} &97.93\\textsubscript{0.70}  \\\\\n",
      " &  & 500 & 1,000 & 82.07\\textsubscript{1.77} &90.63\\textsubscript{1.14} &90.44\\textsubscript{1.06} &92.13\\textsubscript{0.88} &89.98\\textsubscript{2.17} &93.80\\textsubscript{1.28} &82.36\\textsubscript{1.38} &95.13\\textsubscript{0.36} &84.07\\textsubscript{2.80} &97.47\\textsubscript{0.50}  \\\\\n",
      " &  & 500 & 1,500 & 81.96\\textsubscript{2.09} &90.67\\textsubscript{0.89} &91.08\\textsubscript{0.89} &92.70\\textsubscript{0.74} &90.82\\textsubscript{1.79} &94.20\\textsubscript{1.32} &83.57\\textsubscript{2.35} &95.53\\textsubscript{0.57} &86.81\\textsubscript{2.28} &98.00\\textsubscript{0.33}  \\\\\n",
      "\\hline\n",
      "\\multirow{6}{*}{\\textbf{GPT-3.5-turbo}} & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{25}}} & 25 & 475 & 71.41\\textsubscript{4.80} &82.40\\textsubscript{3.30} &86.85\\textsubscript{2.24} &88.97\\textsubscript{1.61} &78.77\\textsubscript{4.93} &88.53\\textsubscript{2.25} &76.90\\textsubscript{2.23} &94.03\\textsubscript{0.52} &81.73\\textsubscript{2.12} &96.73\\textsubscript{0.47}  \\\\\n",
      " &  & 25 & 975 & 72.66\\textsubscript{4.05} &83.33\\textsubscript{2.32} &87.30\\textsubscript{2.67} &89.53\\textsubscript{1.92} &75.95\\textsubscript{4.83} &87.37\\textsubscript{2.08} &74.97\\textsubscript{5.22} &93.60\\textsubscript{1.47} &83.14\\textsubscript{4.64} &97.00\\textsubscript{1.01}  \\\\\n",
      " &  & 25 & 1,975 & 73.61\\textsubscript{4.01} &83.83\\textsubscript{2.52} &87.23\\textsubscript{2.82} &89.60\\textsubscript{1.95} &74.61\\textsubscript{3.61} &86.83\\textsubscript{1.20} &76.88\\textsubscript{4.99} &94.07\\textsubscript{1.35} &83.21\\textsubscript{5.67} &97.00\\textsubscript{1.19}  \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-14}\\arrayrulecolor{black}\n",
      " & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{500}}} & 500 & 500 & 86.55\\textsubscript{2.20} &93.23\\textsubscript{1.10} &93.47\\textsubscript{1.01} &94.47\\textsubscript{0.88} &92.59\\textsubscript{2.07} &95.33\\textsubscript{1.19} &87.14\\textsubscript{3.17} &96.50\\textsubscript{1.00} &89.70\\textsubscript{2.20} &98.37\\textsubscript{0.48}  \\\\\n",
      " &  & 500 & 1,000 & 85.47\\textsubscript{1.99} &92.53\\textsubscript{1.30} &93.34\\textsubscript{1.40} &94.30\\textsubscript{1.33} &92.16\\textsubscript{1.32} &95.03\\textsubscript{0.68} &87.17\\textsubscript{3.62} &96.47\\textsubscript{1.05} &90.89\\textsubscript{2.49} &98.57\\textsubscript{0.39}  \\\\\n",
      " &  & 500 & 1,500 & 84.30\\textsubscript{2.19} &91.90\\textsubscript{0.87} &92.72\\textsubscript{1.15} &93.83\\textsubscript{1.08} &91.95\\textsubscript{1.84} &94.93\\textsubscript{1.09} &84.91\\textsubscript{3.33} &95.83\\textsubscript{1.04} &89.99\\textsubscript{2.17} &98.40\\textsubscript{0.42}  \\\\\n",
      "\\hline\n"
     ]
    }
   ],
   "source": [
    "absa_task = \"aspect_category\"\n",
    "for n_real_idx, n_real in enumerate([500, 1000, 2000]):\n",
    "    json_path = RESULTS_PATH_BASE + \\\n",
    "        f\"only_real_real{n_real}_synth0_{absa_task}_random.json\"\n",
    "    with open(json_path, 'r') as json_file:\n",
    "        results = json.load(json_file)\n",
    "\n",
    "    if n_real_idx == 0:\n",
    "        condition_print = \"\\\\multirow{3}{*}{\\\\textbf{Real Examples}} & \\\\multirow{3}{*}{-}\"\n",
    "    else:\n",
    "        condition_print = \" & \"\n",
    "\n",
    "    class_wise_metrics = \"\"\n",
    "    for ac in [\"GENERAL-IMPRESSION\", \"FOOD\", \"SERVICE\", \"AMBIENCE\", \"PRICE\"]:\n",
    "        for metric in [\"f1\", \"accuracy\"]:\n",
    "            class_wise_metrics += f\"{get_metric(f'eval_{metric}_{ac}', results)} &\"\n",
    "    print(\n",
    "        f\"{condition_print} & {add_thousand_dots(str(n_real))} & 0 & {class_wise_metrics[:-1]} \\\\\\\\\")\n",
    "print(\"\\\\hline\")\n",
    "for llm_idx, llm in enumerate(LLMS):\n",
    "    for fs_idx, few_shot_condition in enumerate(SYNTH_COMBINATIONS.keys()):\n",
    "        for freq_idx, freq in enumerate(SYNTH_COMBINATIONS[few_shot_condition]):\n",
    "            n_real = freq[\"real\"]\n",
    "            n_synth = freq[\"synth\"]\n",
    "            json_path = RESULTS_PATH_BASE + llm + \\\n",
    "                f\"_real{n_real}_synth{n_synth}_{absa_task}_{few_shot_condition}.json\"\n",
    "            with open(json_path, 'r') as json_file:\n",
    "                results = json.load(json_file)\n",
    "\n",
    "            if fs_idx == 0 and freq_idx == 0:\n",
    "                llm_print = \"\\\\multirow{6}{*}{\"+LLMS_ENCODED[llm]+\"}\"\n",
    "            else:\n",
    "                llm_print = \"\"\n",
    "\n",
    "            if freq_idx == 0:\n",
    "                condition_print = \"\\\\multirow{3}{*}{\" + \\\n",
    "                    ENCODE_CONDITION[few_shot_condition]+\"}\"\n",
    "            else:\n",
    "                condition_print = \"\"\n",
    "\n",
    "            class_wise_metrics = \"\"\n",
    "            for ac in [\"GENERAL-IMPRESSION\", \"FOOD\", \"SERVICE\", \"AMBIENCE\", \"PRICE\"]:\n",
    "                for metric in [\"f1\", \"accuracy\"]:\n",
    "                    class_wise_metrics += f\"{get_metric(f'eval_{metric}_{ac}', results)} &\"\n",
    "\n",
    "            print(\n",
    "                f\"{llm_print} & {condition_print} & {add_thousand_dots(str(n_real))} & {add_thousand_dots(str(n_synth))} & {class_wise_metrics[:-1]} \\\\\\\\\")\n",
    "            if fs_idx == 0 and freq_idx == 2:\n",
    "               print(\n",
    "                \"\\\\arrayrulecolor{gray}\\cline{2-14}\\\\arrayrulecolor{black}\")\n",
    "\n",
    "    print(\"\\hline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ACSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metric(metric, ac, polarity, results):\n",
    "    metric_name = f'{metric}_{ac}-{polarity}'\n",
    "    n_examples_field = f'eval_n_examples_{ac}-{polarity}'\n",
    "    main_metric = add_thousand_dots(round_number(results[metric_name]*100, 2))\n",
    "    std_metric = round_number(np.std(\n",
    "        [res[metric_name] * 100 for res in results[\"single_split_results\"] if res[n_examples_field] > 0]), 2)\n",
    "    return main_metric + \"\\\\textsubscript{\" + std_metric + \"}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table for: ['GENERAL-IMPRESSION', 'FOOD'] \n",
      "\n",
      "\n",
      "\\multirow{3}{*}{\\textbf{Real Examples}} & \\multirow{3}{*}{-} & 500 & 0 & 82.88\\textsubscript{3.05} & 95.77\\textsubscript{0.41} & 0.00\\textsubscript{0.00} & 99.17\\textsubscript{0.33} & 82.18\\textsubscript{7.34} & 96.33\\textsubscript{1.48} & 91.93\\textsubscript{1.48} & 96.13\\textsubscript{0.84} & 66.30\\textsubscript{8.56} & 98.07\\textsubscript{0.49} & 82.17\\textsubscript{4.06} & 94.37\\textsubscript{1.19} \\\\\n",
      " &  & 1,000 & 0 & 84.74\\textsubscript{2.43} & 96.07\\textsubscript{0.56} & 57.12\\textsubscript{26.45} & 99.43\\textsubscript{0.45} & 85.18\\textsubscript{6.61} & 96.93\\textsubscript{1.30} & 94.47\\textsubscript{1.10} & 97.33\\textsubscript{0.57} & 81.56\\textsubscript{5.95} & 98.63\\textsubscript{0.41} & 86.87\\textsubscript{2.86} & 95.70\\textsubscript{0.93} \\\\\n",
      " &  & 2,000 & 0 & 85.57\\textsubscript{3.62} & 96.27\\textsubscript{0.81} & 67.67\\textsubscript{20.57} & 99.50\\textsubscript{0.40} & 86.50\\textsubscript{4.17} & 97.07\\textsubscript{0.96} & 94.30\\textsubscript{1.23} & 97.23\\textsubscript{0.60} & 85.63\\textsubscript{4.81} & 98.90\\textsubscript{0.38} & 87.05\\textsubscript{2.85} & 95.80\\textsubscript{0.84} \\\\\n",
      "\\hline\n",
      "\\multirow{6}{*}{\\textbf{Llama-2-70B}} & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{25}}} & 25 & 475 & 56.18\\textsubscript{15.28} & 91.37\\textsubscript{1.73} & 11.03\\textsubscript{17.32} & 98.87\\textsubscript{0.43} & 54.03\\textsubscript{10.11} & 92.53\\textsubscript{1.91} & 55.17\\textsubscript{10.89} & 84.97\\textsubscript{2.59} & 34.02\\textsubscript{11.67} & 95.33\\textsubscript{0.54} & 61.09\\textsubscript{7.41} & 90.50\\textsubscript{1.12} \\\\\n",
      " &  & 25 & 975 & 65.05\\textsubscript{8.31} & 91.93\\textsubscript{1.23} & 18.29\\textsubscript{11.76} & 96.00\\textsubscript{1.98} & 61.33\\textsubscript{7.72} & 92.80\\textsubscript{1.42} & 64.58\\textsubscript{9.94} & 87.17\\textsubscript{3.00} & 37.72\\textsubscript{12.83} & 94.17\\textsubscript{1.27} & 67.36\\textsubscript{6.29} & 91.30\\textsubscript{0.99} \\\\\n",
      " &  & 25 & 1,975 & 61.49\\textsubscript{5.11} & 90.63\\textsubscript{0.67} & 10.98\\textsubscript{9.65} & 94.00\\textsubscript{1.89} & 66.63\\textsubscript{7.79} & 93.23\\textsubscript{0.99} & 69.53\\textsubscript{4.93} & 88.43\\textsubscript{1.62} & 37.33\\textsubscript{10.51} & 93.03\\textsubscript{1.41} & 69.97\\textsubscript{5.79} & 91.43\\textsubscript{1.26} \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-16}\\arrayrulecolor{black}\n",
      " & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{500}}} & 500 & 500 & 79.48\\textsubscript{3.02} & 94.83\\textsubscript{0.87} & 39.51\\textsubscript{24.14} & 98.97\\textsubscript{0.65} & 82.96\\textsubscript{4.81} & 96.33\\textsubscript{1.14} & 88.08\\textsubscript{1.80} & 94.53\\textsubscript{0.98} & 59.73\\textsubscript{8.33} & 97.27\\textsubscript{0.46} & 81.17\\textsubscript{3.70} & 94.13\\textsubscript{1.00} \\\\\n",
      " &  & 500 & 1,000 & 77.35\\textsubscript{2.91} & 94.30\\textsubscript{0.77} & 32.96\\textsubscript{13.49} & 98.37\\textsubscript{0.72} & 81.45\\textsubscript{4.50} & 96.03\\textsubscript{0.97} & 85.09\\textsubscript{2.26} & 93.40\\textsubscript{1.05} & 56.83\\textsubscript{10.84} & 97.00\\textsubscript{0.49} & 80.30\\textsubscript{4.35} & 93.90\\textsubscript{1.27} \\\\\n",
      " &  & 500 & 1,500 & 77.21\\textsubscript{3.84} & 94.33\\textsubscript{1.09} & 26.81\\textsubscript{10.96} & 97.70\\textsubscript{0.64} & 79.87\\textsubscript{5.12} & 95.63\\textsubscript{1.20} & 83.17\\textsubscript{3.40} & 92.70\\textsubscript{1.42} & 53.20\\textsubscript{11.28} & 96.63\\textsubscript{0.42} & 79.04\\textsubscript{3.27} & 93.63\\textsubscript{0.69} \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-16}\\arrayrulecolor{black}\n",
      "\\hline\n",
      "\\multirow{6}{*}{\\textbf{GPT-3.5-turbo}} & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{25}}} & 25 & 475 & 66.90\\textsubscript{10.26} & 91.63\\textsubscript{2.17} & 29.81\\textsubscript{15.72} & 99.20\\textsubscript{0.31} & 54.72\\textsubscript{12.03} & 92.60\\textsubscript{1.24} & 71.25\\textsubscript{5.92} & 89.00\\textsubscript{1.68} & 63.85\\textsubscript{6.62} & 97.57\\textsubscript{0.69} & 49.37\\textsubscript{15.44} & 89.20\\textsubscript{1.91} \\\\\n",
      " &  & 25 & 975 & 70.92\\textsubscript{7.90} & 91.87\\textsubscript{2.29} & 50.68\\textsubscript{19.27} & 99.17\\textsubscript{0.35} & 68.74\\textsubscript{7.53} & 93.67\\textsubscript{0.88} & 82.42\\textsubscript{3.73} & 92.50\\textsubscript{1.60} & 65.77\\textsubscript{7.85} & 97.07\\textsubscript{1.02} & 68.47\\textsubscript{12.32} & 91.97\\textsubscript{1.56} \\\\\n",
      " &  & 25 & 1,975 & 71.87\\textsubscript{5.35} & 91.40\\textsubscript{2.08} & 40.48\\textsubscript{11.45} & 98.87\\textsubscript{0.30} & 67.72\\textsubscript{5.88} & 92.80\\textsubscript{0.70} & 82.74\\textsubscript{3.53} & 92.27\\textsubscript{1.91} & 65.71\\textsubscript{11.18} & 96.90\\textsubscript{1.30} & 70.57\\textsubscript{7.59} & 92.30\\textsubscript{1.07} \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-16}\\arrayrulecolor{black}\n",
      " & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{500}}} & 500 & 500 & 83.41\\textsubscript{1.46} & 95.63\\textsubscript{0.58} & 58.33\\textsubscript{15.18} & 99.40\\textsubscript{0.42} & 82.68\\textsubscript{6.32} & 96.30\\textsubscript{1.32} & 92.12\\textsubscript{1.51} & 96.23\\textsubscript{0.86} & 82.30\\textsubscript{8.24} & 98.80\\textsubscript{0.49} & 84.58\\textsubscript{3.55} & 95.00\\textsubscript{1.12} \\\\\n",
      " &  & 500 & 1,000 & 82.99\\textsubscript{1.77} & 95.53\\textsubscript{0.61} & 58.97\\textsubscript{14.73} & 99.40\\textsubscript{0.33} & 83.72\\textsubscript{3.75} & 96.40\\textsubscript{0.95} & 91.92\\textsubscript{1.54} & 96.13\\textsubscript{0.85} & 81.15\\textsubscript{8.12} & 98.70\\textsubscript{0.60} & 85.42\\textsubscript{2.75} & 95.40\\textsubscript{0.83} \\\\\n",
      " &  & 500 & 1,500 & 83.31\\textsubscript{2.97} & 95.53\\textsubscript{0.91} & 60.23\\textsubscript{13.02} & 99.30\\textsubscript{0.43} & 81.43\\textsubscript{6.37} & 95.97\\textsubscript{1.41} & 92.06\\textsubscript{1.43} & 96.20\\textsubscript{0.77} & 78.40\\textsubscript{3.76} & 98.47\\textsubscript{0.27} & 85.13\\textsubscript{3.30} & 95.37\\textsubscript{0.99} \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-16}\\arrayrulecolor{black}\n",
      "\\hline\n",
      "Table for: ['SERVICE', 'AMBIENCE'] \n",
      "\n",
      "\n",
      "\\multirow{3}{*}{\\textbf{Real Examples}} & \\multirow{3}{*}{-} & 500 & 0 & 91.34\\textsubscript{1.66} & 97.13\\textsubscript{0.44} & 0.00\\textsubscript{0.00} & 99.60\\textsubscript{0.13} & 85.92\\textsubscript{2.84} & 95.97\\textsubscript{0.33} & 85.01\\textsubscript{3.28} & 97.30\\textsubscript{0.65} & 0.00\\textsubscript{0.00} & 99.75\\textsubscript{0.09} & 69.41\\textsubscript{9.19} & 97.90\\textsubscript{0.62} \\\\\n",
      " &  & 1,000 & 0 & 93.98\\textsubscript{2.25} & 97.93\\textsubscript{0.73} & 13.33\\textsubscript{26.67} & 99.64\\textsubscript{0.15} & 90.69\\textsubscript{1.73} & 97.23\\textsubscript{0.44} & 86.44\\textsubscript{1.13} & 97.43\\textsubscript{0.39} & 0.00\\textsubscript{0.00} & 99.75\\textsubscript{0.09} & 79.40\\textsubscript{6.51} & 98.37\\textsubscript{0.48} \\\\\n",
      " &  & 2,000 & 0 & 95.15\\textsubscript{2.24} & 98.37\\textsubscript{0.65} & 40.00\\textsubscript{48.99} & 99.72\\textsubscript{0.24} & 90.64\\textsubscript{2.73} & 97.17\\textsubscript{0.80} & 87.25\\textsubscript{2.89} & 97.53\\textsubscript{0.57} & 0.00\\textsubscript{0.00} & 99.75\\textsubscript{0.09} & 83.64\\textsubscript{6.02} & 98.73\\textsubscript{0.39} \\\\\n",
      "\\hline\n",
      "\\multirow{6}{*}{\\textbf{Llama-2-70B}} & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{25}}} & 25 & 475 & 48.69\\textsubscript{11.21} & 88.40\\textsubscript{1.78} & 17.35\\textsubscript{15.76} & 98.44\\textsubscript{0.91} & 50.52\\textsubscript{6.21} & 90.03\\textsubscript{1.05} & 46.89\\textsubscript{8.37} & 93.23\\textsubscript{1.04} & 22.50\\textsubscript{22.78} & 99.30\\textsubscript{0.30} & 48.65\\textsubscript{12.37} & 97.03\\textsubscript{0.53} \\\\\n",
      " &  & 25 & 975 & 58.27\\textsubscript{9.27} & 89.87\\textsubscript{1.68} & 11.12\\textsubscript{3.61} & 95.96\\textsubscript{1.18} & 64.84\\textsubscript{5.22} & 91.87\\textsubscript{1.36} & 52.10\\textsubscript{8.25} & 93.60\\textsubscript{1.05} & 13.39\\textsubscript{13.45} & 98.60\\textsubscript{0.66} & 59.20\\textsubscript{8.86} & 97.20\\textsubscript{0.46} \\\\\n",
      " &  & 25 & 1,975 & 60.55\\textsubscript{8.84} & 90.30\\textsubscript{0.96} & 12.65\\textsubscript{3.01} & 96.20\\textsubscript{0.59} & 64.06\\textsubscript{6.31} & 91.87\\textsubscript{0.94} & 51.41\\textsubscript{6.55} & 93.27\\textsubscript{0.79} & 11.86\\textsubscript{6.87} & 98.15\\textsubscript{0.50} & 62.34\\textsubscript{5.77} & 97.27\\textsubscript{0.43} \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-16}\\arrayrulecolor{black}\n",
      " & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{500}}} & 500 & 500 & 85.43\\textsubscript{3.06} & 95.40\\textsubscript{0.90} & 19.11\\textsubscript{16.61} & 99.04\\textsubscript{0.29} & 85.26\\textsubscript{4.08} & 95.87\\textsubscript{0.79} & 79.02\\textsubscript{3.19} & 96.37\\textsubscript{0.52} & 19.64\\textsubscript{21.05} & 99.30\\textsubscript{0.22} & 71.07\\textsubscript{6.70} & 97.87\\textsubscript{0.49} \\\\\n",
      " &  & 500 & 1,000 & 85.22\\textsubscript{2.99} & 95.40\\textsubscript{0.88} & 23.71\\textsubscript{14.10} & 98.72\\textsubscript{0.60} & 84.87\\textsubscript{2.33} & 95.73\\textsubscript{0.66} & 77.96\\textsubscript{2.81} & 96.27\\textsubscript{0.41} & 16.25\\textsubscript{17.09} & 99.10\\textsubscript{0.41} & 70.87\\textsubscript{7.09} & 97.77\\textsubscript{0.65} \\\\\n",
      " &  & 500 & 1,500 & 82.60\\textsubscript{3.72} & 94.73\\textsubscript{0.85} & 14.74\\textsubscript{8.13} & 98.20\\textsubscript{0.36} & 82.97\\textsubscript{3.76} & 95.30\\textsubscript{0.94} & 75.23\\textsubscript{3.06} & 95.97\\textsubscript{0.35} & 11.81\\textsubscript{11.85} & 98.85\\textsubscript{0.17} & 67.85\\textsubscript{6.16} & 97.67\\textsubscript{0.46} \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-16}\\arrayrulecolor{black}\n",
      "\\hline\n",
      "\\multirow{6}{*}{\\textbf{GPT-3.5-turbo}} & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{25}}} & 25 & 475 & 68.72\\textsubscript{9.66} & 91.90\\textsubscript{1.92} & 58.10\\textsubscript{32.49} & 99.68\\textsubscript{0.24} & 40.35\\textsubscript{10.17} & 88.80\\textsubscript{1.95} & 55.81\\textsubscript{14.16} & 94.13\\textsubscript{1.66} & 50.00\\textsubscript{50.00} & 99.90\\textsubscript{0.10} & 49.72\\textsubscript{17.88} & 97.23\\textsubscript{0.80} \\\\\n",
      " &  & 25 & 975 & 77.21\\textsubscript{7.65} & 93.63\\textsubscript{1.73} & 54.67\\textsubscript{14.85} & 99.52\\textsubscript{0.20} & 53.15\\textsubscript{12.55} & 90.57\\textsubscript{1.53} & 64.35\\textsubscript{11.56} & 94.77\\textsubscript{1.53} & 66.67\\textsubscript{40.82} & 99.75\\textsubscript{0.33} & 72.95\\textsubscript{8.03} & 98.10\\textsubscript{0.55} \\\\\n",
      " &  & 25 & 1,975 & 79.48\\textsubscript{4.89} & 94.13\\textsubscript{1.11} & 41.86\\textsubscript{16.10} & 99.12\\textsubscript{0.45} & 60.45\\textsubscript{5.52} & 91.47\\textsubscript{1.16} & 66.20\\textsubscript{11.10} & 94.90\\textsubscript{1.44} & 70.00\\textsubscript{24.27} & 99.70\\textsubscript{0.30} & 70.61\\textsubscript{6.85} & 97.83\\textsubscript{0.52} \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-16}\\arrayrulecolor{black}\n",
      " & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{500}}} & 500 & 500 & 93.68\\textsubscript{1.53} & 97.87\\textsubscript{0.49} & 73.33\\textsubscript{38.87} & 99.84\\textsubscript{0.23} & 88.49\\textsubscript{1.82} & 96.60\\textsubscript{0.45} & 86.89\\textsubscript{1.66} & 97.63\\textsubscript{0.41} & 70.00\\textsubscript{41.23} & 99.90\\textsubscript{0.10} & 75.16\\textsubscript{7.07} & 98.13\\textsubscript{0.52} \\\\\n",
      " &  & 500 & 1,000 & 92.34\\textsubscript{1.54} & 97.43\\textsubscript{0.52} & 66.67\\textsubscript{36.51} & 99.80\\textsubscript{0.22} & 87.67\\textsubscript{2.33} & 96.43\\textsubscript{0.39} & 86.20\\textsubscript{2.13} & 97.50\\textsubscript{0.49} & 50.00\\textsubscript{50.00} & 99.90\\textsubscript{0.10} & 75.07\\textsubscript{6.24} & 98.13\\textsubscript{0.41} \\\\\n",
      " &  & 500 & 1,500 & 91.13\\textsubscript{2.27} & 97.10\\textsubscript{0.60} & 61.33\\textsubscript{23.63} & 99.64\\textsubscript{0.29} & 87.21\\textsubscript{2.12} & 96.27\\textsubscript{0.72} & 86.67\\textsubscript{1.45} & 97.60\\textsubscript{0.37} & 75.00\\textsubscript{43.30} & 99.90\\textsubscript{0.17} & 76.63\\textsubscript{5.78} & 98.20\\textsubscript{0.38} \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-16}\\arrayrulecolor{black}\n",
      "\\hline\n",
      "Table for: ['PRICE'] \n",
      "\n",
      "\n",
      "\\multirow{3}{*}{\\textbf{Real Examples}} & \\multirow{3}{*}{-} & 500 & 0 & 43.26\\textsubscript{26.86} & 98.93\\textsubscript{0.54} & 0.00\\textsubscript{0.00} & 99.37\\textsubscript{0.21} & 81.58\\textsubscript{5.02} & 98.03\\textsubscript{0.67} \\\\\n",
      " &  & 1,000 & 0 & 85.70\\textsubscript{8.04} & 99.57\\textsubscript{0.31} & 57.30\\textsubscript{31.65} & 99.63\\textsubscript{0.24} & 85.79\\textsubscript{4.59} & 98.40\\textsubscript{0.55} \\\\\n",
      " &  & 2,000 & 0 & 87.12\\textsubscript{9.44} & 99.60\\textsubscript{0.33} & 71.75\\textsubscript{21.87} & 99.67\\textsubscript{0.25} & 86.70\\textsubscript{5.19} & 98.50\\textsubscript{0.60} \\\\\n",
      "\\hline\n",
      "\\multirow{6}{*}{\\textbf{Llama-2-70B}} & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{25}}} & 25 & 475 & 62.42\\textsubscript{12.23} & 99.13\\textsubscript{0.41} & 33.93\\textsubscript{34.24} & 99.27\\textsubscript{0.41} & 53.97\\textsubscript{7.43} & 96.27\\textsubscript{0.67} \\\\\n",
      " &  & 25 & 975 & 66.59\\textsubscript{14.08} & 98.97\\textsubscript{0.53} & 33.60\\textsubscript{19.96} & 99.13\\textsubscript{0.22} & 65.99\\textsubscript{14.12} & 97.03\\textsubscript{1.12} \\\\\n",
      " &  & 25 & 1,975 & 64.62\\textsubscript{9.58} & 98.80\\textsubscript{0.71} & 38.84\\textsubscript{19.81} & 99.03\\textsubscript{0.44} & 65.91\\textsubscript{3.97} & 96.80\\textsubscript{0.43} \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-10}\\arrayrulecolor{black}\n",
      " & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{500}}} & 500 & 500 & 73.28\\textsubscript{16.92} & 99.23\\textsubscript{0.51} & 38.61\\textsubscript{23.38} & 99.10\\textsubscript{0.40} & 81.24\\textsubscript{3.15} & 98.03\\textsubscript{0.37} \\\\\n",
      " &  & 500 & 1,000 & 78.06\\textsubscript{19.04} & 99.40\\textsubscript{0.42} & 33.69\\textsubscript{29.10} & 99.17\\textsubscript{0.41} & 77.63\\textsubscript{2.58} & 97.70\\textsubscript{0.22} \\\\\n",
      " &  & 500 & 1,500 & 75.25\\textsubscript{11.02} & 99.30\\textsubscript{0.32} & 46.94\\textsubscript{26.92} & 99.27\\textsubscript{0.44} & 76.04\\textsubscript{5.43} & 97.60\\textsubscript{0.42} \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-10}\\arrayrulecolor{black}\n",
      "\\hline\n",
      "\\multirow{6}{*}{\\textbf{GPT-3.5-turbo}} & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{25}}} & 25 & 475 & 48.86\\textsubscript{18.74} & 98.97\\textsubscript{0.48} & 8.33\\textsubscript{18.63} & 99.33\\textsubscript{0.25} & 49.84\\textsubscript{17.50} & 96.33\\textsubscript{1.07} \\\\\n",
      " &  & 25 & 975 & 59.02\\textsubscript{14.47} & 98.83\\textsubscript{0.42} & 16.67\\textsubscript{25.46} & 99.10\\textsubscript{0.32} & 68.61\\textsubscript{7.40} & 97.13\\textsubscript{0.75} \\\\\n",
      " &  & 25 & 1,975 & 66.04\\textsubscript{4.35} & 98.87\\textsubscript{0.43} & 33.95\\textsubscript{11.22} & 98.73\\textsubscript{0.52} & 67.34\\textsubscript{7.45} & 96.87\\textsubscript{0.81} \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-10}\\arrayrulecolor{black}\n",
      " & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{500}}} & 500 & 500 & 69.66\\textsubscript{7.73} & 99.07\\textsubscript{0.43} & 61.94\\textsubscript{24.65} & 99.47\\textsubscript{0.39} & 80.04\\textsubscript{4.70} & 97.93\\textsubscript{0.50} \\\\\n",
      " &  & 500 & 1,000 & 77.42\\textsubscript{7.10} & 99.30\\textsubscript{0.34} & 63.06\\textsubscript{13.89} & 99.53\\textsubscript{0.19} & 82.33\\textsubscript{5.04} & 98.17\\textsubscript{0.58} \\\\\n",
      " &  & 500 & 1,500 & 71.70\\textsubscript{7.38} & 99.10\\textsubscript{0.34} & 62.94\\textsubscript{9.60} & 99.47\\textsubscript{0.19} & 80.67\\textsubscript{4.56} & 98.00\\textsubscript{0.69} \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-10}\\arrayrulecolor{black}\n",
      "\\hline\n"
     ]
    }
   ],
   "source": [
    "absa_task = \"aspect_category_sentiment\"\n",
    "\n",
    "idx = 0\n",
    "for ac_idx, aspect_categories in enumerate([[\"GENERAL-IMPRESSION\", \"FOOD\"], [\"SERVICE\", \"AMBIENCE\"], [\"PRICE\"]]):\n",
    "    print(\"Table for:\", aspect_categories, \"\\n\\n\")\n",
    "    for n_real_idx, n_real in enumerate([500, 1000, 2000]):\n",
    "        json_path = RESULTS_PATH_BASE + \\\n",
    "            f\"only_real_real{n_real}_synth0_{absa_task}_random.json\"\n",
    "        with open(json_path, 'r') as json_file:\n",
    "            results = json.load(json_file)\n",
    "\n",
    "        if n_real_idx == 0:\n",
    "            condition_print = \"\\\\multirow{3}{*}{\\\\textbf{Real Examples}} & \\\\multirow{3}{*}{-}\"\n",
    "        else:\n",
    "            condition_print = \" & \"\n",
    "\n",
    "        condition_string = f\"{condition_print} & {add_thousand_dots(str(n_real))} & 0 &\"\n",
    "        metrics_class_wise = \"\"\n",
    "        for ac in aspect_categories:\n",
    "            for polarity in [\"POSITIVE\", \"NEUTRAL\", \"NEGATIVE\"]:\n",
    "                for metric in [\"eval_f1\", \"eval_accuracy\"]:\n",
    "                    metrics_class_wise += f\" {get_metric(metric, ac, polarity, results)} &\"\n",
    "\n",
    "        print(condition_string + metrics_class_wise[:-1] + \"\\\\\\\\\")\n",
    "\n",
    "    print(\"\\\\hline\")\n",
    "    for llm_idx, llm in enumerate(LLMS):\n",
    "        for fs_idx, few_shot_condition in enumerate(SYNTH_COMBINATIONS.keys()):\n",
    "            for freq_idx, freq in enumerate(SYNTH_COMBINATIONS[few_shot_condition]):\n",
    "                n_real = freq[\"real\"]\n",
    "                n_synth = freq[\"synth\"]\n",
    "                json_path = RESULTS_PATH_BASE + llm + \\\n",
    "                    f\"_real{n_real}_synth{n_synth}_{absa_task}_{few_shot_condition}.json\"\n",
    "                with open(json_path, 'r') as json_file:\n",
    "                    results = json.load(json_file)\n",
    "\n",
    "                if fs_idx == 0 and freq_idx == 0:\n",
    "                    llm_print = \"\\\\multirow{6}{*}{\"+LLMS_ENCODED[llm]+\"}\"\n",
    "                else:\n",
    "                    llm_print = \"\"\n",
    "\n",
    "                if freq_idx == 0:\n",
    "                    condition_print = \"\\\\multirow{3}{*}{\" + \\\n",
    "                        ENCODE_CONDITION[few_shot_condition]+\"}\"\n",
    "                else:\n",
    "                    condition_print = \"\"\n",
    "\n",
    "                condition_string = f\"{llm_print} & {condition_print} & {add_thousand_dots(str(n_real))} & {add_thousand_dots(str(n_synth))} &\"\n",
    "                metrics_class_wise = \"\"\n",
    "                for ac in aspect_categories:\n",
    "                    for polarity in [\"POSITIVE\", \"NEUTRAL\", \"NEGATIVE\"]:\n",
    "                        for metric in [\"eval_f1\", \"eval_accuracy\"]:\n",
    "                            metrics_class_wise += f\" {get_metric(metric, ac, polarity, results)} &\"\n",
    "\n",
    "                print(condition_string + metrics_class_wise[:-1] + \"\\\\\\\\\")\n",
    "            \n",
    "                n_col = 10 if ac_idx == 2 else 16\n",
    "                if freq_idx == 2:\n",
    "                   print(\"\\\\arrayrulecolor{gray}\\cline{2-\"+str(n_col)+\"}\\\\arrayrulecolor{black}\")\n",
    "        print(\"\\hline\")\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_m1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
