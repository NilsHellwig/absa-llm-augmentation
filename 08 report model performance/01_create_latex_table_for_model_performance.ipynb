{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook: Convert Model Results to Latex\n",
    "\n",
    "This notebook is used to load the .json files with the model performance in order to convert them into a latex table for the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo: Schauen, ob es die Metriken auch bei anderen Modellen gibt\n",
    "# Todo: 1.000 <- Punkte einfÃ¼gen\n",
    "# Todo: Soll bei nur Real gehen\n",
    "# Todo: Soll bei allen Tasks gehen\n",
    "# Todo: bei f1 micro etc 3 nachkommastellen\n",
    "# Schauen, dass es bei jedem Task \"eval_f1_micro\", \"eval_f1_macro\", \"accuracy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings / Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_PATH_BASE = \"../07 train classifier/results_json/results_\"\n",
    "LLMS = [\"Llama70B\", \"GPT-3\"]\n",
    "LLM_PAPER_TITLE = {\"Llama70B\": \"Llama2-70B\", \"GPT-3\": \"GPT-3.5-turbo\"}\n",
    "# , \"aspect_category_sentiment\", \"end_2_end_absa\" ,\"target_aspect_sentiment_detection\"]\n",
    "ABSA_TASKS = [\"aspect_category\"]\n",
    "SYNTH_COMBINATIONS = {\n",
    "    \"random\": [\n",
    "        {\"real\": 500, \"synth\": 500},\n",
    "        {\"real\": 500, \"synth\": 1000},\n",
    "        {\"real\": 500, \"synth\": 1500}\n",
    "    ], \"fixed\": [\n",
    "        {\"real\": 25, \"synth\": 475},\n",
    "        {\"real\": 25, \"synth\": 975},\n",
    "        {\"real\": 25, \"synth\": 1975}\n",
    "    ]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEW_SHOT_STRATEGY = {25: \"25 fixed examples\", 500: \"25 random examples\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_thousands(number):\n",
    "    formatted_number = \"{:,}\".format(number)\n",
    "    return formatted_number\n",
    "\n",
    "def round_to_three_decimals(number):\n",
    "    rounded_number = round(number, 3)\n",
    "    return rounded_number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report Main Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_category :\n",
      "\n",
      "- & - & 500 & 0 & 0.061 & 0.033 & 0.026 \\\\\n",
      "- & - & 1,000 & 0 & 0.061 & 0.033 & 0.026 \\\\\n",
      "- & - & 2,000 & 0 & 0.061 & 0.033 & 0.026 \\\\\n",
      "\\hline\n",
      "Llama2-70B & 25 random examples & 500 & 500 & 0.061 & 0.026 & 0.026 \\\\\n",
      "Llama2-70B & 25 random examples & 500 & 1,000 & 0.061 & 0.026 & 0.026 \\\\\n",
      "Llama2-70B & 25 random examples & 500 & 1,500 & 0.061 & 0.026 & 0.026 \\\\\n",
      "GPT-3.5-turbo & 25 random examples & 500 & 500 & 0.061 & 0.026 & 0.026 \\\\\n",
      "GPT-3.5-turbo & 25 random examples & 500 & 1,000 & 0.061 & 0.026 & 0.026 \\\\\n",
      "GPT-3.5-turbo & 25 random examples & 500 & 1,500 & 0.061 & 0.026 & 0.026 \\\\\n",
      "\\hline\n",
      "Llama2-70B & 25 fixed examples & 25 & 475 & 0.061 & 0.026 & 0.026 \\\\\n",
      "Llama2-70B & 25 fixed examples & 25 & 975 & 0.061 & 0.026 & 0.026 \\\\\n",
      "Llama2-70B & 25 fixed examples & 25 & 1,975 & 0.061 & 0.026 & 0.026 \\\\\n",
      "GPT-3.5-turbo & 25 fixed examples & 25 & 475 & 0.061 & 0.026 & 0.026 \\\\\n",
      "GPT-3.5-turbo & 25 fixed examples & 25 & 975 & 0.061 & 0.026 & 0.026 \\\\\n",
      "GPT-3.5-turbo & 25 fixed examples & 25 & 1,975 & 0.061 & 0.026 & 0.026 \\\\\n",
      "\\hline\n"
     ]
    }
   ],
   "source": [
    "for absa_task in ABSA_TASKS:\n",
    "    print(absa_task, \":\\n\")\n",
    "    for n_real in [500, 1000, 2000]:\n",
    "        json_path = RESULTS_PATH_BASE + \\\n",
    "            f\"only_real_real{n_real}_synth0_{absa_task}_random.json\"\n",
    "        with open(json_path, 'r') as json_file:\n",
    "            results = json.load(json_file)\n",
    "        print(\n",
    "            f\"- & - & {format_thousands(n_real)} & 0 & {round_to_three_decimals(results['eval_f1_micro'])} & {round_to_three_decimals(results['eval_f1_macro'])} & {round_to_three_decimals(results['eval_accuracy'])} \\\\\\\\\")\n",
    "    print(\"\\\\hline\")\n",
    "    for few_shot_condition in SYNTH_COMBINATIONS.keys():\n",
    "        for llm in LLMS:\n",
    "            for freq in SYNTH_COMBINATIONS[few_shot_condition]:\n",
    "                n_real = freq[\"real\"]\n",
    "                n_synth = freq[\"synth\"]\n",
    "                json_path = RESULTS_PATH_BASE + llm + \\\n",
    "                    f\"_real{n_real}_synth{n_synth}_{absa_task}_{few_shot_condition}.json\"\n",
    "                with open(json_path, 'r') as json_file:\n",
    "                    results = json.load(json_file)\n",
    "                # print(f\"results: {absa_task}, {llm}, {few_shot_condition}, n_real: {n_real}, n_synth: {n_synth}\", results)\n",
    "                if absa_task == \"TASD\":\n",
    "                    f1_metrics = f\"{round_to_three_decimals(results['eval_f1_micro'])} & {round_to_three_decimals(results['eval_f1_macro'])}\"\n",
    "                else:\n",
    "                    f1_metrics = f\"{round_to_three_decimals(results['eval_f1_micro'])}\"\n",
    "                print(\n",
    "                    f\"{LLM_PAPER_TITLE[llm]} & {FEW_SHOT_STRATEGY[n_real]} & {format_thousands(n_real)} & {format_thousands(n_synth)} & {f1_metrics} & {round_to_three_decimals(results['eval_accuracy'])} & {round_to_three_decimals(results['eval_accuracy'])} \\\\\\\\\")\n",
    "        print(\"\\hline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report Metrics Fine-Grained Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ACSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table for: ['GENERAL-IMPRESSION', 'FOOD'] \n",
      "\n",
      "\n",
      "- & - & 500 & 0 & 0.278 & 0.234 & 0.342 & 0.044 & 0.026 & 0.143 & 0.0 & 0.0 & 0.0 & 0.152 & 0.241 & 0.111 & 0.079 & 0.044 & 0.348 & 0.381 & 0.268 & 0.662 &\\\\\n",
      "- & - & 1,000 & 0 & 0.278 & 0.234 & 0.342 & 0.044 & 0.026 & 0.143 & 0.0 & 0.0 & 0.0 & 0.152 & 0.241 & 0.111 & 0.079 & 0.044 & 0.348 & 0.381 & 0.268 & 0.662 &\\\\\n",
      "- & - & 2,000 & 0 & 0.278 & 0.234 & 0.342 & 0.044 & 0.026 & 0.143 & 0.0 & 0.0 & 0.0 & 0.152 & 0.241 & 0.111 & 0.079 & 0.044 & 0.348 & 0.381 & 0.268 & 0.662 &\\\\\n",
      "\\hline\n",
      "Llama2-70B & 25 random examples & 500 & 500 & 0.278 & 0.234 & 0.342 & 0.044 & 0.026 & 0.143 & 0.0 & 0.0 & 0.0 & 0.152 & 0.241 & 0.111 & 0.079 & 0.044 & 0.348 & 0.381 & 0.268 & 0.662 &\\\\\n",
      "Llama2-70B & 25 random examples & 500 & 1,000 & 0.278 & 0.234 & 0.342 & 0.044 & 0.026 & 0.143 & 0.0 & 0.0 & 0.0 & 0.152 & 0.241 & 0.111 & 0.079 & 0.044 & 0.348 & 0.381 & 0.268 & 0.662 &\\\\\n",
      "Llama2-70B & 25 random examples & 500 & 1,500 & 0.278 & 0.234 & 0.342 & 0.044 & 0.026 & 0.143 & 0.0 & 0.0 & 0.0 & 0.152 & 0.241 & 0.111 & 0.079 & 0.044 & 0.348 & 0.381 & 0.268 & 0.662 &\\\\\n",
      "GPT-3.5-turbo & 25 random examples & 500 & 500 & 0.278 & 0.234 & 0.342 & 0.044 & 0.026 & 0.143 & 0.0 & 0.0 & 0.0 & 0.152 & 0.241 & 0.111 & 0.079 & 0.044 & 0.348 & 0.381 & 0.268 & 0.662 &\\\\\n",
      "GPT-3.5-turbo & 25 random examples & 500 & 1,000 & 0.278 & 0.234 & 0.342 & 0.044 & 0.026 & 0.143 & 0.0 & 0.0 & 0.0 & 0.152 & 0.241 & 0.111 & 0.079 & 0.044 & 0.348 & 0.381 & 0.268 & 0.662 &\\\\\n",
      "GPT-3.5-turbo & 25 random examples & 500 & 1,500 & 0.278 & 0.234 & 0.342 & 0.044 & 0.026 & 0.143 & 0.0 & 0.0 & 0.0 & 0.152 & 0.241 & 0.111 & 0.079 & 0.044 & 0.348 & 0.381 & 0.268 & 0.662 &\\\\\n",
      "\\hline\n",
      "Llama2-70B & 25 fixed examples & 25 & 475 & 0.278 & 0.234 & 0.342 & 0.044 & 0.026 & 0.143 & 0.0 & 0.0 & 0.0 & 0.152 & 0.241 & 0.111 & 0.079 & 0.044 & 0.348 & 0.381 & 0.268 & 0.662 &\\\\\n",
      "Llama2-70B & 25 fixed examples & 25 & 975 & 0.278 & 0.234 & 0.342 & 0.044 & 0.026 & 0.143 & 0.0 & 0.0 & 0.0 & 0.152 & 0.241 & 0.111 & 0.079 & 0.044 & 0.348 & 0.381 & 0.268 & 0.662 &\\\\\n",
      "Llama2-70B & 25 fixed examples & 25 & 1,975 & 0.278 & 0.234 & 0.342 & 0.044 & 0.026 & 0.143 & 0.0 & 0.0 & 0.0 & 0.152 & 0.241 & 0.111 & 0.079 & 0.044 & 0.348 & 0.381 & 0.268 & 0.662 &\\\\\n",
      "GPT-3.5-turbo & 25 fixed examples & 25 & 475 & 0.278 & 0.234 & 0.342 & 0.044 & 0.026 & 0.143 & 0.0 & 0.0 & 0.0 & 0.152 & 0.241 & 0.111 & 0.079 & 0.044 & 0.348 & 0.381 & 0.268 & 0.662 &\\\\\n",
      "GPT-3.5-turbo & 25 fixed examples & 25 & 975 & 0.278 & 0.234 & 0.342 & 0.044 & 0.026 & 0.143 & 0.0 & 0.0 & 0.0 & 0.152 & 0.241 & 0.111 & 0.079 & 0.044 & 0.348 & 0.381 & 0.268 & 0.662 &\\\\\n",
      "GPT-3.5-turbo & 25 fixed examples & 25 & 1,975 & 0.278 & 0.234 & 0.342 & 0.044 & 0.026 & 0.143 & 0.0 & 0.0 & 0.0 & 0.152 & 0.241 & 0.111 & 0.079 & 0.044 & 0.348 & 0.381 & 0.268 & 0.662 &\\\\\n",
      "\\hline\n",
      "Table for: ['SERVICE', 'AMBIENCE', 'PRICE'] \n",
      "\n",
      "\n",
      " 0.082 & 0.2 & 0.051 & 0.012 & 0.006 & 0.5 & 0.302 & 0.199 & 0.623 & 0.217 & 0.151 & 0.383 & 0.0 & 0.0 & 0.0 & 0.075 & 0.04 & 0.588 & 0.036 & 0.019 & 0.571 & 0.0 & 0.0 & 0.0 & 0.056 & 0.034 & 0.143 \\\\\n",
      " 0.082 & 0.2 & 0.051 & 0.012 & 0.006 & 0.5 & 0.302 & 0.199 & 0.623 & 0.217 & 0.151 & 0.383 & 0.0 & 0.0 & 0.0 & 0.075 & 0.04 & 0.588 & 0.036 & 0.019 & 0.571 & 0.0 & 0.0 & 0.0 & 0.056 & 0.034 & 0.143 \\\\\n",
      " 0.082 & 0.2 & 0.051 & 0.012 & 0.006 & 0.5 & 0.302 & 0.199 & 0.623 & 0.217 & 0.151 & 0.383 & 0.0 & 0.0 & 0.0 & 0.075 & 0.04 & 0.588 & 0.036 & 0.019 & 0.571 & 0.0 & 0.0 & 0.0 & 0.056 & 0.034 & 0.143 \\\\\n",
      "\\hline\n",
      " 0.082 & 0.2 & 0.051 & 0.012 & 0.006 & 0.5 & 0.302 & 0.199 & 0.623 & 0.217 & 0.151 & 0.383 & 0.0 & 0.0 & 0.0 & 0.075 & 0.04 & 0.588 & 0.036 & 0.019 & 0.571 & 0.0 & 0.0 & 0.0 & 0.056 & 0.034 & 0.143 \\\\\n",
      " 0.082 & 0.2 & 0.051 & 0.012 & 0.006 & 0.5 & 0.302 & 0.199 & 0.623 & 0.217 & 0.151 & 0.383 & 0.0 & 0.0 & 0.0 & 0.075 & 0.04 & 0.588 & 0.036 & 0.019 & 0.571 & 0.0 & 0.0 & 0.0 & 0.056 & 0.034 & 0.143 \\\\\n",
      " 0.082 & 0.2 & 0.051 & 0.012 & 0.006 & 0.5 & 0.302 & 0.199 & 0.623 & 0.217 & 0.151 & 0.383 & 0.0 & 0.0 & 0.0 & 0.075 & 0.04 & 0.588 & 0.036 & 0.019 & 0.571 & 0.0 & 0.0 & 0.0 & 0.056 & 0.034 & 0.143 \\\\\n",
      " 0.082 & 0.2 & 0.051 & 0.012 & 0.006 & 0.5 & 0.302 & 0.199 & 0.623 & 0.217 & 0.151 & 0.383 & 0.0 & 0.0 & 0.0 & 0.075 & 0.04 & 0.588 & 0.036 & 0.019 & 0.571 & 0.0 & 0.0 & 0.0 & 0.056 & 0.034 & 0.143 \\\\\n",
      " 0.082 & 0.2 & 0.051 & 0.012 & 0.006 & 0.5 & 0.302 & 0.199 & 0.623 & 0.217 & 0.151 & 0.383 & 0.0 & 0.0 & 0.0 & 0.075 & 0.04 & 0.588 & 0.036 & 0.019 & 0.571 & 0.0 & 0.0 & 0.0 & 0.056 & 0.034 & 0.143 \\\\\n",
      " 0.082 & 0.2 & 0.051 & 0.012 & 0.006 & 0.5 & 0.302 & 0.199 & 0.623 & 0.217 & 0.151 & 0.383 & 0.0 & 0.0 & 0.0 & 0.075 & 0.04 & 0.588 & 0.036 & 0.019 & 0.571 & 0.0 & 0.0 & 0.0 & 0.056 & 0.034 & 0.143 \\\\\n",
      "\\hline\n",
      " 0.082 & 0.2 & 0.051 & 0.012 & 0.006 & 0.5 & 0.302 & 0.199 & 0.623 & 0.217 & 0.151 & 0.383 & 0.0 & 0.0 & 0.0 & 0.075 & 0.04 & 0.588 & 0.036 & 0.019 & 0.571 & 0.0 & 0.0 & 0.0 & 0.056 & 0.034 & 0.143 \\\\\n",
      " 0.082 & 0.2 & 0.051 & 0.012 & 0.006 & 0.5 & 0.302 & 0.199 & 0.623 & 0.217 & 0.151 & 0.383 & 0.0 & 0.0 & 0.0 & 0.075 & 0.04 & 0.588 & 0.036 & 0.019 & 0.571 & 0.0 & 0.0 & 0.0 & 0.056 & 0.034 & 0.143 \\\\\n",
      " 0.082 & 0.2 & 0.051 & 0.012 & 0.006 & 0.5 & 0.302 & 0.199 & 0.623 & 0.217 & 0.151 & 0.383 & 0.0 & 0.0 & 0.0 & 0.075 & 0.04 & 0.588 & 0.036 & 0.019 & 0.571 & 0.0 & 0.0 & 0.0 & 0.056 & 0.034 & 0.143 \\\\\n",
      " 0.082 & 0.2 & 0.051 & 0.012 & 0.006 & 0.5 & 0.302 & 0.199 & 0.623 & 0.217 & 0.151 & 0.383 & 0.0 & 0.0 & 0.0 & 0.075 & 0.04 & 0.588 & 0.036 & 0.019 & 0.571 & 0.0 & 0.0 & 0.0 & 0.056 & 0.034 & 0.143 \\\\\n",
      " 0.082 & 0.2 & 0.051 & 0.012 & 0.006 & 0.5 & 0.302 & 0.199 & 0.623 & 0.217 & 0.151 & 0.383 & 0.0 & 0.0 & 0.0 & 0.075 & 0.04 & 0.588 & 0.036 & 0.019 & 0.571 & 0.0 & 0.0 & 0.0 & 0.056 & 0.034 & 0.143 \\\\\n",
      " 0.082 & 0.2 & 0.051 & 0.012 & 0.006 & 0.5 & 0.302 & 0.199 & 0.623 & 0.217 & 0.151 & 0.383 & 0.0 & 0.0 & 0.0 & 0.075 & 0.04 & 0.588 & 0.036 & 0.019 & 0.571 & 0.0 & 0.0 & 0.0 & 0.056 & 0.034 & 0.143 \\\\\n",
      "\\hline\n"
     ]
    }
   ],
   "source": [
    "absa_task = \"aspect_category_sentiment\"\n",
    "\n",
    "idx = 0\n",
    "for aspect_categories in [[\"GENERAL-IMPRESSION\", \"FOOD\"], [\"SERVICE\", \"AMBIENCE\", \"PRICE\"]]:\n",
    "    print(\"Table for:\", aspect_categories, \"\\n\\n\")\n",
    "    for n_real in [500, 1000, 2000]:\n",
    "        json_path = RESULTS_PATH_BASE + \\\n",
    "            f\"only_real_real{n_real}_synth0_{absa_task}_random.json\"\n",
    "        with open(json_path, 'r') as json_file:\n",
    "            results = json.load(json_file)\n",
    "\n",
    "        condition_string = f\"- & - & {format_thousands(n_real)} & 0 &\"\n",
    "        metrics_class_wise = \"\"\n",
    "        for ac in aspect_categories:\n",
    "            for polarity in [\"POSITIVE\", \"NEUTRAL\", \"NEGATIVE\"]:\n",
    "                for metric in [\"eval_f1\", \"eval_precision\", \"eval_recall\"]:\n",
    "                    metrics_class_wise += f\" {round_to_three_decimals(results[f'{metric}_{ac}-{polarity}'])} &\"\n",
    "\n",
    "        print(condition_string + metrics_class_wise + \"\\\\\\\\\") if idx == 0 else print(metrics_class_wise[:-1] + \"\\\\\\\\\")\n",
    "\n",
    "    print(\"\\\\hline\")\n",
    "    for few_shot_condition in SYNTH_COMBINATIONS.keys():\n",
    "        for llm in LLMS:\n",
    "            for freq in SYNTH_COMBINATIONS[few_shot_condition]:\n",
    "                n_real = freq[\"real\"]\n",
    "                n_synth = freq[\"synth\"]\n",
    "                json_path = RESULTS_PATH_BASE + llm + \\\n",
    "                    f\"_real{n_real}_synth{n_synth}_{absa_task}_{few_shot_condition}.json\"\n",
    "                with open(json_path, 'r') as json_file:\n",
    "                    results = json.load(json_file)\n",
    "\n",
    "                condition_string = f\"{LLM_PAPER_TITLE[llm]} & {FEW_SHOT_STRATEGY[n_real]} & {format_thousands(n_real)} & {format_thousands(n_synth)} &\"\n",
    "                metrics_class_wise = \"\"\n",
    "                for ac in aspect_categories:\n",
    "                    for polarity in [\"POSITIVE\", \"NEUTRAL\", \"NEGATIVE\"]:\n",
    "                        for metric in [\"eval_f1\", \"eval_precision\", \"eval_recall\"]:\n",
    "                            metrics_class_wise += f\" {round_to_three_decimals(results[f'{metric}_{ac}-{polarity}'])} &\"\n",
    "\n",
    "                print(condition_string + metrics_class_wise + \"\\\\\\\\\") if idx == 0 else print(metrics_class_wise[:-1] + \"\\\\\\\\\")\n",
    "        print(\"\\hline\")\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_m1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
