{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook: Convert Model Results to Latex\n",
    "\n",
    "This notebook is used to load the .json files with the model performance in order to convert them into a latex table for the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo: Schauen, ob es die Metriken auch bei anderen Modellen gibt\n",
    "# Todo: 1.000 <- Punkte einfÃ¼gen\n",
    "# Todo: Soll bei nur Real gehen\n",
    "# Todo: Soll bei allen Tasks gehen\n",
    "# Todo: bei f1 micro etc 3 nachkommastellen\n",
    "# Schauen, dass es bei jedem Task \"eval_f1_micro\", \"eval_f1_macro\", \"accuracy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings / Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_PATH_BASE = \"../07 train models/results_json/results_\"\n",
    "LLMS = [\"Llama70B\", \"GPT-3\"]\n",
    "# , \"aspect_category_sentiment\", \"end_2_end_absa\" ,\"target_aspect_sentiment_detection\"]\n",
    "ABSA_TASKS = [\"aspect_category\", \"aspect_category_sentiment\"]#, \"end_2_end_absa\", \"target_aspect_sentiment_detection\"]\n",
    "SYNTH_COMBINATIONS = {\n",
    "    \"random\": [\n",
    "        {\"real\": 500, \"synth\": 500},\n",
    "        {\"real\": 500, \"synth\": 1000},\n",
    "        {\"real\": 500, \"synth\": 1500}\n",
    "    ], \"fixed\": [\n",
    "        {\"real\": 25, \"synth\": 475},\n",
    "        {\"real\": 25, \"synth\": 975},\n",
    "        {\"real\": 25, \"synth\": 1975}\n",
    "    ]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "LLMS_ENCODED = {\"GPT-3\": \"\\\\textbf{GPT-3.5-turbo}\", \"Llama70B\": \"\\\\textbf{Llama-2-70B}\"}\n",
    "ENCODE_CONDITION = {\"fixed\": \"\\\\textbf{LRS\\\\textsubscript{25}}\",\n",
    "                    \"random\": \"\\\\textbf{LRS\\\\textsubscript{500}}\"}\n",
    "\n",
    "N_METRICS = {\"aspect_category\": 6, \"aspect_category_sentiment\": 6,\n",
    "             \"end_2_end_absa\": 6, \"target_aspect_sentiment_detection\": 5}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_number(num, decimal_places):\n",
    "    formatted_num = \"{:.{}f}\".format(num, decimal_places)\n",
    "    rounded_num_str = \"{:.{}f}\".format(float(formatted_num), decimal_places)\n",
    "    return rounded_num_str\n",
    "\n",
    "def add_thousand_dots(n_sample):\n",
    "    if isinstance(n_sample, str):\n",
    "        if '.' in n_sample:\n",
    "            integer_part, decimal_part = n_sample.split('.')\n",
    "            formatted_integer_part = \"{:,}\".format(int(integer_part))\n",
    "            result = f\"{formatted_integer_part}.{decimal_part}\"\n",
    "        else:\n",
    "            result = \"{:,}\".format(int(n_sample))\n",
    "    elif isinstance(n_sample, np.float64):\n",
    "        result = \"{:,}\".format(round(n_sample, 1))\n",
    "    else:\n",
    "        result = n_sample\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report Main Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_category :\n",
      "\n",
      " -------#-----#-----#-------\n",
      "\\multirow{3}{*}{\\textbf{Real Examples}} & \\multirow{3}{*}{-} & 500 & 0 & 0.910 & 0.899 & 0.841 \\\\\n",
      " &  & 1,000 & 0 & 0.916 & 0.906 & 0.852 \\\\\n",
      " &  & 2,000 & 0 & 0.926 & 0.916 & 0.868 \\\\\n",
      "\\hline\n",
      "\\multirow{6}{*}{\\textbf{Llama-2-70B}} & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{25}}} & 25 & 475 & 0.768 & 0.758 & 0.630 \\\\\n",
      " &  & 25 & 975 & 0.764 & 0.755 & 0.626 \\\\\n",
      " &  & 25 & 1,975 & 0.779 & 0.764 & 0.656 \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-7}\\arrayrulecolor{black}\n",
      " & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{500}}} & 500 & 500 & 0.885 & 0.876 & 0.800 \\\\\n",
      " &  & 500 & 1,000 & 0.873 & 0.863 & 0.782 \\\\\n",
      " &  & 500 & 1,500 & 0.870 & 0.862 & 0.780 \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-7}\\arrayrulecolor{black}\n",
      "\\hline\n",
      "\\multirow{6}{*}{\\textbf{GPT-3.5-turbo}} & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{25}}} & 25 & 475 & 0.807 & 0.804 & 0.682 \\\\\n",
      " &  & 25 & 975 & 0.793 & 0.788 & 0.672 \\\\\n",
      " &  & 25 & 1,975 & 0.794 & 0.789 & 0.670 \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-7}\\arrayrulecolor{black}\n",
      " & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{500}}} & 500 & 500 & 0.907 & 0.900 & 0.838 \\\\\n",
      " &  & 500 & 1,000 & 0.905 & 0.897 & 0.831 \\\\\n",
      " &  & 500 & 1,500 & 0.902 & 0.894 & 0.826 \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-7}\\arrayrulecolor{black}\n",
      "\\hline\n",
      "\n",
      "\n",
      "\n",
      "aspect_category_sentiment :\n",
      "\n",
      " -------#-----#-----#-------\n",
      "\\multirow{3}{*}{\\textbf{Real Examples}} & \\multirow{3}{*}{-} & 500 & 0 & 0.856 & 0.640 & 0.777 \\\\\n",
      " &  & 1,000 & 0 & 0.881 & 0.743 & 0.806 \\\\\n",
      " &  & 2,000 & 0 & 0.885 & 0.717 & 0.812 \\\\\n",
      "\\hline\n",
      "\\multirow{6}{*}{\\textbf{Llama-2-70B}} & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{25}}} & 25 & 475 & 0.401 & 0.332 & 0.297 \\\\\n",
      " &  & 25 & 975 & 0.395 & 0.326 & 0.305 \\\\\n",
      " &  & 25 & 1,975 & 0.638 & 0.523 & 0.501 \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-7}\\arrayrulecolor{black}\n",
      " & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{500}}} & 500 & 500 & 0.816 & 0.645 & 0.720 \\\\\n",
      " &  & 500 & 1,000 & 0.664 & 0.515 & 0.582 \\\\\n",
      " &  & 500 & 1,500 & 0.529 & 0.432 & 0.464 \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-7}\\arrayrulecolor{black}\n",
      "\\hline\n",
      "\\multirow{6}{*}{\\textbf{GPT-3.5-turbo}} & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{25}}} & 25 & 475 & 0.726 & 0.622 & 0.579 \\\\\n",
      " &  & 25 & 975 & 0.724 & 0.600 & 0.580 \\\\\n",
      " &  & 25 & 1,975 & 0.718 & 0.612 & 0.568 \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-7}\\arrayrulecolor{black}\n",
      " & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{500}}} & 500 & 500 & 0.862 & 0.761 & 0.779 \\\\\n",
      " &  & 500 & 1,000 & 0.714 & 0.627 & 0.645 \\\\\n",
      " &  & 500 & 1,500 & 0.863 & 0.750 & 0.780 \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-7}\\arrayrulecolor{black}\n",
      "\\hline\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for absa_task in ABSA_TASKS:\n",
    "    print(absa_task, \":\\n\\n\", \"-------#-----#-----#-------\")\n",
    "    for n_real_idx, n_real in enumerate([500, 1000, 2000]):\n",
    "        if n_real_idx == 0:\n",
    "            condition_print = \"\\\\multirow{3}{*}{\\\\textbf{Real Examples}} & \\\\multirow{3}{*}{-}\"\n",
    "        else:\n",
    "            condition_print = \" & \"\n",
    "\n",
    "        json_path = RESULTS_PATH_BASE + \\\n",
    "            f\"only_real_real{n_real}_synth0_{absa_task}_random.json\"\n",
    "\n",
    "        with open(json_path, 'r') as json_file:\n",
    "            results = json.load(json_file)\n",
    "        if absa_task != \"target_aspect_sentiment_detection\":\n",
    "            print(\n",
    "                f\"{condition_print} & {add_thousand_dots(str(n_real))} & 0 & {add_thousand_dots(round_number(results['eval_f1_micro'], 3))} & {add_thousand_dots(round_number(results['eval_f1_macro'], 3))} & {add_thousand_dots(round_number(results['eval_accuracy'], 3))} \\\\\\\\\")\n",
    "        else:\n",
    "            print(\n",
    "                f\"{condition_print} & {add_thousand_dots(str(n_real))} & 0 & {add_thousand_dots(round_number(results['eval_f1'], 3))} & {add_thousand_dots(round_number(results['eval_accuracy'], 3))} \\\\\\\\\")\n",
    "\n",
    "    print(\"\\\\hline\")\n",
    "    for llm_idx, llm in enumerate(LLMS):\n",
    "        for fs_idx, few_shot_condition in enumerate([\"fixed\", \"random\"]):\n",
    "            for freq_idx, freq in enumerate(SYNTH_COMBINATIONS[few_shot_condition]):\n",
    "                n_real = freq[\"real\"]\n",
    "                n_synth = freq[\"synth\"]\n",
    "                json_path = RESULTS_PATH_BASE + llm + \\\n",
    "                    f\"_real{n_real}_synth{n_synth}_{absa_task}_{few_shot_condition}.json\"\n",
    "                with open(json_path, 'r') as json_file:\n",
    "                    results = json.load(json_file)\n",
    "\n",
    "                if fs_idx == 0 and freq_idx == 0:\n",
    "                    llm_print = \"\\\\multirow{6}{*}{\"+LLMS_ENCODED[llm]+\"}\"\n",
    "                else:\n",
    "                    llm_print = \"\"\n",
    "\n",
    "                if freq_idx == 0:\n",
    "                    condition_print = \"\\\\multirow{3}{*}{\" + \\\n",
    "                        ENCODE_CONDITION[few_shot_condition]+\"}\"\n",
    "                else:\n",
    "                    condition_print = \"\"\n",
    "\n",
    "                if absa_task != \"target_aspect_sentiment_detection\":\n",
    "                    f1_metrics = f\"{add_thousand_dots(round_number(results['eval_f1_micro'], 3))} & {add_thousand_dots(round_number(results['eval_f1_macro'], 3))}\"\n",
    "                else:\n",
    "                    f1_metrics = f\"{add_thousand_dots(round_number(results['eval_f1'], 3))}\"\n",
    "                print(\n",
    "                    f\"{llm_print} & {condition_print} & {add_thousand_dots(str(n_real))} & {add_thousand_dots(str(n_synth))} & {f1_metrics} & {add_thousand_dots(round_number(results['eval_accuracy'], 3))} \\\\\\\\\")\n",
    "\n",
    "                # print(llm_idx, fs_idx, freq_idx)\n",
    "            if freq_idx == 2:\n",
    "                print(\n",
    "                    \"\\\\arrayrulecolor{gray}\\cline{2-\"+str(N_METRICS[absa_task]+1)+\"}\\\\arrayrulecolor{black}\")\n",
    "            else:\n",
    "                print(\"\\\\hline\")\n",
    "        print(\"\\hline\")\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report Metrics Fine-Grained Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ACD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\multirow{3}{*}{\\textbf{Real Examples}} & \\multirow{3}{*}{-} & 500 & 0 & 0.858 &0.932 &0.939 &0.948 &0.928 &0.954 &0.863 &0.962 &0.909 &0.986  \\\\\n",
      " &  & 1,000 & 0 & 0.860 &0.932 &0.944 &0.952 &0.942 &0.963 &0.865 &0.962 &0.919 &0.987  \\\\\n",
      " &  & 2,000 & 0 & 0.881 &0.941 &0.954 &0.961 &0.946 &0.965 &0.878 &0.965 &0.921 &0.988  \\\\\n",
      "\\hline\n",
      "\\multirow{6}{*}{\\textbf{Llama-2-70B}} & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{500}}} & 500 & 500 & 0.822 &0.909 &0.915 &0.929 &0.912 &0.945 &0.851 &0.959 &0.880 &0.981  \\\\\n",
      " &  & 500 & 1,000 & 0.818 &0.905 &0.901 &0.919 &0.904 &0.941 &0.826 &0.952 &0.864 &0.979  \\\\\n",
      " &  & 500 & 1,500 & 0.811 &0.901 &0.895 &0.915 &0.900 &0.938 &0.840 &0.956 &0.865 &0.979  \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-14}\\arrayrulecolor{black}\n",
      " & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{500}}} & 500 & 500 & 0.864 &0.931 &0.933 &0.943 &0.924 &0.953 &0.862 &0.963 &0.915 &0.987  \\\\\n",
      " &  & 500 & 1,000 & 0.858 &0.928 &0.933 &0.943 &0.920 &0.950 &0.867 &0.964 &0.907 &0.985  \\\\\n",
      " &  & 500 & 1,500 & 0.843 &0.920 &0.936 &0.946 &0.918 &0.948 &0.868 &0.964 &0.905 &0.985  \\\\\n",
      "\\hline\n",
      "\\multirow{6}{*}{\\textbf{Llama-2-70B}} & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{25}}} & 25 & 475 & 0.687 &0.814 &0.836 &0.864 &0.786 &0.882 &0.693 &0.907 &0.785 &0.960  \\\\\n",
      " &  & 25 & 975 & 0.677 &0.796 &0.833 &0.865 &0.794 &0.884 &0.695 &0.914 &0.775 &0.960  \\\\\n",
      " &  & 25 & 1,975 & 0.711 &0.824 &0.850 &0.880 &0.799 &0.888 &0.706 &0.916 &0.753 &0.955  \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-14}\\arrayrulecolor{black}\n",
      " & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{25}}} & 25 & 475 & 0.749 &0.857 &0.880 &0.899 &0.742 &0.866 &0.785 &0.942 &0.863 &0.977  \\\\\n",
      " &  & 25 & 975 & 0.736 &0.840 &0.878 &0.900 &0.717 &0.858 &0.766 &0.941 &0.846 &0.973  \\\\\n",
      " &  & 25 & 1,975 & 0.728 &0.832 &0.884 &0.906 &0.728 &0.861 &0.765 &0.938 &0.839 &0.972  \\\\\n",
      "\\hline\n"
     ]
    }
   ],
   "source": [
    "absa_task = \"aspect_category\"\n",
    "for n_real_idx, n_real in enumerate([500, 1000, 2000]):\n",
    "    json_path = RESULTS_PATH_BASE + \\\n",
    "        f\"only_real_real{n_real}_synth0_{absa_task}_random.json\"\n",
    "    with open(json_path, 'r') as json_file:\n",
    "        results = json.load(json_file)\n",
    "\n",
    "    if n_real_idx == 0:\n",
    "        condition_print = \"\\\\multirow{3}{*}{\\\\textbf{Real Examples}} & \\\\multirow{3}{*}{-}\"\n",
    "    else:\n",
    "        condition_print = \" & \"\n",
    "\n",
    "    class_wise_metrics = \"\"\n",
    "    for ac in [\"GENERAL-IMPRESSION\", \"FOOD\", \"SERVICE\", \"AMBIENCE\", \"PRICE\"]:\n",
    "        for metric in [\"f1\", \"accuracy\"]:\n",
    "            class_wise_metrics += f\"{add_thousand_dots(round_number(results[f'eval_{metric}_{ac}'], 3))} &\"\n",
    "    print(\n",
    "        f\"{condition_print} & {add_thousand_dots(str(n_real))} & 0 & {class_wise_metrics[:-1]} \\\\\\\\\")\n",
    "print(\"\\\\hline\")\n",
    "for fs_idx, few_shot_condition in enumerate(SYNTH_COMBINATIONS.keys()):\n",
    "    for llm_idx, llm in enumerate(LLMS):\n",
    "        for freq_idx, freq in enumerate(SYNTH_COMBINATIONS[few_shot_condition]):\n",
    "            n_real = freq[\"real\"]\n",
    "            n_synth = freq[\"synth\"]\n",
    "            json_path = RESULTS_PATH_BASE + llm + \\\n",
    "                f\"_real{n_real}_synth{n_synth}_{absa_task}_{few_shot_condition}.json\"\n",
    "            with open(json_path, 'r') as json_file:\n",
    "                results = json.load(json_file)\n",
    "            # print(f\"results: {absa_task}, {llm}, {few_shot_condition}, n_real: {n_real}, n_synth: {n_synth}\", results)\n",
    "            if absa_task == \"TASD\":\n",
    "                f1_metrics = f\"{add_thousand_dots(results['eval_f1_micro'])} & {add_thousand_dots(results['eval_f1_macro'])}\"\n",
    "            else:\n",
    "                f1_metrics = f\"{add_thousand_dots(results['eval_f1_micro'])}\"\n",
    "\n",
    "            if llm_idx == 0 and freq_idx == 0:\n",
    "                llm_print = \"\\\\multirow{6}{*}{\"+LLMS_ENCODED[llm]+\"}\"\n",
    "            else:\n",
    "                llm_print = \"\"\n",
    "\n",
    "            if freq_idx == 0:\n",
    "                condition_print = \"\\\\multirow{3}{*}{\" + \\\n",
    "                    ENCODE_CONDITION[few_shot_condition]+\"}\"\n",
    "            else:\n",
    "                condition_print = \"\"\n",
    "\n",
    "            class_wise_metrics = \"\"\n",
    "            for ac in [\"GENERAL-IMPRESSION\", \"FOOD\", \"SERVICE\", \"AMBIENCE\", \"PRICE\"]:\n",
    "                for metric in [\"f1\", \"accuracy\"]:\n",
    "                    class_wise_metrics += f\"{add_thousand_dots(round_number(results[f'eval_{metric}_{ac}'], 3))} &\"\n",
    "\n",
    "            print(\n",
    "                f\"{llm_print} & {condition_print} & {add_thousand_dots(str(n_real))} & {add_thousand_dots(str(n_synth))} & {class_wise_metrics[:-1]} \\\\\\\\\")\n",
    "            if freq_idx == 2 and llm_idx == 0:\n",
    "               print(\n",
    "                \"\\\\arrayrulecolor{gray}\\cline{2-14}\\\\arrayrulecolor{black}\")\n",
    "\n",
    "    print(\"\\hline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ACSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table for: ['GENERAL-IMPRESSION', 'FOOD'] \n",
      "\n",
      "\n",
      "\\multirow{3}{*}{\\textbf{Real Examples}} & \\multirow{3}{*}{-} & 500 & 0 & 0.828 & 0.956 & 0.159 & 0.992 & 0.825 & 0.964 & 0.924 & 0.963 & 0.763 & 0.983 & 0.826 & 0.943 \\\\\n",
      " &  & 1,000 & 0 & 0.852 & 0.962 & 0.667 & 0.995 & 0.838 & 0.966 & 0.933 & 0.968 & 0.839 & 0.988 & 0.855 & 0.952 \\\\\n",
      " &  & 2,000 & 0 & 0.850 & 0.961 & 0.634 & 0.994 & 0.848 & 0.968 & 0.942 & 0.972 & 0.832 & 0.987 & 0.859 & 0.954 \\\\\n",
      "\\hline\n",
      "\\multirow{6}{*}{\\textbf{Llama-2-70B}} & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{500}}} & 500 & 500 & 0.789 & 0.945 & 0.317 & 0.989 & 0.819 & 0.961 & 0.886 & 0.947 & 0.598 & 0.972 & 0.812 & 0.939 \\\\\n",
      " &  & 500 & 1,000 & 0.644 & 0.932 & 0.308 & 0.987 & 0.669 & 0.945 & 0.715 & 0.911 & 0.450 & 0.969 & 0.674 & 0.924 \\\\\n",
      " &  & 500 & 1,500 & 0.511 & 0.918 & 0.251 & 0.990 & 0.530 & 0.937 & 0.579 & 0.879 & 0.344 & 0.965 & 0.530 & 0.906 \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-16}\\arrayrulecolor{black}\n",
      " & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{500}}} & 500 & 500 & 0.841 & 0.959 & 0.623 & 0.994 & 0.827 & 0.963 & 0.913 & 0.959 & 0.813 & 0.986 & 0.841 & 0.948 \\\\\n",
      " &  & 500 & 1,000 & 0.686 & 0.937 & 0.577 & 0.994 & 0.684 & 0.948 & 0.761 & 0.926 & 0.688 & 0.984 & 0.697 & 0.927 \\\\\n",
      " &  & 500 & 1,500 & 0.843 & 0.957 & 0.570 & 0.993 & 0.836 & 0.964 & 0.913 & 0.959 & 0.797 & 0.985 & 0.844 & 0.950 \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-16}\\arrayrulecolor{black}\n",
      "\\hline\n",
      "\\multirow{6}{*}{\\textbf{Llama-2-70B}} & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{25}}} & 25 & 475 & 0.439 & 0.903 & 0.085 & 0.967 & 0.353 & 0.904 & 0.445 & 0.836 & 0.295 & 0.951 & 0.423 & 0.877 \\\\\n",
      " &  & 25 & 975 & 0.396 & 0.892 & 0.062 & 0.965 & 0.383 & 0.904 & 0.420 & 0.830 & 0.232 & 0.943 & 0.457 & 0.885 \\\\\n",
      " &  & 25 & 1,975 & 0.642 & 0.916 & 0.193 & 0.967 & 0.684 & 0.928 & 0.695 & 0.884 & 0.402 & 0.941 & 0.716 & 0.917 \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-16}\\arrayrulecolor{black}\n",
      " & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{25}}} & 25 & 475 & 0.687 & 0.909 & 0.367 & 0.992 & 0.617 & 0.925 & 0.843 & 0.928 & 0.710 & 0.978 & 0.716 & 0.921 \\\\\n",
      " &  & 25 & 975 & 0.696 & 0.905 & 0.380 & 0.984 & 0.651 & 0.921 & 0.832 & 0.922 & 0.716 & 0.975 & 0.745 & 0.927 \\\\\n",
      " &  & 25 & 1,975 & 0.697 & 0.909 & 0.353 & 0.986 & 0.661 & 0.924 & 0.827 & 0.921 & 0.619 & 0.964 & 0.728 & 0.924 \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-16}\\arrayrulecolor{black}\n",
      "\\hline\n",
      "Table for: ['SERVICE', 'AMBIENCE'] \n",
      "\n",
      "\n",
      "\\multirow{3}{*}{\\textbf{Real Examples}} & \\multirow{3}{*}{-} & 500 & 0 & 0.931 & 0.977 & 0.000 & 0.996 & 0.881 & 0.964 & 0.852 & 0.972 & 0.000 & 0.998 & 0.703 & 0.978 \\\\\n",
      " &  & 1,000 & 0 & 0.941 & 0.980 & 0.333 & 0.997 & 0.895 & 0.968 & 0.864 & 0.974 & 0.000 & 0.998 & 0.806 & 0.985 \\\\\n",
      " &  & 2,000 & 0 & 0.944 & 0.981 & 0.000 & 0.996 & 0.895 & 0.968 & 0.867 & 0.974 & 0.000 & 0.998 & 0.814 & 0.985 \\\\\n",
      "\\hline\n",
      "\\multirow{6}{*}{\\textbf{Llama-2-70B}} & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{500}}} & 500 & 500 & 0.863 & 0.957 & 0.274 & 0.991 & 0.858 & 0.959 & 0.790 & 0.963 & 0.071 & 0.992 & 0.766 & 0.983 \\\\\n",
      " &  & 500 & 1,000 & 0.712 & 0.933 & 0.147 & 0.989 & 0.718 & 0.940 & 0.634 & 0.951 & 0.062 & 0.993 & 0.567 & 0.974 \\\\\n",
      " &  & 500 & 1,500 & 0.558 & 0.906 & 0.170 & 0.989 & 0.567 & 0.923 & 0.525 & 0.945 & 0.100 & 0.994 & 0.454 & 0.968 \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-16}\\arrayrulecolor{black}\n",
      " & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{500}}} & 500 & 500 & 0.921 & 0.974 & 0.713 & 0.998 & 0.875 & 0.963 & 0.866 & 0.975 & 0.667 & 0.998 & 0.749 & 0.981 \\\\\n",
      " &  & 500 & 1,000 & 0.770 & 0.949 & 0.400 & 0.996 & 0.726 & 0.946 & 0.706 & 0.960 & 0.667 & 0.998 & 0.630 & 0.978 \\\\\n",
      " &  & 500 & 1,500 & 0.923 & 0.974 & 0.733 & 0.998 & 0.879 & 0.964 & 0.844 & 0.972 & 0.367 & 0.998 & 0.794 & 0.984 \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-16}\\arrayrulecolor{black}\n",
      "\\hline\n",
      "\\multirow{6}{*}{\\textbf{Llama-2-70B}} & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{25}}} & 25 & 475 & 0.434 & 0.882 & 0.049 & 0.974 & 0.427 & 0.895 & 0.382 & 0.926 & 0.098 & 0.979 & 0.396 & 0.967 \\\\\n",
      " &  & 25 & 975 & 0.432 & 0.884 & 0.038 & 0.975 & 0.434 & 0.898 & 0.387 & 0.927 & 0.086 & 0.986 & 0.382 & 0.967 \\\\\n",
      " &  & 25 & 1,975 & 0.673 & 0.915 & 0.140 & 0.970 & 0.683 & 0.925 & 0.502 & 0.934 & 0.088 & 0.979 & 0.615 & 0.973 \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-16}\\arrayrulecolor{black}\n",
      " & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{25}}} & 25 & 475 & 0.813 & 0.944 & 0.429 & 0.994 & 0.639 & 0.921 & 0.660 & 0.949 & 0.792 & 0.998 & 0.678 & 0.978 \\\\\n",
      " &  & 25 & 975 & 0.818 & 0.946 & 0.398 & 0.992 & 0.622 & 0.917 & 0.651 & 0.948 & 0.492 & 0.996 & 0.689 & 0.977 \\\\\n",
      " &  & 25 & 1,975 & 0.825 & 0.948 & 0.428 & 0.991 & 0.634 & 0.918 & 0.636 & 0.946 & 0.558 & 0.994 & 0.650 & 0.973 \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-16}\\arrayrulecolor{black}\n",
      "\\hline\n",
      "Table for: ['PRICE'] \n",
      "\n",
      "\n",
      "\\multirow{3}{*}{\\textbf{Real Examples}} & \\multirow{3}{*}{-} & 500 & 0 & 0.697 & 0.992 & 0.411 & 0.995 & 0.804 & 0.978 \\\\\n",
      " &  & 1,000 & 0 & 0.807 & 0.995 & 0.729 & 0.997 & 0.845 & 0.983 \\\\\n",
      " &  & 2,000 & 0 & 0.843 & 0.996 & 0.550 & 0.996 & 0.875 & 0.986 \\\\\n",
      "\\hline\n",
      "\\multirow{6}{*}{\\textbf{Llama-2-70B}} & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{500}}} & 500 & 500 & 0.717 & 0.992 & 0.400 & 0.992 & 0.781 & 0.977 \\\\\n",
      " &  & 500 & 1,000 & 0.576 & 0.990 & 0.253 & 0.991 & 0.643 & 0.970 \\\\\n",
      " &  & 500 & 1,500 & 0.491 & 0.990 & 0.431 & 0.995 & 0.494 & 0.965 \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-10}\\arrayrulecolor{black}\n",
      " & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{500}}} & 500 & 500 & 0.674 & 0.990 & 0.617 & 0.995 & 0.813 & 0.980 \\\\\n",
      " &  & 500 & 1,000 & 0.544 & 0.988 & 0.479 & 0.994 & 0.675 & 0.975 \\\\\n",
      " &  & 500 & 1,500 & 0.720 & 0.992 & 0.605 & 0.995 & 0.829 & 0.982 \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-10}\\arrayrulecolor{black}\n",
      "\\hline\n",
      "\\multirow{6}{*}{\\textbf{Llama-2-70B}} & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{25}}} & 25 & 475 & 0.392 & 0.986 & 0.322 & 0.991 & 0.480 & 0.964 \\\\\n",
      " &  & 25 & 975 & 0.477 & 0.989 & 0.320 & 0.992 & 0.420 & 0.960 \\\\\n",
      " &  & 25 & 1,975 & 0.761 & 0.991 & 0.407 & 0.991 & 0.703 & 0.972 \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-10}\\arrayrulecolor{black}\n",
      " & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{25}}} & 25 & 475 & 0.540 & 0.987 & 0.487 & 0.994 & 0.689 & 0.970 \\\\\n",
      " &  & 25 & 975 & 0.577 & 0.987 & 0.291 & 0.990 & 0.673 & 0.969 \\\\\n",
      " &  & 25 & 1,975 & 0.695 & 0.990 & 0.449 & 0.990 & 0.671 & 0.967 \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-10}\\arrayrulecolor{black}\n",
      "\\hline\n"
     ]
    }
   ],
   "source": [
    "absa_task = \"aspect_category_sentiment\"\n",
    "\n",
    "idx = 0\n",
    "for ac_idx, aspect_categories in enumerate([[\"GENERAL-IMPRESSION\", \"FOOD\"], [\"SERVICE\", \"AMBIENCE\"], [\"PRICE\"]]):\n",
    "    print(\"Table for:\", aspect_categories, \"\\n\\n\")\n",
    "    for n_real_idx, n_real in enumerate([500, 1000, 2000]):\n",
    "        json_path = RESULTS_PATH_BASE + \\\n",
    "            f\"only_real_real{n_real}_synth0_{absa_task}_random.json\"\n",
    "        with open(json_path, 'r') as json_file:\n",
    "            results = json.load(json_file)\n",
    "\n",
    "        if n_real_idx == 0:\n",
    "            condition_print = \"\\\\multirow{3}{*}{\\\\textbf{Real Examples}} & \\\\multirow{3}{*}{-}\"\n",
    "        else:\n",
    "            condition_print = \" & \"\n",
    "\n",
    "        condition_string = f\"{condition_print} & {add_thousand_dots(str(n_real))} & 0 &\"\n",
    "        metrics_class_wise = \"\"\n",
    "        for ac in aspect_categories:\n",
    "            for polarity in [\"POSITIVE\", \"NEUTRAL\", \"NEGATIVE\"]:\n",
    "                for metric in [\"eval_f1\", \"eval_accuracy\"]:\n",
    "                    metrics_class_wise += f\" {add_thousand_dots(round_number(results[f'{metric}_{ac}-{polarity}'], 3))} &\"\n",
    "\n",
    "        print(condition_string + metrics_class_wise[:-1] + \"\\\\\\\\\")\n",
    "\n",
    "    print(\"\\\\hline\")\n",
    "    for fs_idx, few_shot_condition in enumerate(SYNTH_COMBINATIONS.keys()):\n",
    "        for llm_idx, llm in enumerate(LLMS):\n",
    "            for freq_idx, freq in enumerate(SYNTH_COMBINATIONS[few_shot_condition]):\n",
    "                n_real = freq[\"real\"]\n",
    "                n_synth = freq[\"synth\"]\n",
    "                json_path = RESULTS_PATH_BASE + llm + \\\n",
    "                    f\"_real{n_real}_synth{n_synth}_{absa_task}_{few_shot_condition}.json\"\n",
    "                with open(json_path, 'r') as json_file:\n",
    "                    results = json.load(json_file)\n",
    "\n",
    "                if llm_idx == 0 and freq_idx == 0:\n",
    "                    llm_print = \"\\\\multirow{6}{*}{\"+LLMS_ENCODED[llm]+\"}\"\n",
    "                else:\n",
    "                    llm_print = \"\"\n",
    "\n",
    "                if freq_idx == 0:\n",
    "                    condition_print = \"\\\\multirow{3}{*}{\" + \\\n",
    "                        ENCODE_CONDITION[few_shot_condition]+\"}\"\n",
    "                else:\n",
    "                    condition_print = \"\"\n",
    "\n",
    "                condition_string = f\"{llm_print} & {condition_print} & {add_thousand_dots(str(n_real))} & {add_thousand_dots(str(n_synth))} &\"\n",
    "                metrics_class_wise = \"\"\n",
    "                for ac in aspect_categories:\n",
    "                    for polarity in [\"POSITIVE\", \"NEUTRAL\", \"NEGATIVE\"]:\n",
    "                        for metric in [\"eval_f1\", \"eval_accuracy\"]:\n",
    "                            metrics_class_wise += f\" {add_thousand_dots(round_number(results[f'{metric}_{ac}-{polarity}'], 3))} &\"\n",
    "\n",
    "                print(condition_string + metrics_class_wise[:-1] + \"\\\\\\\\\")\n",
    "            \n",
    "                n_col = 10 if ac_idx == 2 else 16\n",
    "                if freq_idx == 2:\n",
    "                   print(\"\\\\arrayrulecolor{gray}\\cline{2-\"+str(n_col)+\"}\\\\arrayrulecolor{black}\")\n",
    "        print(\"\\hline\")\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'llllllllllllllllllllll' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[200], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mllllllllllllllllllllll\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'llllllllllllllllllllll' is not defined"
     ]
    }
   ],
   "source": [
    "llllllllllllllllllllll"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_m1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
