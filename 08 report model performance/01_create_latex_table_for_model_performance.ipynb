{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook: Convert Model Results to Latex\n",
    "\n",
    "This notebook is used to load the .json files with the model performance in order to convert them into a latex table for the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo: Schauen, ob es die Metriken auch bei anderen Modellen gibt\n",
    "# Todo: 1.000 <- Punkte einfÃ¼gen\n",
    "# Todo: Soll bei nur Real gehen\n",
    "# Todo: Soll bei allen Tasks gehen\n",
    "# Todo: bei f1 micro etc 3 nachkommastellen\n",
    "# Schauen, dass es bei jedem Task \"eval_f1_micro\", \"eval_f1_macro\", \"accuracy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings / Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_PATH_BASE = \"../07 train models/results_json/results_\"\n",
    "LLMS = [\"Llama70B\"]#, \"GPT-3\"]\n",
    "LLM_PAPER_TITLE = {\"Llama70B\": \"Llama-2-70B\", \"GPT-3\": \"GPT-3.5-turbo\"}\n",
    "# , \"aspect_category_sentiment\", \"end_2_end_absa\" ,\"target_aspect_sentiment_detection\"]\n",
    "ABSA_TASKS = [\"aspect_category\", \"aspect_category_sentiment\", \"end_2_end_absa\", \"target_aspect_sentiment_detection\"]\n",
    "SYNTH_COMBINATIONS = {\n",
    "    \"random\": [\n",
    "        {\"real\": 500, \"synth\": 500},\n",
    "        {\"real\": 500, \"synth\": 1000},\n",
    "        {\"real\": 500, \"synth\": 1500}\n",
    "    ], \"fixed\": [\n",
    "        {\"real\": 25, \"synth\": 475},\n",
    "        {\"real\": 25, \"synth\": 975},\n",
    "        {\"real\": 25, \"synth\": 1975}\n",
    "    ]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEW_SHOT_STRATEGY = {25: \"25 fixed examples\", 500: \"25 random examples\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_thousands(number):\n",
    "    formatted_number = \"{:,}\".format(number)\n",
    "    return formatted_number\n",
    "\n",
    "def round_to_three_decimals(number):\n",
    "    rounded_number = round(number, 3)\n",
    "    return rounded_number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report Main Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_category :\n",
      "\n",
      "- & - & 500 & 0 & 0.867 & 0.866 & 0.778 \\\\\n",
      "- & - & 1,000 & 0 & 0.899 & 0.889 & 0.824 \\\\\n",
      "- & - & 2,000 & 0 & 0.903 & 0.893 & 0.826 \\\\\n",
      "\\hline\n",
      "Llama-2-70B & 25 random examples & 500 & 500 & 0.839 & 0.833 & 0.726 \\\\\n",
      "Llama-2-70B & 25 random examples & 500 & 1,000 & 0.854 & 0.834 & 0.742 \\\\\n",
      "Llama-2-70B & 25 random examples & 500 & 1,500 & 0.832 & 0.823 & 0.734 \\\\\n",
      "\\hline\n",
      "Llama-2-70B & 25 fixed examples & 25 & 475 & 0.693 & 0.701 & 0.476 \\\\\n",
      "Llama-2-70B & 25 fixed examples & 25 & 975 & 0.74 & 0.747 & 0.596 \\\\\n",
      "Llama-2-70B & 25 fixed examples & 25 & 1,975 & 0.79 & 0.779 & 0.676 \\\\\n",
      "\\hline\n",
      "aspect_category_sentiment :\n",
      "\n",
      "- & - & 500 & 0 & 0.789 & 0.552 & 0.68 \\\\\n",
      "- & - & 1,000 & 0 & 0.819 & 0.592 & 0.732 \\\\\n",
      "- & - & 2,000 & 0 & 0.833 & 0.671 & 0.748 \\\\\n",
      "\\hline\n",
      "Llama-2-70B & 25 random examples & 500 & 500 & 0.736 & 0.534 & 0.602 \\\\\n",
      "Llama-2-70B & 25 random examples & 500 & 1,000 & 0.739 & 0.568 & 0.604 \\\\\n",
      "Llama-2-70B & 25 random examples & 500 & 1,500 & 0.742 & 0.546 & 0.58 \\\\\n",
      "\\hline\n",
      "Llama-2-70B & 25 fixed examples & 25 & 475 & 0.487 & 0.368 & 0.326 \\\\\n",
      "Llama-2-70B & 25 fixed examples & 25 & 975 & 0.548 & 0.456 & 0.384 \\\\\n",
      "Llama-2-70B & 25 fixed examples & 25 & 1,975 & 0.571 & 0.47 & 0.416 \\\\\n",
      "\\hline\n",
      "end_2_end_absa :\n",
      "\n",
      "- & - & 500 & 0 & 0.708 & 0.619 & 0.549 \\\\\n",
      "- & - & 1,000 & 0 & 0.757 & 0.733 & 0.609 \\\\\n",
      "- & - & 2,000 & 0 & 0.779 & 0.758 & 0.639 \\\\\n",
      "\\hline\n",
      "Llama-2-70B & 25 random examples & 500 & 500 & 0.684 & 0.56 & 0.52 \\\\\n",
      "Llama-2-70B & 25 random examples & 500 & 1,000 & 0.669 & 0.59 & 0.503 \\\\\n",
      "Llama-2-70B & 25 random examples & 500 & 1,500 & 0.683 & 0.605 & 0.519 \\\\\n",
      "\\hline\n",
      "Llama-2-70B & 25 fixed examples & 25 & 475 & 0.5 & 0.41 & 0.334 \\\\\n",
      "Llama-2-70B & 25 fixed examples & 25 & 975 & 0.519 & 0.434 & 0.351 \\\\\n",
      "Llama-2-70B & 25 fixed examples & 25 & 1,975 & 0.535 & 0.456 & 0.365 \\\\\n",
      "\\hline\n",
      "target_aspect_sentiment_detection :\n",
      "\n",
      "- & - & 500 & 0 & 0.618 & 0.448 \\\\\n",
      "- & - & 1,000 & 0 & 0.652 & 0.484 \\\\\n",
      "- & - & 2,000 & 0 & 0.692 & 0.53 \\\\\n",
      "\\hline\n",
      "Llama-2-70B & 25 random examples & 500 & 500 & 0.571 & 0.399 \\\\\n",
      "Llama-2-70B & 25 random examples & 500 & 1,000 & 0.572 & 0.401 \\\\\n",
      "Llama-2-70B & 25 random examples & 500 & 1,500 & 0.541 & 0.371 \\\\\n",
      "\\hline\n",
      "Llama-2-70B & 25 fixed examples & 25 & 475 & 0.355 & 0.216 \\\\\n",
      "Llama-2-70B & 25 fixed examples & 25 & 975 & 0.392 & 0.244 \\\\\n",
      "Llama-2-70B & 25 fixed examples & 25 & 1,975 & 0.413 & 0.26 \\\\\n",
      "\\hline\n"
     ]
    }
   ],
   "source": [
    "for absa_task in ABSA_TASKS:\n",
    "    print(absa_task, \":\\n\")\n",
    "    for n_real in [500, 1000, 2000]:\n",
    "        json_path = RESULTS_PATH_BASE + \\\n",
    "            f\"only_real_real{n_real}_synth0_{absa_task}_random.json\"\n",
    "        with open(json_path, 'r') as json_file:\n",
    "            results = json.load(json_file)\n",
    "        if absa_task != \"target_aspect_sentiment_detection\":\n",
    "            print(\n",
    "                f\"- & - & {format_thousands(n_real)} & 0 & {round_to_three_decimals(results['eval_f1_micro'])} & {round_to_three_decimals(results['eval_f1_macro'])} & {round_to_three_decimals(results['eval_accuracy'])} \\\\\\\\\")\n",
    "        else:\n",
    "            print(f\"- & - & {format_thousands(n_real)} & 0 & {round_to_three_decimals(results['eval_f1'])} & {round_to_three_decimals(results['eval_accuracy'])} \\\\\\\\\")\n",
    "    print(\"\\\\hline\")\n",
    "    for few_shot_condition in SYNTH_COMBINATIONS.keys():\n",
    "        for llm in LLMS:\n",
    "            for freq in SYNTH_COMBINATIONS[few_shot_condition]:\n",
    "                n_real = freq[\"real\"]\n",
    "                n_synth = freq[\"synth\"]\n",
    "                json_path = RESULTS_PATH_BASE + llm + \\\n",
    "                    f\"_real{n_real}_synth{n_synth}_{absa_task}_{few_shot_condition}.json\"\n",
    "                with open(json_path, 'r') as json_file:\n",
    "                    results = json.load(json_file)\n",
    "                # print(f\"results: {absa_task}, {llm}, {few_shot_condition}, n_real: {n_real}, n_synth: {n_synth}\", results)\n",
    "                if absa_task != \"target_aspect_sentiment_detection\":\n",
    "                    f1_metrics = f\"{round_to_three_decimals(results['eval_f1_micro'])} & {round_to_three_decimals(results['eval_f1_macro'])}\"\n",
    "                else:\n",
    "                    f1_metrics = f\"{round_to_three_decimals(results['eval_f1'])}\"\n",
    "                print(\n",
    "                    f\"{LLM_PAPER_TITLE[llm]} & {FEW_SHOT_STRATEGY[n_real]} & {format_thousands(n_real)} & {format_thousands(n_synth)} & {f1_metrics} & {round_to_three_decimals(results['eval_accuracy'])} \\\\\\\\\")\n",
    "        print(\"\\hline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report Metrics Fine-Grained Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ACD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- & - & 500 & 0 & 0.783 &0.896 &0.894 &0.91 &0.896 &0.926 &0.812 &0.952 &0.944 &0.992  \\\\\n",
      "- & - & 1,000 & 0 & 0.821 &0.91 &0.92 &0.932 &0.955 &0.97 &0.844 &0.954 &0.904 &0.986  \\\\\n",
      "- & - & 2,000 & 0 & 0.836 &0.912 &0.933 &0.944 &0.949 &0.966 &0.827 &0.948 &0.921 &0.988  \\\\\n",
      "\\hline\n",
      "Llama-2-70B & 25 random examples & 500 & 500 & 0.776 &0.894 &0.866 &0.896 &0.865 &0.906 &0.788 &0.944 &0.868 &0.98  \\\\\n",
      "Llama-2-70B & 25 random examples & 500 & 1,000 & 0.797 &0.902 &0.886 &0.908 &0.911 &0.942 &0.753 &0.928 &0.825 &0.972  \\\\\n",
      "Llama-2-70B & 25 random examples & 500 & 1,500 & 0.792 &0.892 &0.824 &0.866 &0.897 &0.936 &0.797 &0.948 &0.805 &0.966  \\\\\n",
      "\\hline\n",
      "Llama-2-70B & 25 fixed examples & 25 & 475 & 0.555 &0.634 &0.729 &0.774 &0.836 &0.902 &0.677 &0.92 &0.706 &0.95  \\\\\n",
      "Llama-2-70B & 25 fixed examples & 25 & 975 & 0.654 &0.816 &0.735 &0.808 &0.823 &0.896 &0.71 &0.91 &0.811 &0.972  \\\\\n",
      "Llama-2-70B & 25 fixed examples & 25 & 1,975 & 0.74 &0.844 &0.811 &0.856 &0.839 &0.902 &0.733 &0.936 &0.771 &0.968  \\\\\n",
      "\\hline\n"
     ]
    }
   ],
   "source": [
    "absa_task = \"aspect_category\"\n",
    "for n_real in [500, 1000, 2000]:\n",
    "    json_path = RESULTS_PATH_BASE + \\\n",
    "        f\"only_real_real{n_real}_synth0_{absa_task}_random.json\"\n",
    "    with open(json_path, 'r') as json_file:\n",
    "        results = json.load(json_file)\n",
    "    class_wise_metrics = \"\"\n",
    "    for ac in [\"GENERAL-IMPRESSION\", \"FOOD\", \"SERVICE\", \"AMBIENCE\", \"PRICE\"]:\n",
    "       for metric in [\"f1\", \"accuracy\"]:\n",
    "           class_wise_metrics += f\"{round_to_three_decimals(results[f'eval_{metric}_{ac}'])} &\"\n",
    "    print(f\"- & - & {format_thousands(n_real)} & 0 & {class_wise_metrics[:-1]} \\\\\\\\\")\n",
    "print(\"\\\\hline\")\n",
    "for few_shot_condition in SYNTH_COMBINATIONS.keys():\n",
    "    for llm in LLMS:\n",
    "        for freq in SYNTH_COMBINATIONS[few_shot_condition]:\n",
    "            n_real = freq[\"real\"]\n",
    "            n_synth = freq[\"synth\"]\n",
    "            json_path = RESULTS_PATH_BASE + llm + \\\n",
    "                f\"_real{n_real}_synth{n_synth}_{absa_task}_{few_shot_condition}.json\"\n",
    "            with open(json_path, 'r') as json_file:\n",
    "                results = json.load(json_file)\n",
    "            # print(f\"results: {absa_task}, {llm}, {few_shot_condition}, n_real: {n_real}, n_synth: {n_synth}\", results)\n",
    "            if absa_task == \"TASD\":\n",
    "                f1_metrics = f\"{round_to_three_decimals(results['eval_f1_micro'])} & {round_to_three_decimals(results['eval_f1_macro'])}\"\n",
    "            else:\n",
    "                f1_metrics = f\"{round_to_three_decimals(results['eval_f1_micro'])}\"\n",
    "\n",
    "            class_wise_metrics = \"\"\n",
    "            for ac in [\"GENERAL-IMPRESSION\", \"FOOD\", \"SERVICE\", \"AMBIENCE\", \"PRICE\"]:\n",
    "                for metric in [\"f1\", \"accuracy\"]:\n",
    "                   class_wise_metrics += f\"{round_to_three_decimals(results[f'eval_{metric}_{ac}'])} &\"\n",
    "\n",
    "            print(\n",
    "                    f\"{LLM_PAPER_TITLE[llm]} & {FEW_SHOT_STRATEGY[n_real]} & {format_thousands(n_real)} & {format_thousands(n_synth)} & {class_wise_metrics[:-1]} \\\\\\\\\")\n",
    "    print(\"\\hline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ACSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table for: ['GENERAL-IMPRESSION', 'FOOD'] \n",
      "\n",
      "\n",
      "- & - & 500 & 0 & 0.797 & 0.833 & 0.764 & 0.0 & 0.0 & 0.0 & 0.654 & 0.723 & 0.596 & 0.869 & 0.88 & 0.858 & 0.727 & 0.75 & 0.706 & 0.68 & 0.718 & 0.646 \\\\\n",
      "- & - & 1,000 & 0 & 0.832 & 0.877 & 0.792 & 0.0 & 0.0 & 0.0 & 0.673 & 0.72 & 0.632 & 0.893 & 0.92 & 0.867 & 0.833 & 0.789 & 0.882 & 0.732 & 0.757 & 0.709 \\\\\n",
      "- & - & 2,000 & 0 & 0.824 & 0.803 & 0.847 & 0.571 & 1.0 & 0.4 & 0.694 & 0.829 & 0.596 & 0.911 & 0.93 & 0.892 & 0.756 & 0.607 & 1.0 & 0.765 & 0.747 & 0.785 \\\\\n",
      "\\hline\n",
      "Llama-2-70B & 25 random examples & 500 & 500 & 0.718 & 0.933 & 0.583 & 0.0 & 0.0 & 0.0 & 0.66 & 0.767 & 0.579 & 0.812 & 0.875 & 0.758 & 0.3 & 1.0 & 0.176 & 0.691 & 0.675 & 0.709 \\\\\n",
      "Llama-2-70B & 25 random examples & 500 & 1,000 & 0.776 & 0.839 & 0.722 & 0.0 & 0.0 & 0.0 & 0.646 & 0.762 & 0.561 & 0.8 & 0.88 & 0.733 & 0.286 & 0.364 & 0.235 & 0.618 & 0.864 & 0.481 \\\\\n",
      "Llama-2-70B & 25 random examples & 500 & 1,500 & 0.818 & 0.862 & 0.778 & 0.0 & 0.0 & 0.0 & 0.729 & 0.78 & 0.684 & 0.787 & 0.912 & 0.692 & 0.286 & 0.75 & 0.176 & 0.662 & 0.746 & 0.595 \\\\\n",
      "\\hline\n",
      "Llama-2-70B & 25 fixed examples & 25 & 475 & 0.336 & 0.514 & 0.25 & 0.118 & 0.069 & 0.4 & 0.393 & 0.42 & 0.368 & 0.5 & 1.0 & 0.333 & 0.195 & 0.167 & 0.235 & 0.627 & 0.649 & 0.608 \\\\\n",
      "Llama-2-70B & 25 fixed examples & 25 & 975 & 0.525 & 0.64 & 0.444 & 0.059 & 0.034 & 0.2 & 0.474 & 0.575 & 0.404 & 0.619 & 0.918 & 0.467 & 0.267 & 0.308 & 0.235 & 0.62 & 0.8 & 0.506 \\\\\n",
      "Llama-2-70B & 25 fixed examples & 25 & 1,975 & 0.614 & 0.709 & 0.542 & 0.133 & 0.1 & 0.2 & 0.56 & 0.651 & 0.491 & 0.598 & 0.963 & 0.433 & 0.485 & 0.5 & 0.471 & 0.631 & 0.804 & 0.519 \\\\\n",
      "\\hline\n",
      "Table for: ['SERVICE', 'AMBIENCE', 'PRICE'] \n",
      "\n",
      "\n",
      " 0.894 & 0.935 & 0.857 & 0.0 & 0.0 & 0.0 & 0.791 & 0.756 & 0.829 & 0.871 & 0.846 & 0.898 & 0.0 & 0.0 & 0.0 & 0.571 & 0.526 & 0.625 & 0.571 & 0.667 & 0.5 & 0.0 & 0.0 & 0.0 & 0.847 & 0.893 & 0.806 \\\\\n",
      " 0.902 & 0.925 & 0.881 & 0.0 & 0.0 & 0.0 & 0.818 & 0.766 & 0.878 & 0.9 & 0.882 & 0.918 & 0.0 & 0.0 & 0.0 & 0.706 & 0.667 & 0.75 & 0.75 & 0.75 & 0.75 & 0.0 & 0.0 & 0.0 & 0.836 & 0.958 & 0.742 \\\\\n",
      " 0.922 & 0.928 & 0.917 & 0.0 & 0.0 & 0.0 & 0.852 & 0.828 & 0.878 & 0.913 & 0.87 & 0.959 & 0.0 & 0.0 & 0.0 & 0.591 & 0.464 & 0.812 & 0.75 & 0.75 & 0.75 & 0.667 & 1.0 & 0.5 & 0.842 & 0.923 & 0.774 \\\\\n",
      "\\hline\n",
      " 0.85 & 0.942 & 0.774 & 0.167 & 0.1 & 0.5 & 0.781 & 0.855 & 0.72 & 0.713 & 0.816 & 0.633 & 0.0 & 0.0 & 0.0 & 0.593 & 0.727 & 0.5 & 0.5 & 0.5 & 0.5 & 0.4 & 0.333 & 0.5 & 0.821 & 0.92 & 0.742 \\\\\n",
      " 0.855 & 0.907 & 0.81 & 0.4 & 0.333 & 0.5 & 0.762 & 0.862 & 0.683 & 0.821 & 0.848 & 0.796 & 0.0 & 0.0 & 0.0 & 0.593 & 0.727 & 0.5 & 0.727 & 0.571 & 1.0 & 0.444 & 0.286 & 1.0 & 0.792 & 0.955 & 0.677 \\\\\n",
      " 0.852 & 0.93 & 0.786 & 0.0 & 0.0 & 0.0 & 0.771 & 0.931 & 0.659 & 0.611 & 0.957 & 0.449 & 0.0 & 0.0 & 0.0 & 0.741 & 0.909 & 0.625 & 0.667 & 1.0 & 0.5 & 0.5 & 0.5 & 0.5 & 0.769 & 0.952 & 0.645 \\\\\n",
      "\\hline\n",
      " 0.636 & 0.911 & 0.488 & 0.111 & 0.062 & 0.5 & 0.631 & 0.701 & 0.573 & 0.479 & 0.773 & 0.347 & 0.0 & 0.0 & 0.0 & 0.5 & 0.583 & 0.438 & 0.25 & 0.25 & 0.25 & 0.25 & 0.167 & 0.5 & 0.5 & 0.846 & 0.355 \\\\\n",
      " 0.646 & 0.953 & 0.488 & 0.286 & 0.2 & 0.5 & 0.588 & 0.946 & 0.427 & 0.595 & 0.88 & 0.449 & 0.286 & 0.167 & 1.0 & 0.621 & 0.692 & 0.562 & 0.571 & 0.4 & 1.0 & 0.182 & 0.111 & 0.5 & 0.5 & 0.846 & 0.355 \\\\\n",
      " 0.618 & 0.974 & 0.452 & 0.333 & 0.25 & 0.5 & 0.595 & 0.923 & 0.439 & 0.448 & 0.833 & 0.306 & 0.0 & 0.0 & 0.0 & 0.417 & 0.625 & 0.312 & 0.571 & 0.667 & 0.5 & 0.5 & 0.333 & 1.0 & 0.545 & 0.923 & 0.387 \\\\\n",
      "\\hline\n"
     ]
    }
   ],
   "source": [
    "absa_task = \"aspect_category_sentiment\"\n",
    "\n",
    "idx = 0\n",
    "for aspect_categories in [[\"GENERAL-IMPRESSION\", \"FOOD\"], [\"SERVICE\", \"AMBIENCE\", \"PRICE\"]]:\n",
    "    print(\"Table for:\", aspect_categories, \"\\n\\n\")\n",
    "    for n_real in [500, 1000, 2000]:\n",
    "        json_path = RESULTS_PATH_BASE + \\\n",
    "            f\"only_real_real{n_real}_synth0_{absa_task}_random.json\"\n",
    "        with open(json_path, 'r') as json_file:\n",
    "            results = json.load(json_file)\n",
    "\n",
    "        condition_string = f\"- & - & {format_thousands(n_real)} & 0 &\"\n",
    "        metrics_class_wise = \"\"\n",
    "        for ac in aspect_categories:\n",
    "            for polarity in [\"POSITIVE\", \"NEUTRAL\", \"NEGATIVE\"]:\n",
    "                for metric in [\"eval_f1\", \"eval_precision\", \"eval_recall\"]:\n",
    "                    metrics_class_wise += f\" {round_to_three_decimals(results[f'{metric}_{ac}-{polarity}'])} &\"\n",
    "\n",
    "        print(condition_string + metrics_class_wise[:-1] + \"\\\\\\\\\") if idx == 0 else print(metrics_class_wise[:-1] + \"\\\\\\\\\")\n",
    "\n",
    "    print(\"\\\\hline\")\n",
    "    for few_shot_condition in SYNTH_COMBINATIONS.keys():\n",
    "        for llm in LLMS:\n",
    "            for freq in SYNTH_COMBINATIONS[few_shot_condition]:\n",
    "                n_real = freq[\"real\"]\n",
    "                n_synth = freq[\"synth\"]\n",
    "                json_path = RESULTS_PATH_BASE + llm + \\\n",
    "                    f\"_real{n_real}_synth{n_synth}_{absa_task}_{few_shot_condition}.json\"\n",
    "                with open(json_path, 'r') as json_file:\n",
    "                    results = json.load(json_file)\n",
    "\n",
    "                condition_string = f\"{LLM_PAPER_TITLE[llm]} & {FEW_SHOT_STRATEGY[n_real]} & {format_thousands(n_real)} & {format_thousands(n_synth)} &\"\n",
    "                metrics_class_wise = \"\"\n",
    "                for ac in aspect_categories:\n",
    "                    for polarity in [\"POSITIVE\", \"NEUTRAL\", \"NEGATIVE\"]:\n",
    "                        for metric in [\"eval_f1\", \"eval_precision\", \"eval_recall\"]:\n",
    "                            metrics_class_wise += f\" {round_to_three_decimals(results[f'{metric}_{ac}-{polarity}'])} &\"\n",
    "\n",
    "                print(condition_string + metrics_class_wise[:-1] + \"\\\\\\\\\") if idx == 0 else print(metrics_class_wise[:-1] + \"\\\\\\\\\")\n",
    "        print(\"\\hline\")\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_m1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
