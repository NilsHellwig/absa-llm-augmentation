{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook: Convert Model Results to Latex\n",
    "\n",
    "This notebook is used to load the .json files with the model performance in order to convert them into a latex table for the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo: Schauen, ob es die Metriken auch bei anderen Modellen gibt\n",
    "# Todo: 1.000 <- Punkte einfÃ¼gen\n",
    "# Todo: Soll bei nur Real gehen\n",
    "# Todo: Soll bei allen Tasks gehen\n",
    "# Todo: bei f1 micro etc 3 nachkommastellen\n",
    "# Schauen, dass es bei jedem Task \"eval_f1_micro\", \"eval_f1_macro\", \"accuracy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings / Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_PATH_BASE = \"../07 train classifier/results_json/results_\"\n",
    "LLMS = [\"Llama70B\", \"GPT-3\"]\n",
    "LLM_PAPER_TITLE = {\"Llama70B\": \"Llama2-70B\", \"GPT-3\": \"GPT-3.5-turbo\"}\n",
    "# , \"aspect_category_sentiment\", \"end_2_end_absa\" ,\"target_aspect_sentiment_detection\"]\n",
    "ABSA_TASKS = [\"aspect_category\"]\n",
    "SYNTH_COMBINATIONS = {\n",
    "    \"random\": [\n",
    "        {\"real\": 500, \"synth\": 500},\n",
    "        {\"real\": 500, \"synth\": 1000},\n",
    "        {\"real\": 500, \"synth\": 1500}\n",
    "    ], \"fixed\": [\n",
    "        {\"real\": 25, \"synth\": 475},\n",
    "        {\"real\": 25, \"synth\": 975},\n",
    "        {\"real\": 25, \"synth\": 1975}\n",
    "    ]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEW_SHOT_STRATEGY = {25: \"25 fixed examples\", 500: \"25 random examples\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_thousands(number):\n",
    "    formatted_number = \"{:,}\".format(number)\n",
    "    return formatted_number\n",
    "\n",
    "def round_to_three_decimals(number):\n",
    "    rounded_number = round(number, 3)\n",
    "    return rounded_number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report Main Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_category :\n",
      "\n",
      "- & - & 500 & 0 & 0.061 & 0.033 & 0.026 \\\\\n",
      "- & - & 1,000 & 0 & 0.061 & 0.033 & 0.026 \\\\\n",
      "- & - & 2,000 & 0 & 0.061 & 0.033 & 0.026 \\\\\n",
      "\\hline\n",
      "Llama2-70B & 25 random examples & 500 & 500 & 0.061 & 0.026 & 0.026 \\\\\n",
      "Llama2-70B & 25 random examples & 500 & 1,000 & 0.061 & 0.026 & 0.026 \\\\\n",
      "Llama2-70B & 25 random examples & 500 & 1,500 & 0.061 & 0.026 & 0.026 \\\\\n",
      "GPT-3.5-turbo & 25 random examples & 500 & 500 & 0.061 & 0.026 & 0.026 \\\\\n",
      "GPT-3.5-turbo & 25 random examples & 500 & 1,000 & 0.061 & 0.026 & 0.026 \\\\\n",
      "GPT-3.5-turbo & 25 random examples & 500 & 1,500 & 0.061 & 0.026 & 0.026 \\\\\n",
      "\\hline\n",
      "Llama2-70B & 25 fixed examples & 25 & 475 & 0.061 & 0.026 & 0.026 \\\\\n",
      "Llama2-70B & 25 fixed examples & 25 & 975 & 0.061 & 0.026 & 0.026 \\\\\n",
      "Llama2-70B & 25 fixed examples & 25 & 1,975 & 0.061 & 0.026 & 0.026 \\\\\n",
      "GPT-3.5-turbo & 25 fixed examples & 25 & 475 & 0.061 & 0.026 & 0.026 \\\\\n",
      "GPT-3.5-turbo & 25 fixed examples & 25 & 975 & 0.061 & 0.026 & 0.026 \\\\\n",
      "GPT-3.5-turbo & 25 fixed examples & 25 & 1,975 & 0.061 & 0.026 & 0.026 \\\\\n",
      "\\hline\n"
     ]
    }
   ],
   "source": [
    "for absa_task in ABSA_TASKS:\n",
    "    print(absa_task, \":\\n\")\n",
    "    for n_real in [500, 1000, 2000]:\n",
    "        json_path = RESULTS_PATH_BASE + \\\n",
    "            f\"only_real_real{n_real}_synth0_{absa_task}_random.json\"\n",
    "        with open(json_path, 'r') as json_file:\n",
    "            results = json.load(json_file)\n",
    "        print(\n",
    "            f\"- & - & {format_thousands(n_real)} & 0 & {round_to_three_decimals(results['eval_f1_micro'])} & {round_to_three_decimals(results['eval_f1_macro'])} & {round_to_three_decimals(results['eval_accuracy'])} \\\\\\\\\")\n",
    "    print(\"\\\\hline\")\n",
    "    for few_shot_condition in SYNTH_COMBINATIONS.keys():\n",
    "        for llm in LLMS:\n",
    "            for freq in SYNTH_COMBINATIONS[few_shot_condition]:\n",
    "                n_real = freq[\"real\"]\n",
    "                n_synth = freq[\"synth\"]\n",
    "                json_path = RESULTS_PATH_BASE + llm + \\\n",
    "                    f\"_real{n_real}_synth{n_synth}_{absa_task}_{few_shot_condition}.json\"\n",
    "                with open(json_path, 'r') as json_file:\n",
    "                    results = json.load(json_file)\n",
    "                # print(f\"results: {absa_task}, {llm}, {few_shot_condition}, n_real: {n_real}, n_synth: {n_synth}\", results)\n",
    "                if absa_task == \"TASD\":\n",
    "                    f1_metrics = f\"{round_to_three_decimals(results['eval_f1_micro'])} & {round_to_three_decimals(results['eval_f1_macro'])}\"\n",
    "                else:\n",
    "                    f1_metrics = f\"{round_to_three_decimals(results['eval_f1_micro'])}\"\n",
    "                print(\n",
    "                    f\"{LLM_PAPER_TITLE[llm]} & {FEW_SHOT_STRATEGY[n_real]} & {format_thousands(n_real)} & {format_thousands(n_synth)} & {f1_metrics} & {round_to_three_decimals(results['eval_accuracy'])} & {round_to_three_decimals(results['eval_accuracy'])} \\\\\\\\\")\n",
    "        print(\"\\hline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report Metrics Fine-Grained Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ACD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- & - & 500 & 0 & 0.0 &0.736 &0.165 &0.614 &0.0 &0.686 &0.0 &0.872 &0.0 &0.926  \\\\\n",
      "- & - & 1,000 & 0 & 0.0 &0.736 &0.165 &0.614 &0.0 &0.686 &0.0 &0.872 &0.0 &0.926  \\\\\n",
      "- & - & 2,000 & 0 & 0.0 &0.736 &0.165 &0.614 &0.0 &0.686 &0.0 &0.872 &0.0 &0.926  \\\\\n",
      "\\hline\n",
      "Llama2-70B & 25 random examples & 500 & 500 & 0.0 &0.736 &0.165 &0.614 &0.0 &0.686 &0.0 &0.872 &0.0 &0.926  \\\\\n",
      "Llama2-70B & 25 random examples & 500 & 1,000 & 0.0 &0.736 &0.165 &0.614 &0.0 &0.686 &0.0 &0.872 &0.0 &0.926  \\\\\n",
      "Llama2-70B & 25 random examples & 500 & 1,500 & 0.0 &0.736 &0.165 &0.614 &0.0 &0.686 &0.0 &0.872 &0.0 &0.926  \\\\\n",
      "GPT-3.5-turbo & 25 random examples & 500 & 500 & 0.0 &0.736 &0.165 &0.614 &0.0 &0.686 &0.0 &0.872 &0.0 &0.926  \\\\\n",
      "GPT-3.5-turbo & 25 random examples & 500 & 1,000 & 0.0 &0.736 &0.165 &0.614 &0.0 &0.686 &0.0 &0.872 &0.0 &0.926  \\\\\n",
      "GPT-3.5-turbo & 25 random examples & 500 & 1,500 & 0.0 &0.736 &0.165 &0.614 &0.0 &0.686 &0.0 &0.872 &0.0 &0.926  \\\\\n",
      "\\hline\n",
      "Llama2-70B & 25 fixed examples & 25 & 475 & 0.0 &0.736 &0.165 &0.614 &0.0 &0.686 &0.0 &0.872 &0.0 &0.926  \\\\\n",
      "Llama2-70B & 25 fixed examples & 25 & 975 & 0.0 &0.736 &0.165 &0.614 &0.0 &0.686 &0.0 &0.872 &0.0 &0.926  \\\\\n",
      "Llama2-70B & 25 fixed examples & 25 & 1,975 & 0.0 &0.736 &0.165 &0.614 &0.0 &0.686 &0.0 &0.872 &0.0 &0.926  \\\\\n",
      "GPT-3.5-turbo & 25 fixed examples & 25 & 475 & 0.0 &0.736 &0.165 &0.614 &0.0 &0.686 &0.0 &0.872 &0.0 &0.926  \\\\\n",
      "GPT-3.5-turbo & 25 fixed examples & 25 & 975 & 0.0 &0.736 &0.165 &0.614 &0.0 &0.686 &0.0 &0.872 &0.0 &0.926  \\\\\n",
      "GPT-3.5-turbo & 25 fixed examples & 25 & 1,975 & 0.0 &0.736 &0.165 &0.614 &0.0 &0.686 &0.0 &0.872 &0.0 &0.926  \\\\\n",
      "\\hline\n"
     ]
    }
   ],
   "source": [
    "absa_task = \"aspect_category\"\n",
    "for n_real in [500, 1000, 2000]:\n",
    "    json_path = RESULTS_PATH_BASE + \\\n",
    "        f\"only_real_real{n_real}_synth0_{absa_task}_random.json\"\n",
    "    with open(json_path, 'r') as json_file:\n",
    "        results = json.load(json_file)\n",
    "    class_wise_metrics = \"\"\n",
    "    for ac in [\"GENERAL-IMPRESSION\", \"FOOD\", \"SERVICE\", \"AMBIENCE\", \"PRICE\"]:\n",
    "       for metric in [\"f1\", \"accuracy\"]:\n",
    "           class_wise_metrics += f\"{round_to_three_decimals(results[f'eval_{metric}_{ac}'])} &\"\n",
    "    print(f\"- & - & {format_thousands(n_real)} & 0 & {class_wise_metrics[:-1]} \\\\\\\\\")\n",
    "print(\"\\\\hline\")\n",
    "for few_shot_condition in SYNTH_COMBINATIONS.keys():\n",
    "    for llm in LLMS:\n",
    "        for freq in SYNTH_COMBINATIONS[few_shot_condition]:\n",
    "            n_real = freq[\"real\"]\n",
    "            n_synth = freq[\"synth\"]\n",
    "            json_path = RESULTS_PATH_BASE + llm + \\\n",
    "                f\"_real{n_real}_synth{n_synth}_{absa_task}_{few_shot_condition}.json\"\n",
    "            with open(json_path, 'r') as json_file:\n",
    "                results = json.load(json_file)\n",
    "            # print(f\"results: {absa_task}, {llm}, {few_shot_condition}, n_real: {n_real}, n_synth: {n_synth}\", results)\n",
    "            if absa_task == \"TASD\":\n",
    "                f1_metrics = f\"{round_to_three_decimals(results['eval_f1_micro'])} & {round_to_three_decimals(results['eval_f1_macro'])}\"\n",
    "            else:\n",
    "                f1_metrics = f\"{round_to_three_decimals(results['eval_f1_micro'])}\"\n",
    "\n",
    "            class_wise_metrics = \"\"\n",
    "            for ac in [\"GENERAL-IMPRESSION\", \"FOOD\", \"SERVICE\", \"AMBIENCE\", \"PRICE\"]:\n",
    "                for metric in [\"f1\", \"accuracy\"]:\n",
    "                   class_wise_metrics += f\"{round_to_three_decimals(results[f'eval_{metric}_{ac}'])} &\"\n",
    "\n",
    "            print(\n",
    "                    f\"{LLM_PAPER_TITLE[llm]} & {FEW_SHOT_STRATEGY[n_real]} & {format_thousands(n_real)} & {format_thousands(n_synth)} & {class_wise_metrics[:-1]} \\\\\\\\\")\n",
    "    print(\"\\hline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ACSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table for: ['GENERAL-IMPRESSION', 'FOOD'] \n",
      "\n",
      "\n",
      "- & - & 500 & 0 & 0.278 & 0.234 & 0.342 & 0.044 & 0.026 & 0.143 & 0.0 & 0.0 & 0.0 & 0.152 & 0.241 & 0.111 & 0.079 & 0.044 & 0.348 & 0.381 & 0.268 & 0.662 &\\\\\n",
      "- & - & 1,000 & 0 & 0.278 & 0.234 & 0.342 & 0.044 & 0.026 & 0.143 & 0.0 & 0.0 & 0.0 & 0.152 & 0.241 & 0.111 & 0.079 & 0.044 & 0.348 & 0.381 & 0.268 & 0.662 &\\\\\n",
      "- & - & 2,000 & 0 & 0.278 & 0.234 & 0.342 & 0.044 & 0.026 & 0.143 & 0.0 & 0.0 & 0.0 & 0.152 & 0.241 & 0.111 & 0.079 & 0.044 & 0.348 & 0.381 & 0.268 & 0.662 &\\\\\n",
      "\\hline\n",
      "Llama2-70B & 25 random examples & 500 & 500 & 0.278 & 0.234 & 0.342 & 0.044 & 0.026 & 0.143 & 0.0 & 0.0 & 0.0 & 0.152 & 0.241 & 0.111 & 0.079 & 0.044 & 0.348 & 0.381 & 0.268 & 0.662 &\\\\\n",
      "Llama2-70B & 25 random examples & 500 & 1,000 & 0.278 & 0.234 & 0.342 & 0.044 & 0.026 & 0.143 & 0.0 & 0.0 & 0.0 & 0.152 & 0.241 & 0.111 & 0.079 & 0.044 & 0.348 & 0.381 & 0.268 & 0.662 &\\\\\n",
      "Llama2-70B & 25 random examples & 500 & 1,500 & 0.278 & 0.234 & 0.342 & 0.044 & 0.026 & 0.143 & 0.0 & 0.0 & 0.0 & 0.152 & 0.241 & 0.111 & 0.079 & 0.044 & 0.348 & 0.381 & 0.268 & 0.662 &\\\\\n",
      "GPT-3.5-turbo & 25 random examples & 500 & 500 & 0.278 & 0.234 & 0.342 & 0.044 & 0.026 & 0.143 & 0.0 & 0.0 & 0.0 & 0.152 & 0.241 & 0.111 & 0.079 & 0.044 & 0.348 & 0.381 & 0.268 & 0.662 &\\\\\n",
      "GPT-3.5-turbo & 25 random examples & 500 & 1,000 & 0.278 & 0.234 & 0.342 & 0.044 & 0.026 & 0.143 & 0.0 & 0.0 & 0.0 & 0.152 & 0.241 & 0.111 & 0.079 & 0.044 & 0.348 & 0.381 & 0.268 & 0.662 &\\\\\n",
      "GPT-3.5-turbo & 25 random examples & 500 & 1,500 & 0.278 & 0.234 & 0.342 & 0.044 & 0.026 & 0.143 & 0.0 & 0.0 & 0.0 & 0.152 & 0.241 & 0.111 & 0.079 & 0.044 & 0.348 & 0.381 & 0.268 & 0.662 &\\\\\n",
      "\\hline\n",
      "Llama2-70B & 25 fixed examples & 25 & 475 & 0.278 & 0.234 & 0.342 & 0.044 & 0.026 & 0.143 & 0.0 & 0.0 & 0.0 & 0.152 & 0.241 & 0.111 & 0.079 & 0.044 & 0.348 & 0.381 & 0.268 & 0.662 &\\\\\n",
      "Llama2-70B & 25 fixed examples & 25 & 975 & 0.278 & 0.234 & 0.342 & 0.044 & 0.026 & 0.143 & 0.0 & 0.0 & 0.0 & 0.152 & 0.241 & 0.111 & 0.079 & 0.044 & 0.348 & 0.381 & 0.268 & 0.662 &\\\\\n",
      "Llama2-70B & 25 fixed examples & 25 & 1,975 & 0.278 & 0.234 & 0.342 & 0.044 & 0.026 & 0.143 & 0.0 & 0.0 & 0.0 & 0.152 & 0.241 & 0.111 & 0.079 & 0.044 & 0.348 & 0.381 & 0.268 & 0.662 &\\\\\n",
      "GPT-3.5-turbo & 25 fixed examples & 25 & 475 & 0.278 & 0.234 & 0.342 & 0.044 & 0.026 & 0.143 & 0.0 & 0.0 & 0.0 & 0.152 & 0.241 & 0.111 & 0.079 & 0.044 & 0.348 & 0.381 & 0.268 & 0.662 &\\\\\n",
      "GPT-3.5-turbo & 25 fixed examples & 25 & 975 & 0.278 & 0.234 & 0.342 & 0.044 & 0.026 & 0.143 & 0.0 & 0.0 & 0.0 & 0.152 & 0.241 & 0.111 & 0.079 & 0.044 & 0.348 & 0.381 & 0.268 & 0.662 &\\\\\n",
      "GPT-3.5-turbo & 25 fixed examples & 25 & 1,975 & 0.278 & 0.234 & 0.342 & 0.044 & 0.026 & 0.143 & 0.0 & 0.0 & 0.0 & 0.152 & 0.241 & 0.111 & 0.079 & 0.044 & 0.348 & 0.381 & 0.268 & 0.662 &\\\\\n",
      "\\hline\n",
      "Table for: ['SERVICE', 'AMBIENCE', 'PRICE'] \n",
      "\n",
      "\n",
      " 0.082 & 0.2 & 0.051 & 0.012 & 0.006 & 0.5 & 0.302 & 0.199 & 0.623 & 0.217 & 0.151 & 0.383 & 0.0 & 0.0 & 0.0 & 0.075 & 0.04 & 0.588 & 0.036 & 0.019 & 0.571 & 0.0 & 0.0 & 0.0 & 0.056 & 0.034 & 0.143 \\\\\n",
      " 0.082 & 0.2 & 0.051 & 0.012 & 0.006 & 0.5 & 0.302 & 0.199 & 0.623 & 0.217 & 0.151 & 0.383 & 0.0 & 0.0 & 0.0 & 0.075 & 0.04 & 0.588 & 0.036 & 0.019 & 0.571 & 0.0 & 0.0 & 0.0 & 0.056 & 0.034 & 0.143 \\\\\n",
      " 0.082 & 0.2 & 0.051 & 0.012 & 0.006 & 0.5 & 0.302 & 0.199 & 0.623 & 0.217 & 0.151 & 0.383 & 0.0 & 0.0 & 0.0 & 0.075 & 0.04 & 0.588 & 0.036 & 0.019 & 0.571 & 0.0 & 0.0 & 0.0 & 0.056 & 0.034 & 0.143 \\\\\n",
      "\\hline\n",
      " 0.082 & 0.2 & 0.051 & 0.012 & 0.006 & 0.5 & 0.302 & 0.199 & 0.623 & 0.217 & 0.151 & 0.383 & 0.0 & 0.0 & 0.0 & 0.075 & 0.04 & 0.588 & 0.036 & 0.019 & 0.571 & 0.0 & 0.0 & 0.0 & 0.056 & 0.034 & 0.143 \\\\\n",
      " 0.082 & 0.2 & 0.051 & 0.012 & 0.006 & 0.5 & 0.302 & 0.199 & 0.623 & 0.217 & 0.151 & 0.383 & 0.0 & 0.0 & 0.0 & 0.075 & 0.04 & 0.588 & 0.036 & 0.019 & 0.571 & 0.0 & 0.0 & 0.0 & 0.056 & 0.034 & 0.143 \\\\\n",
      " 0.082 & 0.2 & 0.051 & 0.012 & 0.006 & 0.5 & 0.302 & 0.199 & 0.623 & 0.217 & 0.151 & 0.383 & 0.0 & 0.0 & 0.0 & 0.075 & 0.04 & 0.588 & 0.036 & 0.019 & 0.571 & 0.0 & 0.0 & 0.0 & 0.056 & 0.034 & 0.143 \\\\\n",
      " 0.082 & 0.2 & 0.051 & 0.012 & 0.006 & 0.5 & 0.302 & 0.199 & 0.623 & 0.217 & 0.151 & 0.383 & 0.0 & 0.0 & 0.0 & 0.075 & 0.04 & 0.588 & 0.036 & 0.019 & 0.571 & 0.0 & 0.0 & 0.0 & 0.056 & 0.034 & 0.143 \\\\\n",
      " 0.082 & 0.2 & 0.051 & 0.012 & 0.006 & 0.5 & 0.302 & 0.199 & 0.623 & 0.217 & 0.151 & 0.383 & 0.0 & 0.0 & 0.0 & 0.075 & 0.04 & 0.588 & 0.036 & 0.019 & 0.571 & 0.0 & 0.0 & 0.0 & 0.056 & 0.034 & 0.143 \\\\\n",
      " 0.082 & 0.2 & 0.051 & 0.012 & 0.006 & 0.5 & 0.302 & 0.199 & 0.623 & 0.217 & 0.151 & 0.383 & 0.0 & 0.0 & 0.0 & 0.075 & 0.04 & 0.588 & 0.036 & 0.019 & 0.571 & 0.0 & 0.0 & 0.0 & 0.056 & 0.034 & 0.143 \\\\\n",
      "\\hline\n",
      " 0.082 & 0.2 & 0.051 & 0.012 & 0.006 & 0.5 & 0.302 & 0.199 & 0.623 & 0.217 & 0.151 & 0.383 & 0.0 & 0.0 & 0.0 & 0.075 & 0.04 & 0.588 & 0.036 & 0.019 & 0.571 & 0.0 & 0.0 & 0.0 & 0.056 & 0.034 & 0.143 \\\\\n",
      " 0.082 & 0.2 & 0.051 & 0.012 & 0.006 & 0.5 & 0.302 & 0.199 & 0.623 & 0.217 & 0.151 & 0.383 & 0.0 & 0.0 & 0.0 & 0.075 & 0.04 & 0.588 & 0.036 & 0.019 & 0.571 & 0.0 & 0.0 & 0.0 & 0.056 & 0.034 & 0.143 \\\\\n",
      " 0.082 & 0.2 & 0.051 & 0.012 & 0.006 & 0.5 & 0.302 & 0.199 & 0.623 & 0.217 & 0.151 & 0.383 & 0.0 & 0.0 & 0.0 & 0.075 & 0.04 & 0.588 & 0.036 & 0.019 & 0.571 & 0.0 & 0.0 & 0.0 & 0.056 & 0.034 & 0.143 \\\\\n",
      " 0.082 & 0.2 & 0.051 & 0.012 & 0.006 & 0.5 & 0.302 & 0.199 & 0.623 & 0.217 & 0.151 & 0.383 & 0.0 & 0.0 & 0.0 & 0.075 & 0.04 & 0.588 & 0.036 & 0.019 & 0.571 & 0.0 & 0.0 & 0.0 & 0.056 & 0.034 & 0.143 \\\\\n",
      " 0.082 & 0.2 & 0.051 & 0.012 & 0.006 & 0.5 & 0.302 & 0.199 & 0.623 & 0.217 & 0.151 & 0.383 & 0.0 & 0.0 & 0.0 & 0.075 & 0.04 & 0.588 & 0.036 & 0.019 & 0.571 & 0.0 & 0.0 & 0.0 & 0.056 & 0.034 & 0.143 \\\\\n",
      " 0.082 & 0.2 & 0.051 & 0.012 & 0.006 & 0.5 & 0.302 & 0.199 & 0.623 & 0.217 & 0.151 & 0.383 & 0.0 & 0.0 & 0.0 & 0.075 & 0.04 & 0.588 & 0.036 & 0.019 & 0.571 & 0.0 & 0.0 & 0.0 & 0.056 & 0.034 & 0.143 \\\\\n",
      "\\hline\n"
     ]
    }
   ],
   "source": [
    "absa_task = \"aspect_category_sentiment\"\n",
    "\n",
    "idx = 0\n",
    "for aspect_categories in [[\"GENERAL-IMPRESSION\", \"FOOD\"], [\"SERVICE\", \"AMBIENCE\", \"PRICE\"]]:\n",
    "    print(\"Table for:\", aspect_categories, \"\\n\\n\")\n",
    "    for n_real in [500, 1000, 2000]:\n",
    "        json_path = RESULTS_PATH_BASE + \\\n",
    "            f\"only_real_real{n_real}_synth0_{absa_task}_random.json\"\n",
    "        with open(json_path, 'r') as json_file:\n",
    "            results = json.load(json_file)\n",
    "\n",
    "        condition_string = f\"- & - & {format_thousands(n_real)} & 0 &\"\n",
    "        metrics_class_wise = \"\"\n",
    "        for ac in aspect_categories:\n",
    "            for polarity in [\"POSITIVE\", \"NEUTRAL\", \"NEGATIVE\"]:\n",
    "                for metric in [\"eval_f1\", \"eval_precision\", \"eval_recall\"]:\n",
    "                    metrics_class_wise += f\" {round_to_three_decimals(results[f'{metric}_{ac}-{polarity}'])} &\"\n",
    "\n",
    "        print(condition_string + metrics_class_wise + \"\\\\\\\\\") if idx == 0 else print(metrics_class_wise[:-1] + \"\\\\\\\\\")\n",
    "\n",
    "    print(\"\\\\hline\")\n",
    "    for few_shot_condition in SYNTH_COMBINATIONS.keys():\n",
    "        for llm in LLMS:\n",
    "            for freq in SYNTH_COMBINATIONS[few_shot_condition]:\n",
    "                n_real = freq[\"real\"]\n",
    "                n_synth = freq[\"synth\"]\n",
    "                json_path = RESULTS_PATH_BASE + llm + \\\n",
    "                    f\"_real{n_real}_synth{n_synth}_{absa_task}_{few_shot_condition}.json\"\n",
    "                with open(json_path, 'r') as json_file:\n",
    "                    results = json.load(json_file)\n",
    "\n",
    "                condition_string = f\"{LLM_PAPER_TITLE[llm]} & {FEW_SHOT_STRATEGY[n_real]} & {format_thousands(n_real)} & {format_thousands(n_synth)} &\"\n",
    "                metrics_class_wise = \"\"\n",
    "                for ac in aspect_categories:\n",
    "                    for polarity in [\"POSITIVE\", \"NEUTRAL\", \"NEGATIVE\"]:\n",
    "                        for metric in [\"eval_f1\", \"eval_precision\", \"eval_recall\"]:\n",
    "                            metrics_class_wise += f\" {round_to_three_decimals(results[f'{metric}_{ac}-{polarity}'])} &\"\n",
    "\n",
    "                print(condition_string + metrics_class_wise + \"\\\\\\\\\") if idx == 0 else print(metrics_class_wise[:-1] + \"\\\\\\\\\")\n",
    "        print(\"\\hline\")\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LLM_NAME': 'only_real',\n",
       " 'N_REAL': 500,\n",
       " 'N_SYNTH': 0,\n",
       " 'TARGET': 'aspect_category_sentiment',\n",
       " 'LLM_SAMPLING': 'random',\n",
       " 'eval_loss': 0.6316537976264953,\n",
       " 'eval_accuracy': 0.0,\n",
       " 'eval_hamming_loss': 0.26893333333333336,\n",
       " 'eval_f1_macro': 0.11427978789259886,\n",
       " 'eval_f1_micro': 0.15853149770546515,\n",
       " 'eval_f1_weighted': 0.1873516502346942,\n",
       " 'eval_precision_GENERAL-IMPRESSION': 0.18120805369127516,\n",
       " 'eval_recall_GENERAL-IMPRESSION': 0.20454545454545456,\n",
       " 'eval_f1_GENERAL-IMPRESSION': 0.19217081850533807,\n",
       " 'eval_accuracy_GENERAL-IMPRESSION': 0.648,\n",
       " 'eval_precision_FOOD': 0.1712962962962963,\n",
       " 'eval_recall_FOOD': 0.33636363636363636,\n",
       " 'eval_f1_FOOD': 0.22699386503067484,\n",
       " 'eval_accuracy_FOOD': 0.252,\n",
       " 'eval_precision_SERVICE': 0.12412177985948478,\n",
       " 'eval_recall_SERVICE': 0.3375796178343949,\n",
       " 'eval_f1_SERVICE': 0.18150684931506852,\n",
       " 'eval_accuracy_SERVICE': 0.33,\n",
       " 'eval_precision_AMBIENCE': 0.06292134831460675,\n",
       " 'eval_recall_AMBIENCE': 0.4307692307692308,\n",
       " 'eval_f1_AMBIENCE': 0.10980392156862746,\n",
       " 'eval_accuracy_AMBIENCE': 0.296,\n",
       " 'eval_precision_PRICE': 0.024024024024024024,\n",
       " 'eval_recall_PRICE': 0.21621621621621623,\n",
       " 'eval_f1_PRICE': 0.04324324324324324,\n",
       " 'eval_accuracy_PRICE': 0.328,\n",
       " 'eval_precision_GENERAL-IMPRESSION-POSITIVE': 0.23423423423423423,\n",
       " 'eval_recall_GENERAL-IMPRESSION-POSITIVE': 0.34210526315789475,\n",
       " 'eval_f1_GENERAL-IMPRESSION-POSITIVE': 0.27807486631016043,\n",
       " 'eval_accuracy_GENERAL-IMPRESSION-POSITIVE': 0.73,\n",
       " 'eval_precision_GENERAL-IMPRESSION-NEUTRAL': 0.02631578947368421,\n",
       " 'eval_recall_GENERAL-IMPRESSION-NEUTRAL': 0.14285714285714285,\n",
       " 'eval_f1_GENERAL-IMPRESSION-NEUTRAL': 0.044444444444444446,\n",
       " 'eval_accuracy_GENERAL-IMPRESSION-NEUTRAL': 0.914,\n",
       " 'eval_precision_GENERAL-IMPRESSION-NEGATIVE': 0.0,\n",
       " 'eval_recall_GENERAL-IMPRESSION-NEGATIVE': 0.0,\n",
       " 'eval_f1_GENERAL-IMPRESSION-NEGATIVE': 0.0,\n",
       " 'eval_accuracy_GENERAL-IMPRESSION-NEGATIVE': 0.902,\n",
       " 'eval_precision_FOOD-POSITIVE': 0.24074074074074073,\n",
       " 'eval_recall_FOOD-POSITIVE': 0.1111111111111111,\n",
       " 'eval_f1_FOOD-POSITIVE': 0.15204678362573096,\n",
       " 'eval_accuracy_FOOD-POSITIVE': 0.71,\n",
       " 'eval_precision_FOOD-NEUTRAL': 0.044444444444444446,\n",
       " 'eval_recall_FOOD-NEUTRAL': 0.34782608695652173,\n",
       " 'eval_f1_FOOD-NEUTRAL': 0.07881773399014778,\n",
       " 'eval_accuracy_FOOD-NEUTRAL': 0.626,\n",
       " 'eval_precision_FOOD-NEGATIVE': 0.2676767676767677,\n",
       " 'eval_recall_FOOD-NEGATIVE': 0.6625,\n",
       " 'eval_f1_FOOD-NEGATIVE': 0.381294964028777,\n",
       " 'eval_accuracy_FOOD-NEGATIVE': 0.656,\n",
       " 'eval_precision_SERVICE-POSITIVE': 0.2,\n",
       " 'eval_recall_SERVICE-POSITIVE': 0.05128205128205128,\n",
       " 'eval_f1_SERVICE-POSITIVE': 0.0816326530612245,\n",
       " 'eval_accuracy_SERVICE-POSITIVE': 0.82,\n",
       " 'eval_precision_SERVICE-NEUTRAL': 0.006024096385542169,\n",
       " 'eval_recall_SERVICE-NEUTRAL': 0.5,\n",
       " 'eval_f1_SERVICE-NEUTRAL': 0.011904761904761906,\n",
       " 'eval_accuracy_SERVICE-NEUTRAL': 0.668,\n",
       " 'eval_precision_SERVICE-NEGATIVE': 0.1991701244813278,\n",
       " 'eval_recall_SERVICE-NEGATIVE': 0.6233766233766234,\n",
       " 'eval_f1_SERVICE-NEGATIVE': 0.3018867924528302,\n",
       " 'eval_accuracy_SERVICE-NEGATIVE': 0.556,\n",
       " 'eval_precision_AMBIENCE-POSITIVE': 0.15126050420168066,\n",
       " 'eval_recall_AMBIENCE-POSITIVE': 0.3829787234042553,\n",
       " 'eval_f1_AMBIENCE-POSITIVE': 0.21686746987951805,\n",
       " 'eval_accuracy_AMBIENCE-POSITIVE': 0.74,\n",
       " 'eval_precision_AMBIENCE-NEUTRAL': 0.0,\n",
       " 'eval_recall_AMBIENCE-NEUTRAL': 0.0,\n",
       " 'eval_f1_AMBIENCE-NEUTRAL': 0.0,\n",
       " 'eval_accuracy_AMBIENCE-NEUTRAL': 0.842,\n",
       " 'eval_precision_AMBIENCE-NEGATIVE': 0.04032258064516129,\n",
       " 'eval_recall_AMBIENCE-NEGATIVE': 0.5882352941176471,\n",
       " 'eval_f1_AMBIENCE-NEGATIVE': 0.07547169811320754,\n",
       " 'eval_accuracy_AMBIENCE-NEGATIVE': 0.51,\n",
       " 'eval_precision_PRICE-POSITIVE': 0.018691588785046728,\n",
       " 'eval_recall_PRICE-POSITIVE': 0.5714285714285714,\n",
       " 'eval_f1_PRICE-POSITIVE': 0.03619909502262443,\n",
       " 'eval_accuracy_PRICE-POSITIVE': 0.574,\n",
       " 'eval_precision_PRICE-NEUTRAL': 0.0,\n",
       " 'eval_recall_PRICE-NEUTRAL': 0.0,\n",
       " 'eval_f1_PRICE-NEUTRAL': 0.0,\n",
       " 'eval_accuracy_PRICE-NEUTRAL': 0.99,\n",
       " 'eval_precision_PRICE-NEGATIVE': 0.034482758620689655,\n",
       " 'eval_recall_PRICE-NEGATIVE': 0.14285714285714285,\n",
       " 'eval_f1_PRICE-NEGATIVE': 0.05555555555555555,\n",
       " 'eval_accuracy_PRICE-NEGATIVE': 0.728,\n",
       " 'runtime': 126.8714210987091,\n",
       " 'runtime_formatted': '2m 6s',\n",
       " 'n_samples_train': [500, 500, 500, 500, 500],\n",
       " 'n_samples_train_mean': 500.0,\n",
       " 'n_samples_test': [500, 500, 500, 500, 500],\n",
       " 'n_samples_test_mean': 500.0}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_m1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
