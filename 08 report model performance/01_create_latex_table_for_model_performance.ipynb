{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook: Convert Model Results to Latex\n",
    "\n",
    "This notebook is used to load the .json files with the model performance in order to convert them into a latex table for the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo: Schauen, ob es die Metriken auch bei anderen Modellen gibt\n",
    "# Todo: 1.000 <- Punkte einfÃ¼gen\n",
    "# Todo: Soll bei nur Real gehen\n",
    "# Todo: Soll bei allen Tasks gehen\n",
    "# Todo: bei f1 micro etc 3 nachkommastellen\n",
    "# Schauen, dass es bei jedem Task \"eval_f1_micro\", \"eval_f1_macro\", \"accuracy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings / Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_PATH_BASE = \"../07 train models/results_json/results_\"\n",
    "LLMS = [\"Llama3_70B\", \"GPT-3\"]\n",
    "# , \"aspect_category_sentiment\", \"end_2_end_absa\" ,\"target_aspect_sentiment_detection\"]\n",
    "ABSA_TASKS = [\"aspect_category\", \"aspect_category_sentiment\",\n",
    "              \"end_2_end_absa\", \"target_aspect_sentiment_detection\"]\n",
    "SYNTH_COMBINATIONS = {\n",
    "    \"fixed\": [\n",
    "        {\"real\": 25, \"synth\": 475},\n",
    "        {\"real\": 25, \"synth\": 975},\n",
    "        {\"real\": 25, \"synth\": 1975}\n",
    "    ],\n",
    "    \"random\": [\n",
    "        {\"real\": 500, \"synth\": 500},\n",
    "        {\"real\": 500, \"synth\": 1000},\n",
    "        {\"real\": 500, \"synth\": 1500}\n",
    "    ]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "LLMS_ENCODED = {\"GPT-3\": \"\\\\textbf{GPT-3.5-turbo}\",\n",
    "                \"Llama2_70B\": \"\\\\textbf{Llama-2-70B}\", \"Llama3_70B\": \"\\\\textbf{Llama-3-70B}\"}\n",
    "ENCODE_CONDITION = {\"fixed\": \"\\\\textbf{LRS\\\\textsubscript{25}}\",\n",
    "                    \"random\": \"\\\\textbf{LRS\\\\textsubscript{500}}\"}\n",
    "\n",
    "N_METRICS = {\"aspect_category\": 6, \"aspect_category_sentiment\": 6,\n",
    "             \"end_2_end_absa\": 6, \"target_aspect_sentiment_detection\": 5}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_number(num, decimal_places):\n",
    "    formatted_num = \"{:.{}f}\".format(num, decimal_places)\n",
    "    rounded_num_str = \"{:.{}f}\".format(float(formatted_num), decimal_places)\n",
    "    return rounded_num_str\n",
    "\n",
    "def add_thousand_dots(n_sample):\n",
    "    if isinstance(n_sample, str):\n",
    "        if '.' in n_sample:\n",
    "            integer_part, decimal_part = n_sample.split('.')\n",
    "            formatted_integer_part = \"{:,}\".format(int(integer_part))\n",
    "            result = f\"{formatted_integer_part}.{decimal_part}\"\n",
    "        else:\n",
    "            result = \"{:,}\".format(int(n_sample))\n",
    "    elif isinstance(n_sample, np.float64):\n",
    "        result = \"{:,}\".format(round(n_sample, 1))\n",
    "    else:\n",
    "        result = n_sample\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report Main Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metric(metric_name, results):\n",
    "    main_metric = add_thousand_dots(round_number(results[metric_name]*100, 2))\n",
    "    std_metric = round_number(np.std([res[metric_name] * 100 for res in results[\"single_split_results\"]]), 2)\n",
    "    return main_metric + \"\\\\textsubscript{\" + std_metric + \"}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_category :\n",
      "\n",
      " -------#-----#-----#-------\n",
      "\\multirow{3}{*}{\\textbf{Real Examples}} & \\multirow{3}{*}{-} & 500 & 0 & 90.90\\textsubscript{1.37} & 89.97\\textsubscript{1.66} \\\\\n",
      " &  & 1,000 & 0 & 92.02\\textsubscript{1.19} & 91.10\\textsubscript{1.46} \\\\\n",
      " &  & 2,000 & 0 & 92.35\\textsubscript{1.15} & 91.53\\textsubscript{1.31} \\\\\n",
      "\\hline\n",
      "\\multirow{6}{*}{\\textbf{Llama-3-70B}} & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{25}}} & 25 & 475 & 81.33\\textsubscript{0.36} & 80.37\\textsubscript{1.30} \\\\\n",
      " &  & 25 & 975 & 80.76\\textsubscript{2.03} & 80.18\\textsubscript{1.65} \\\\\n",
      " &  & 25 & 1,975 & 80.65\\textsubscript{1.77} & 80.20\\textsubscript{1.11} \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-6}\\arrayrulecolor{black}\n",
      " & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{500}}} & 500 & 500 & 89.88\\textsubscript{1.42} & 88.77\\textsubscript{1.72} \\\\\n",
      " &  & 500 & 1,000 & 88.77\\textsubscript{1.06} & 87.15\\textsubscript{1.10} \\\\\n",
      " &  & 500 & 1,500 & 88.49\\textsubscript{1.61} & 87.11\\textsubscript{1.55} \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-6}\\arrayrulecolor{black}\n",
      "\\hline\n",
      "\\multirow{6}{*}{\\textbf{GPT-3.5-turbo}} & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{25}}} & 25 & 475 & 79.80\\textsubscript{2.57} & 79.13\\textsubscript{2.15} \\\\\n",
      " &  & 25 & 975 & 79.52\\textsubscript{3.32} & 78.80\\textsubscript{3.58} \\\\\n",
      " &  & 25 & 1,975 & 79.63\\textsubscript{3.17} & 79.11\\textsubscript{3.49} \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-6}\\arrayrulecolor{black}\n",
      " & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{500}}} & 500 & 500 & 90.85\\textsubscript{0.91} & 89.89\\textsubscript{1.16} \\\\\n",
      " &  & 500 & 1,000 & 90.52\\textsubscript{1.33} & 89.81\\textsubscript{1.42} \\\\\n",
      " &  & 500 & 1,500 & 89.68\\textsubscript{0.96} & 88.77\\textsubscript{1.23} \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-6}\\arrayrulecolor{black}\n",
      "\\hline\n",
      "\n",
      "\n",
      "\n",
      "aspect_category_sentiment :\n",
      "\n",
      " -------#-----#-----#-------\n",
      "\\multirow{3}{*}{\\textbf{Real Examples}} & \\multirow{3}{*}{-} & 500 & 0 & 84.54\\textsubscript{1.14} & 59.52\\textsubscript{1.66} \\\\\n",
      " &  & 1,000 & 0 & 88.60\\textsubscript{1.29} & 74.64\\textsubscript{4.26} \\\\\n",
      " &  & 2,000 & 0 & 89.40\\textsubscript{1.37} & 78.86\\textsubscript{5.06} \\\\\n",
      "\\hline\n",
      "\\multirow{6}{*}{\\textbf{Llama-3-70B}} & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{25}}} & 25 & 475 & 60.68\\textsubscript{4.27} & 49.93\\textsubscript{3.41} \\\\\n",
      " &  & 25 & 975 & 64.95\\textsubscript{3.41} & 54.42\\textsubscript{3.60} \\\\\n",
      " &  & 25 & 1,975 & 66.07\\textsubscript{3.95} & 55.58\\textsubscript{3.52} \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-6}\\arrayrulecolor{black}\n",
      " & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{500}}} & 500 & 500 & 83.22\\textsubscript{1.00} & 70.66\\textsubscript{3.81} \\\\\n",
      " &  & 500 & 1,000 & 82.29\\textsubscript{1.30} & 67.96\\textsubscript{4.30} \\\\\n",
      " &  & 500 & 1,500 & 80.64\\textsubscript{1.50} & 66.52\\textsubscript{3.84} \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-6}\\arrayrulecolor{black}\n",
      "\\hline\n",
      "\\multirow{6}{*}{\\textbf{GPT-3.5-turbo}} & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{25}}} & 25 & 475 & 60.18\\textsubscript{6.20} & 50.86\\textsubscript{5.30} \\\\\n",
      " &  & 25 & 975 & 70.95\\textsubscript{4.35} & 62.56\\textsubscript{5.60} \\\\\n",
      " &  & 25 & 1,975 & 71.71\\textsubscript{3.59} & 63.67\\textsubscript{3.05} \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-6}\\arrayrulecolor{black}\n",
      " & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{500}}} & 500 & 500 & 86.70\\textsubscript{2.03} & 79.00\\textsubscript{7.11} \\\\\n",
      " &  & 500 & 1,000 & 86.60\\textsubscript{1.36} & 78.42\\textsubscript{5.28} \\\\\n",
      " &  & 500 & 1,500 & 85.94\\textsubscript{1.45} & 78.47\\textsubscript{3.31} \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-6}\\arrayrulecolor{black}\n",
      "\\hline\n",
      "\n",
      "\n",
      "\n",
      "end_2_end_absa :\n",
      "\n",
      " -------#-----#-----#-------\n",
      "\\multirow{3}{*}{\\textbf{Real Examples}} & \\multirow{3}{*}{-} & 500 & 0 & 77.16\\textsubscript{1.77} & 70.07\\textsubscript{5.01} \\\\\n",
      " &  & 1,000 & 0 & 80.69\\textsubscript{1.65} & 75.03\\textsubscript{2.61} \\\\\n",
      " &  & 2,000 & 0 & 82.00\\textsubscript{3.68} & 78.83\\textsubscript{4.89} \\\\\n",
      "\\hline\n",
      "\\multirow{6}{*}{\\textbf{Llama-3-70B}} & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{25}}} & 25 & 475 & 51.95\\textsubscript{2.41} & 44.50\\textsubscript{2.00} \\\\\n",
      " &  & 25 & 975 & 53.65\\textsubscript{5.49} & 46.81\\textsubscript{5.40} \\\\\n",
      " &  & 25 & 1,975 & 57.34\\textsubscript{3.82} & 48.52\\textsubscript{3.10} \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-6}\\arrayrulecolor{black}\n",
      " & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{500}}} & 500 & 500 & 75.25\\textsubscript{1.59} & 66.86\\textsubscript{2.23} \\\\\n",
      " &  & 500 & 1,000 & 73.19\\textsubscript{2.89} & 63.80\\textsubscript{2.49} \\\\\n",
      " &  & 500 & 1,500 & 71.98\\textsubscript{3.01} & 61.95\\textsubscript{2.57} \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-6}\\arrayrulecolor{black}\n",
      "\\hline\n",
      "\\multirow{6}{*}{\\textbf{GPT-3.5-turbo}} & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{25}}} & 25 & 475 & 59.15\\textsubscript{4.39} & 52.61\\textsubscript{5.08} \\\\\n",
      " &  & 25 & 975 & 58.65\\textsubscript{4.70} & 52.66\\textsubscript{5.71} \\\\\n",
      " &  & 25 & 1,975 & 61.32\\textsubscript{3.87} & 58.15\\textsubscript{3.81} \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-6}\\arrayrulecolor{black}\n",
      " & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{500}}} & 500 & 500 & 76.79\\textsubscript{3.89} & 72.27\\textsubscript{3.78} \\\\\n",
      " &  & 500 & 1,000 & 75.96\\textsubscript{3.26} & 72.55\\textsubscript{2.91} \\\\\n",
      " &  & 500 & 1,500 & 76.14\\textsubscript{3.54} & 71.67\\textsubscript{3.02} \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-6}\\arrayrulecolor{black}\n",
      "\\hline\n",
      "\n",
      "\n",
      "\n",
      "target_aspect_sentiment_detection :\n",
      "\n",
      " -------#-----#-----#-------\n",
      "\\multirow{3}{*}{\\textbf{Real Examples}} & \\multirow{3}{*}{-} & 500 & 0 & 61.80\\textsubscript{1.77} & 53.03\\textsubscript{4.86} \\\\\n",
      " &  & 1,000 & 0 & 65.44\\textsubscript{1.05} & 58.29\\textsubscript{6.31} \\\\\n",
      " &  & 2,000 & 0 & 68.96\\textsubscript{1.31} & 60.22\\textsubscript{4.53} \\\\\n",
      "\\hline\n",
      "\\multirow{6}{*}{\\textbf{Llama-3-70B}} & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{25}}} & 25 & 475 & 38.53\\textsubscript{3.89} & 29.84\\textsubscript{2.36} \\\\\n",
      " &  & 25 & 975 & 39.10\\textsubscript{3.01} & 30.27\\textsubscript{2.02} \\\\\n",
      " &  & 25 & 1,975 & 39.14\\textsubscript{2.35} & 29.50\\textsubscript{1.84} \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-6}\\arrayrulecolor{black}\n",
      " & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{500}}} & 500 & 500 & 58.33\\textsubscript{1.52} & 44.32\\textsubscript{3.23} \\\\\n",
      " &  & 500 & 1,000 & 58.66\\textsubscript{1.10} & 44.66\\textsubscript{3.04} \\\\\n",
      " &  & 500 & 1,500 & 56.23\\textsubscript{1.98} & 41.49\\textsubscript{2.06} \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-6}\\arrayrulecolor{black}\n",
      "\\hline\n",
      "\\multirow{6}{*}{\\textbf{GPT-3.5-turbo}} & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{25}}} & 25 & 475 & 36.96\\textsubscript{2.60} & 29.25\\textsubscript{4.49} \\\\\n",
      " &  & 25 & 975 & 37.88\\textsubscript{3.95} & 31.53\\textsubscript{5.20} \\\\\n",
      " &  & 25 & 1,975 & 37.39\\textsubscript{3.13} & 28.74\\textsubscript{3.55} \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-6}\\arrayrulecolor{black}\n",
      " & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{500}}} & 500 & 500 & 61.39\\textsubscript{1.15} & 50.83\\textsubscript{6.11} \\\\\n",
      " &  & 500 & 1,000 & 59.51\\textsubscript{1.90} & 50.51\\textsubscript{6.63} \\\\\n",
      " &  & 500 & 1,500 & 59.42\\textsubscript{1.74} & 48.76\\textsubscript{5.04} \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-6}\\arrayrulecolor{black}\n",
      "\\hline\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for absa_task in ABSA_TASKS:\n",
    "    print(absa_task, \":\\n\\n\", \"-------#-----#-----#-------\")\n",
    "    for n_real_idx, n_real in enumerate([500, 1000, 2000]):\n",
    "        if n_real_idx == 0:\n",
    "            condition_print = \"\\\\multirow{3}{*}{\\\\textbf{Real Examples}} & \\\\multirow{3}{*}{-}\"\n",
    "        else:\n",
    "            condition_print = \" & \"\n",
    "\n",
    "        json_path = RESULTS_PATH_BASE + \\\n",
    "            f\"only_real_real{n_real}_synth0_{absa_task}_random.json\"\n",
    "\n",
    "        with open(json_path, 'r') as json_file:\n",
    "            results = json.load(json_file)\n",
    "\n",
    "        if absa_task != \"target_aspect_sentiment_detection\":\n",
    "            print(\n",
    "                f\"{condition_print} & {add_thousand_dots(str(n_real))} & 0 & {get_metric('eval_f1_micro', results)} & {get_metric('eval_f1_macro', results)} \\\\\\\\\")\n",
    "        else:\n",
    "            print(\n",
    "                f\"{condition_print} & {add_thousand_dots(str(n_real))} & 0 & {get_metric('eval_f1', results)} & {get_metric('eval_f1_macro', results)} \\\\\\\\\")\n",
    "    print(\"\\\\hline\")\n",
    "    for llm_idx, llm in enumerate(LLMS):\n",
    "        for fs_idx, few_shot_condition in enumerate([\"fixed\", \"random\"]):\n",
    "            for freq_idx, freq in enumerate(SYNTH_COMBINATIONS[few_shot_condition]):\n",
    "                n_real = freq[\"real\"]\n",
    "                n_synth = freq[\"synth\"]\n",
    "                json_path = RESULTS_PATH_BASE + llm + \\\n",
    "                    f\"_real{n_real}_synth{n_synth}_{absa_task}_{few_shot_condition}.json\"\n",
    "                with open(json_path, 'r') as json_file:\n",
    "                    results = json.load(json_file)\n",
    "\n",
    "                if fs_idx == 0 and freq_idx == 0:\n",
    "                    llm_print = \"\\\\multirow{6}{*}{\"+LLMS_ENCODED[llm]+\"}\"\n",
    "                else:\n",
    "                    llm_print = \"\"\n",
    "\n",
    "                if freq_idx == 0:\n",
    "                    condition_print = \"\\\\multirow{3}{*}{\" + \\\n",
    "                        ENCODE_CONDITION[few_shot_condition]+\"}\"\n",
    "                else:\n",
    "                    condition_print = \"\"\n",
    "\n",
    "                if absa_task != \"target_aspect_sentiment_detection\":\n",
    "                    f1_metrics = f\"{get_metric('eval_f1_micro', results)} & {get_metric('eval_f1_macro', results)}\"\n",
    "                else:\n",
    "                    f1_metrics = f\"{get_metric('eval_f1', results)} & {get_metric('eval_f1_macro', results)}\"\n",
    "                print(\n",
    "                    f\"{llm_print} & {condition_print} & {add_thousand_dots(str(n_real))} & {add_thousand_dots(str(n_synth))} & {f1_metrics} \\\\\\\\\")\n",
    "\n",
    "                # print(llm_idx, fs_idx, freq_idx)\n",
    "            if freq_idx == 2:\n",
    "                print(\n",
    "                    \"\\\\arrayrulecolor{gray}\\cline{2-\"+str(6)+\"}\\\\arrayrulecolor{black}\")\n",
    "            else:\n",
    "                print(\"\\\\hline\")\n",
    "        print(\"\\hline\")\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report Metrics Fine-Grained Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ACD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\multirow{3}{*}{\\textbf{Real Examples}} & \\multirow{3}{*}{-} & 500 & 0 & 85.23\\textsubscript{3.71} &93.00\\textsubscript{1.60} &93.57\\textsubscript{0.90} &94.47\\textsubscript{0.78} &93.03\\textsubscript{1.84} &95.43\\textsubscript{1.35} &87.25\\textsubscript{3.80} &96.43\\textsubscript{1.16} &90.78\\textsubscript{3.57} &98.53\\textsubscript{0.60}  \\\\\n",
      " &  & 1,000 & 0 & 86.68\\textsubscript{2.65} &93.53\\textsubscript{1.30} &94.71\\textsubscript{0.92} &95.47\\textsubscript{0.85} &94.15\\textsubscript{1.33} &96.17\\textsubscript{0.93} &88.21\\textsubscript{2.87} &96.70\\textsubscript{0.89} &91.74\\textsubscript{2.42} &98.70\\textsubscript{0.47}  \\\\\n",
      " &  & 2,000 & 0 & 87.41\\textsubscript{2.77} &93.80\\textsubscript{1.18} &94.92\\textsubscript{0.82} &95.67\\textsubscript{0.76} &94.41\\textsubscript{1.10} &96.37\\textsubscript{0.79} &88.34\\textsubscript{2.96} &96.70\\textsubscript{0.98} &92.56\\textsubscript{3.00} &98.83\\textsubscript{0.53}  \\\\\n",
      "\\hline\n",
      "\\multirow{6}{*}{\\textbf{Llama-3-70B}} & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{25}}} & 25 & 475 & 71.22\\textsubscript{2.92} &82.10\\textsubscript{2.18} &89.03\\textsubscript{1.11} &90.73\\textsubscript{0.64} &82.79\\textsubscript{2.49} &90.17\\textsubscript{1.26} &78.04\\textsubscript{3.14} &93.93\\textsubscript{0.92} &80.75\\textsubscript{7.14} &96.57\\textsubscript{1.77}  \\\\\n",
      " &  & 25 & 975 & 72.27\\textsubscript{3.88} &81.90\\textsubscript{3.26} &87.38\\textsubscript{1.97} &89.83\\textsubscript{1.25} &82.26\\textsubscript{4.45} &90.07\\textsubscript{1.49} &79.12\\textsubscript{1.97} &94.10\\textsubscript{0.87} &79.90\\textsubscript{7.93} &96.33\\textsubscript{1.87}  \\\\\n",
      " &  & 25 & 1,975 & 71.15\\textsubscript{2.53} &81.13\\textsubscript{2.22} &87.12\\textsubscript{2.09} &89.63\\textsubscript{1.48} &83.00\\textsubscript{3.90} &90.40\\textsubscript{1.37} &79.78\\textsubscript{3.28} &94.33\\textsubscript{1.31} &79.94\\textsubscript{5.86} &96.50\\textsubscript{1.37}  \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-14}\\arrayrulecolor{black}\n",
      " & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{500}}} & 500 & 500 & 84.27\\textsubscript{2.73} &92.03\\textsubscript{1.50} &93.06\\textsubscript{1.07} &94.10\\textsubscript{0.91} &92.07\\textsubscript{2.66} &95.03\\textsubscript{1.43} &85.56\\textsubscript{3.93} &96.00\\textsubscript{1.11} &88.89\\textsubscript{3.88} &98.27\\textsubscript{0.63}  \\\\\n",
      " &  & 500 & 1,000 & 82.25\\textsubscript{1.65} &90.67\\textsubscript{1.09} &92.74\\textsubscript{1.20} &93.90\\textsubscript{1.12} &91.83\\textsubscript{2.12} &94.87\\textsubscript{1.15} &84.30\\textsubscript{4.12} &95.60\\textsubscript{1.18} &84.65\\textsubscript{3.90} &97.63\\textsubscript{0.56}  \\\\\n",
      " &  & 500 & 1,500 & 82.39\\textsubscript{2.28} &90.67\\textsubscript{1.68} &92.31\\textsubscript{1.79} &93.63\\textsubscript{1.50} &90.86\\textsubscript{2.47} &94.27\\textsubscript{1.46} &85.32\\textsubscript{3.27} &96.00\\textsubscript{0.97} &84.65\\textsubscript{3.09} &97.63\\textsubscript{0.42}  \\\\\n",
      "\\hline\n",
      "\\multirow{6}{*}{\\textbf{GPT-3.5-turbo}} & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{25}}} & 25 & 475 & 71.41\\textsubscript{4.80} &82.40\\textsubscript{3.30} &86.85\\textsubscript{2.24} &88.97\\textsubscript{1.61} &78.77\\textsubscript{4.93} &88.53\\textsubscript{2.25} &76.90\\textsubscript{2.23} &94.03\\textsubscript{0.52} &81.73\\textsubscript{2.12} &96.73\\textsubscript{0.47}  \\\\\n",
      " &  & 25 & 975 & 72.66\\textsubscript{4.05} &83.33\\textsubscript{2.32} &87.30\\textsubscript{2.67} &89.53\\textsubscript{1.92} &75.95\\textsubscript{4.83} &87.37\\textsubscript{2.08} &74.97\\textsubscript{5.22} &93.60\\textsubscript{1.47} &83.14\\textsubscript{4.64} &97.00\\textsubscript{1.01}  \\\\\n",
      " &  & 25 & 1,975 & 73.61\\textsubscript{4.01} &83.83\\textsubscript{2.52} &87.23\\textsubscript{2.82} &89.60\\textsubscript{1.95} &74.61\\textsubscript{3.61} &86.83\\textsubscript{1.20} &76.88\\textsubscript{4.99} &94.07\\textsubscript{1.35} &83.21\\textsubscript{5.67} &97.00\\textsubscript{1.19}  \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-14}\\arrayrulecolor{black}\n",
      " & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{500}}} & 500 & 500 & 86.55\\textsubscript{2.20} &93.23\\textsubscript{1.10} &93.47\\textsubscript{1.01} &94.47\\textsubscript{0.88} &92.59\\textsubscript{2.07} &95.33\\textsubscript{1.19} &87.14\\textsubscript{3.17} &96.50\\textsubscript{1.00} &89.70\\textsubscript{2.20} &98.37\\textsubscript{0.48}  \\\\\n",
      " &  & 500 & 1,000 & 85.47\\textsubscript{1.99} &92.53\\textsubscript{1.30} &93.34\\textsubscript{1.40} &94.30\\textsubscript{1.33} &92.16\\textsubscript{1.32} &95.03\\textsubscript{0.68} &87.17\\textsubscript{3.62} &96.47\\textsubscript{1.05} &90.89\\textsubscript{2.49} &98.57\\textsubscript{0.39}  \\\\\n",
      " &  & 500 & 1,500 & 84.30\\textsubscript{2.19} &91.90\\textsubscript{0.87} &92.72\\textsubscript{1.15} &93.83\\textsubscript{1.08} &91.95\\textsubscript{1.84} &94.93\\textsubscript{1.09} &84.91\\textsubscript{3.33} &95.83\\textsubscript{1.04} &89.99\\textsubscript{2.17} &98.40\\textsubscript{0.42}  \\\\\n",
      "\\hline\n"
     ]
    }
   ],
   "source": [
    "absa_task = \"aspect_category\"\n",
    "for n_real_idx, n_real in enumerate([500, 1000, 2000]):\n",
    "    json_path = RESULTS_PATH_BASE + \\\n",
    "        f\"only_real_real{n_real}_synth0_{absa_task}_random.json\"\n",
    "    with open(json_path, 'r') as json_file:\n",
    "        results = json.load(json_file)\n",
    "\n",
    "    if n_real_idx == 0:\n",
    "        condition_print = \"\\\\multirow{3}{*}{\\\\textbf{Real Examples}} & \\\\multirow{3}{*}{-}\"\n",
    "    else:\n",
    "        condition_print = \" & \"\n",
    "\n",
    "    class_wise_metrics = \"\"\n",
    "    for ac in [\"GENERAL-IMPRESSION\", \"FOOD\", \"SERVICE\", \"AMBIENCE\", \"PRICE\"]:\n",
    "        for metric in [\"f1\", \"accuracy\"]:\n",
    "            class_wise_metrics += f\"{get_metric(f'eval_{metric}_{ac}', results)} &\"\n",
    "    print(\n",
    "        f\"{condition_print} & {add_thousand_dots(str(n_real))} & 0 & {class_wise_metrics[:-1]} \\\\\\\\\")\n",
    "print(\"\\\\hline\")\n",
    "for llm_idx, llm in enumerate(LLMS):\n",
    "    for fs_idx, few_shot_condition in enumerate(SYNTH_COMBINATIONS.keys()):\n",
    "        for freq_idx, freq in enumerate(SYNTH_COMBINATIONS[few_shot_condition]):\n",
    "            n_real = freq[\"real\"]\n",
    "            n_synth = freq[\"synth\"]\n",
    "            json_path = RESULTS_PATH_BASE + llm + \\\n",
    "                f\"_real{n_real}_synth{n_synth}_{absa_task}_{few_shot_condition}.json\"\n",
    "            with open(json_path, 'r') as json_file:\n",
    "                results = json.load(json_file)\n",
    "\n",
    "            if fs_idx == 0 and freq_idx == 0:\n",
    "                llm_print = \"\\\\multirow{6}{*}{\"+LLMS_ENCODED[llm]+\"}\"\n",
    "            else:\n",
    "                llm_print = \"\"\n",
    "\n",
    "            if freq_idx == 0:\n",
    "                condition_print = \"\\\\multirow{3}{*}{\" + \\\n",
    "                    ENCODE_CONDITION[few_shot_condition]+\"}\"\n",
    "            else:\n",
    "                condition_print = \"\"\n",
    "\n",
    "            class_wise_metrics = \"\"\n",
    "            for ac in [\"GENERAL-IMPRESSION\", \"FOOD\", \"SERVICE\", \"AMBIENCE\", \"PRICE\"]:\n",
    "                for metric in [\"f1\", \"accuracy\"]:\n",
    "                    class_wise_metrics += f\"{get_metric(f'eval_{metric}_{ac}', results)} &\"\n",
    "\n",
    "            print(\n",
    "                f\"{llm_print} & {condition_print} & {add_thousand_dots(str(n_real))} & {add_thousand_dots(str(n_synth))} & {class_wise_metrics[:-1]} \\\\\\\\\")\n",
    "            if fs_idx == 0 and freq_idx == 2:\n",
    "               print(\n",
    "                \"\\\\arrayrulecolor{gray}\\cline{2-14}\\\\arrayrulecolor{black}\")\n",
    "\n",
    "    print(\"\\hline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### End-2-End ABSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\multirow{3}{*}{\\textbf{Real Examples}} & \\multirow{3}{*}{-} & 500 & 0 & 82.11\\textsubscript{2.60} &69.74\\textsubscript{3.80} &71.67\\textsubscript{2.53} &55.90\\textsubscript{3.08} &56.43\\textsubscript{16.42} &40.98\\textsubscript{14.69}  \\\\\n",
      " &  & 1,000 & 0 & 84.44\\textsubscript{2.91} &73.18\\textsubscript{4.43} &76.71\\textsubscript{1.73} &62.25\\textsubscript{2.28} &63.94\\textsubscript{7.56} &47.43\\textsubscript{7.84}  \\\\\n",
      " &  & 2,000 & 0 & 85.03\\textsubscript{3.83} &74.15\\textsubscript{5.78} &78.18\\textsubscript{4.12} &64.35\\textsubscript{5.37} &73.29\\textsubscript{9.80} &58.84\\textsubscript{12.83}  \\\\\n",
      "\\hline\n",
      "\\multirow{6}{*}{\\textbf{Llama-3-70B}} & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{25}}} & 25 & 475 & 60.42\\textsubscript{3.22} &43.36\\textsubscript{3.32} &56.69\\textsubscript{3.00} &39.62\\textsubscript{2.90} &16.40\\textsubscript{5.84} &9.05\\textsubscript{3.61}  \\\\\n",
      " &  & 25 & 975 & 60.53\\textsubscript{4.78} &43.56\\textsubscript{4.92} &60.01\\textsubscript{1.82} &42.89\\textsubscript{1.83} &19.88\\textsubscript{11.85} &11.59\\textsubscript{8.31}  \\\\\n",
      " &  & 25 & 1,975 & 62.27\\textsubscript{5.12} &45.41\\textsubscript{5.34} &61.41\\textsubscript{3.97} &44.43\\textsubscript{4.19} &21.87\\textsubscript{5.66} &12.40\\textsubscript{3.70}  \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-10}\\arrayrulecolor{black}\n",
      " & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{500}}} & 500 & 500 & 79.48\\textsubscript{1.91} &65.99\\textsubscript{2.65} &73.10\\textsubscript{2.50} &57.66\\textsubscript{3.08} &48.01\\textsubscript{6.25} &31.82\\textsubscript{5.60}  \\\\\n",
      " &  & 500 & 1,000 & 77.66\\textsubscript{3.22} &63.60\\textsubscript{4.40} &71.60\\textsubscript{3.49} &55.87\\textsubscript{4.15} &42.13\\textsubscript{5.56} &26.85\\textsubscript{4.53}  \\\\\n",
      " &  & 500 & 1,500 & 76.76\\textsubscript{2.59} &62.36\\textsubscript{3.48} &70.26\\textsubscript{4.29} &54.32\\textsubscript{4.99} &38.83\\textsubscript{3.46} &24.15\\textsubscript{2.68}  \\\\\n",
      "\\hline\n",
      "\\multirow{6}{*}{\\textbf{GPT-3.5-turbo}} & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{25}}} & 25 & 475 & 64.69\\textsubscript{5.29} &48.04\\textsubscript{5.84} &51.24\\textsubscript{3.57} &34.52\\textsubscript{3.26} &41.89\\textsubscript{12.02} &27.24\\textsubscript{9.74}  \\\\\n",
      " &  & 25 & 975 & 64.69\\textsubscript{3.46} &47.91\\textsubscript{3.90} &49.54\\textsubscript{8.90} &33.37\\textsubscript{7.49} &43.73\\textsubscript{10.87} &28.67\\textsubscript{9.94}  \\\\\n",
      " &  & 25 & 1,975 & 67.46\\textsubscript{5.36} &51.14\\textsubscript{6.11} &50.30\\textsubscript{4.92} &33.75\\textsubscript{4.42} &56.68\\textsubscript{11.02} &40.36\\textsubscript{10.68}  \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-10}\\arrayrulecolor{black}\n",
      " & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{500}}} & 500 & 500 & 80.33\\textsubscript{4.28} &67.35\\textsubscript{6.14} &72.69\\textsubscript{4.48} &57.29\\textsubscript{5.40} &63.80\\textsubscript{8.36} &47.40\\textsubscript{9.16}  \\\\\n",
      " &  & 500 & 1,000 & 80.16\\textsubscript{3.16} &67.00\\textsubscript{4.45} &70.39\\textsubscript{4.86} &54.51\\textsubscript{5.56} &67.09\\textsubscript{7.39} &50.94\\textsubscript{8.30}  \\\\\n",
      " &  & 500 & 1,500 & 80.21\\textsubscript{3.78} &67.12\\textsubscript{5.11} &71.13\\textsubscript{5.14} &55.43\\textsubscript{5.97} &63.67\\textsubscript{8.39} &47.26\\textsubscript{8.91}  \\\\\n",
      "\\hline\n"
     ]
    }
   ],
   "source": [
    "absa_task = \"end_2_end_absa\"\n",
    "for n_real_idx, n_real in enumerate([500, 1000, 2000]):\n",
    "    json_path = RESULTS_PATH_BASE + \\\n",
    "        f\"only_real_real{n_real}_synth0_{absa_task}_random.json\"\n",
    "    with open(json_path, 'r') as json_file:\n",
    "        results = json.load(json_file)\n",
    "\n",
    "    if n_real_idx == 0:\n",
    "        condition_print = \"\\\\multirow{3}{*}{\\\\textbf{Real Examples}} & \\\\multirow{3}{*}{-}\"\n",
    "    else:\n",
    "        condition_print = \" & \"\n",
    "\n",
    "    class_wise_metrics = \"\"\n",
    "    for polarity in [\"POSITIVE\", \"NEGATIVE\", \"NEUTRAL\"]:\n",
    "        for metric in [\"f1\", \"accuracy\"]:\n",
    "            class_wise_metrics += f\"{get_metric(f'eval_{metric}_{polarity}', results)} &\"\n",
    "    print(\n",
    "        f\"{condition_print} & {add_thousand_dots(str(n_real))} & 0 & {class_wise_metrics[:-1]} \\\\\\\\\")\n",
    "print(\"\\\\hline\")\n",
    "for llm_idx, llm in enumerate(LLMS):\n",
    "    for fs_idx, few_shot_condition in enumerate(SYNTH_COMBINATIONS.keys()):\n",
    "        for freq_idx, freq in enumerate(SYNTH_COMBINATIONS[few_shot_condition]):\n",
    "            n_real = freq[\"real\"]\n",
    "            n_synth = freq[\"synth\"]\n",
    "            json_path = RESULTS_PATH_BASE + llm + \\\n",
    "                f\"_real{n_real}_synth{n_synth}_{absa_task}_{few_shot_condition}.json\"\n",
    "            with open(json_path, 'r') as json_file:\n",
    "                results = json.load(json_file)\n",
    "\n",
    "            if fs_idx == 0 and freq_idx == 0:\n",
    "                llm_print = \"\\\\multirow{6}{*}{\"+LLMS_ENCODED[llm]+\"}\"\n",
    "            else:\n",
    "                llm_print = \"\"\n",
    "\n",
    "            if freq_idx == 0:\n",
    "                condition_print = \"\\\\multirow{3}{*}{\" + \\\n",
    "                    ENCODE_CONDITION[few_shot_condition]+\"}\"\n",
    "            else:\n",
    "                condition_print = \"\"\n",
    "\n",
    "            class_wise_metrics = \"\"\n",
    "            for polarity in [\"POSITIVE\", \"NEGATIVE\", \"NEUTRAL\"]:\n",
    "                for metric in [\"f1\", \"accuracy\"]:\n",
    "                    class_wise_metrics += f\"{get_metric(f'eval_{metric}_{polarity}', results)} &\"\n",
    "\n",
    "            print(\n",
    "                f\"{llm_print} & {condition_print} & {add_thousand_dots(str(n_real))} & {add_thousand_dots(str(n_synth))} & {class_wise_metrics[:-1]} \\\\\\\\\")\n",
    "            if fs_idx == 0 and freq_idx == 2:\n",
    "               print(\n",
    "                \"\\\\arrayrulecolor{gray}\\cline{2-10}\\\\arrayrulecolor{black}\")\n",
    "\n",
    "    print(\"\\hline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ACSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_str(values):\n",
    "    return [value for value in values if isinstance(value, (int, float))]\n",
    "\n",
    "def get_metric(metric, ac, polarity, results):\n",
    "    metric_name = f'{metric}_{ac}-{polarity}'\n",
    "    main_values = []\n",
    "\n",
    "    for i in range(0, 6):\n",
    "        if type(results[\"single_split_results\"][i][f'eval_n_examples_{ac}-{polarity}']) != str:\n",
    "            main_values.append(results[\"single_split_results\"][i][metric_name] * 100)\n",
    "\n",
    "    std_metric = round_number(np.std(main_values), 2)\n",
    "    main_metric = add_thousand_dots(round_number(np.mean(main_values), 2))\n",
    "    return main_metric + \"\\\\textsubscript{\" + std_metric + \"}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table for: ['GENERAL-IMPRESSION', 'FOOD'] \n",
      "\n",
      "\n",
      "\\multirow{3}{*}{\\textbf{Real Examples}} & \\multirow{3}{*}{-} & 500 & 0 & 82.88\\textsubscript{3.05} & 95.77\\textsubscript{0.41} & 0.00\\textsubscript{0.00} & 99.17\\textsubscript{0.33} & 82.18\\textsubscript{7.34} & 96.33\\textsubscript{1.48} & 91.93\\textsubscript{1.48} & 96.13\\textsubscript{0.84} & 66.30\\textsubscript{8.56} & 98.07\\textsubscript{0.49} & 82.17\\textsubscript{4.06} & 94.37\\textsubscript{1.19} \\\\\n",
      " &  & 1,000 & 0 & 84.74\\textsubscript{2.43} & 96.07\\textsubscript{0.56} & 57.12\\textsubscript{26.45} & 99.43\\textsubscript{0.45} & 85.18\\textsubscript{6.61} & 96.93\\textsubscript{1.30} & 94.47\\textsubscript{1.10} & 97.33\\textsubscript{0.57} & 81.56\\textsubscript{5.95} & 98.63\\textsubscript{0.41} & 86.87\\textsubscript{2.86} & 95.70\\textsubscript{0.93} \\\\\n",
      " &  & 2,000 & 0 & 85.57\\textsubscript{3.62} & 96.27\\textsubscript{0.81} & 67.67\\textsubscript{20.57} & 99.50\\textsubscript{0.40} & 86.50\\textsubscript{4.17} & 97.07\\textsubscript{0.96} & 94.30\\textsubscript{1.23} & 97.23\\textsubscript{0.60} & 85.63\\textsubscript{4.81} & 98.90\\textsubscript{0.38} & 87.05\\textsubscript{2.85} & 95.80\\textsubscript{0.84} \\\\\n",
      "\\hline\n",
      "\\multirow{6}{*}{\\textbf{Llama-3-70B}} & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{25}}} & 25 & 475 & 70.83\\textsubscript{4.27} & 93.20\\textsubscript{0.43} & 25.83\\textsubscript{15.92} & 98.93\\textsubscript{0.46} & 71.38\\textsubscript{9.87} & 94.53\\textsubscript{1.44} & 65.02\\textsubscript{4.84} & 87.37\\textsubscript{1.19} & 37.55\\textsubscript{13.64} & 94.83\\textsubscript{1.49} & 65.85\\textsubscript{5.55} & 91.20\\textsubscript{0.81} \\\\\n",
      " &  & 25 & 975 & 72.16\\textsubscript{2.29} & 92.43\\textsubscript{1.01} & 18.14\\textsubscript{8.08} & 95.87\\textsubscript{1.18} & 68.42\\textsubscript{4.36} & 92.47\\textsubscript{0.60} & 70.77\\textsubscript{3.18} & 88.87\\textsubscript{1.41} & 39.74\\textsubscript{15.69} & 93.23\\textsubscript{3.17} & 71.78\\textsubscript{6.58} & 91.80\\textsubscript{1.40} \\\\\n",
      " &  & 25 & 1,975 & 69.29\\textsubscript{4.39} & 91.60\\textsubscript{1.31} & 14.38\\textsubscript{5.93} & 94.30\\textsubscript{1.73} & 70.58\\textsubscript{4.65} & 93.03\\textsubscript{0.85} & 75.48\\textsubscript{5.47} & 90.20\\textsubscript{2.29} & 38.94\\textsubscript{15.95} & 92.97\\textsubscript{2.49} & 75.65\\textsubscript{6.27} & 92.77\\textsubscript{1.45} \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-16}\\arrayrulecolor{black}\n",
      " & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{500}}} & 500 & 500 & 82.51\\textsubscript{1.48} & 95.57\\textsubscript{0.45} & 52.78\\textsubscript{24.37} & 99.10\\textsubscript{0.56} & 81.35\\textsubscript{6.23} & 96.07\\textsubscript{1.32} & 90.46\\textsubscript{1.45} & 95.53\\textsubscript{0.78} & 61.34\\textsubscript{7.73} & 97.53\\textsubscript{0.27} & 82.44\\textsubscript{4.55} & 94.40\\textsubscript{1.28} \\\\\n",
      " &  & 500 & 1,000 & 81.95\\textsubscript{1.63} & 95.37\\textsubscript{0.59} & 49.28\\textsubscript{18.63} & 98.77\\textsubscript{0.68} & 82.39\\textsubscript{5.06} & 96.10\\textsubscript{1.20} & 89.93\\textsubscript{1.72} & 95.40\\textsubscript{0.83} & 60.75\\textsubscript{7.14} & 97.13\\textsubscript{0.60} & 82.17\\textsubscript{5.56} & 94.33\\textsubscript{1.58} \\\\\n",
      " &  & 500 & 1,500 & 80.65\\textsubscript{4.22} & 95.00\\textsubscript{1.24} & 37.77\\textsubscript{11.59} & 98.13\\textsubscript{0.67} & 79.49\\textsubscript{5.37} & 95.47\\textsubscript{1.29} & 87.31\\textsubscript{2.64} & 94.23\\textsubscript{1.20} & 51.26\\textsubscript{5.35} & 96.57\\textsubscript{0.35} & 82.17\\textsubscript{3.37} & 94.33\\textsubscript{0.94} \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-16}\\arrayrulecolor{black}\n",
      "\\hline\n",
      "\\multirow{6}{*}{\\textbf{GPT-3.5-turbo}} & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{25}}} & 25 & 475 & 66.90\\textsubscript{10.26} & 91.63\\textsubscript{2.17} & 29.81\\textsubscript{15.72} & 99.20\\textsubscript{0.31} & 54.72\\textsubscript{12.03} & 92.60\\textsubscript{1.24} & 71.25\\textsubscript{5.92} & 89.00\\textsubscript{1.68} & 63.85\\textsubscript{6.62} & 97.57\\textsubscript{0.69} & 49.37\\textsubscript{15.44} & 89.20\\textsubscript{1.91} \\\\\n",
      " &  & 25 & 975 & 70.92\\textsubscript{7.90} & 91.87\\textsubscript{2.29} & 50.68\\textsubscript{19.27} & 99.17\\textsubscript{0.35} & 68.74\\textsubscript{7.53} & 93.67\\textsubscript{0.88} & 82.42\\textsubscript{3.73} & 92.50\\textsubscript{1.60} & 65.77\\textsubscript{7.85} & 97.07\\textsubscript{1.02} & 68.47\\textsubscript{12.32} & 91.97\\textsubscript{1.56} \\\\\n",
      " &  & 25 & 1,975 & 71.87\\textsubscript{5.35} & 91.40\\textsubscript{2.08} & 40.48\\textsubscript{11.45} & 98.87\\textsubscript{0.30} & 67.72\\textsubscript{5.88} & 92.80\\textsubscript{0.70} & 82.74\\textsubscript{3.53} & 92.27\\textsubscript{1.91} & 65.71\\textsubscript{11.18} & 96.90\\textsubscript{1.30} & 70.57\\textsubscript{7.59} & 92.30\\textsubscript{1.07} \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-16}\\arrayrulecolor{black}\n",
      " & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{500}}} & 500 & 500 & 83.41\\textsubscript{1.46} & 95.63\\textsubscript{0.58} & 58.33\\textsubscript{15.18} & 99.40\\textsubscript{0.42} & 82.68\\textsubscript{6.32} & 96.30\\textsubscript{1.32} & 92.12\\textsubscript{1.51} & 96.23\\textsubscript{0.86} & 82.30\\textsubscript{8.24} & 98.80\\textsubscript{0.49} & 84.58\\textsubscript{3.55} & 95.00\\textsubscript{1.12} \\\\\n",
      " &  & 500 & 1,000 & 82.99\\textsubscript{1.77} & 95.53\\textsubscript{0.61} & 58.97\\textsubscript{14.73} & 99.40\\textsubscript{0.33} & 83.72\\textsubscript{3.75} & 96.40\\textsubscript{0.95} & 91.92\\textsubscript{1.54} & 96.13\\textsubscript{0.85} & 81.15\\textsubscript{8.12} & 98.70\\textsubscript{0.60} & 85.42\\textsubscript{2.75} & 95.40\\textsubscript{0.83} \\\\\n",
      " &  & 500 & 1,500 & 83.31\\textsubscript{2.97} & 95.53\\textsubscript{0.91} & 60.23\\textsubscript{13.02} & 99.30\\textsubscript{0.43} & 81.43\\textsubscript{6.37} & 95.97\\textsubscript{1.41} & 92.06\\textsubscript{1.43} & 96.20\\textsubscript{0.77} & 78.40\\textsubscript{3.76} & 98.47\\textsubscript{0.27} & 85.13\\textsubscript{3.30} & 95.37\\textsubscript{0.99} \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-16}\\arrayrulecolor{black}\n",
      "\\hline\n",
      "Table for: ['SERVICE', 'AMBIENCE'] \n",
      "\n",
      "\n",
      "\\multirow{3}{*}{\\textbf{Real Examples}} & \\multirow{3}{*}{-} & 500 & 0 & 91.34\\textsubscript{1.66} & 97.13\\textsubscript{0.44} & 0.00\\textsubscript{0.00} & 99.60\\textsubscript{0.13} & 85.92\\textsubscript{2.84} & 95.97\\textsubscript{0.33} & 85.01\\textsubscript{3.28} & 97.30\\textsubscript{0.65} & 0.00\\textsubscript{0.00} & 99.75\\textsubscript{0.09} & 69.41\\textsubscript{9.19} & 97.90\\textsubscript{0.62} \\\\\n",
      " &  & 1,000 & 0 & 93.98\\textsubscript{2.25} & 97.93\\textsubscript{0.73} & 13.33\\textsubscript{26.67} & 99.64\\textsubscript{0.15} & 90.69\\textsubscript{1.73} & 97.23\\textsubscript{0.44} & 86.44\\textsubscript{1.13} & 97.43\\textsubscript{0.39} & 0.00\\textsubscript{0.00} & 99.75\\textsubscript{0.09} & 79.40\\textsubscript{6.51} & 98.37\\textsubscript{0.48} \\\\\n",
      " &  & 2,000 & 0 & 95.15\\textsubscript{2.24} & 98.37\\textsubscript{0.65} & 40.00\\textsubscript{48.99} & 99.72\\textsubscript{0.24} & 90.64\\textsubscript{2.73} & 97.17\\textsubscript{0.80} & 87.25\\textsubscript{2.89} & 97.53\\textsubscript{0.57} & 0.00\\textsubscript{0.00} & 99.75\\textsubscript{0.09} & 83.64\\textsubscript{6.02} & 98.73\\textsubscript{0.39} \\\\\n",
      "\\hline\n",
      "\\multirow{6}{*}{\\textbf{Llama-3-70B}} & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{25}}} & 25 & 475 & 57.99\\textsubscript{10.13} & 89.87\\textsubscript{1.75} & 11.83\\textsubscript{10.45} & 98.40\\textsubscript{0.69} & 49.77\\textsubscript{8.56} & 89.97\\textsubscript{1.16} & 56.20\\textsubscript{13.46} & 94.00\\textsubscript{1.62} & 25.00\\textsubscript{43.30} & 99.25\\textsubscript{0.52} & 51.70\\textsubscript{14.43} & 97.13\\textsubscript{0.76} \\\\\n",
      " &  & 25 & 975 & 67.12\\textsubscript{8.24} & 91.50\\textsubscript{1.66} & 16.47\\textsubscript{5.20} & 96.84\\textsubscript{1.42} & 68.39\\textsubscript{3.76} & 92.53\\textsubscript{0.67} & 65.55\\textsubscript{8.65} & 94.90\\textsubscript{1.25} & 17.05\\textsubscript{20.42} & 97.70\\textsubscript{1.50} & 65.35\\textsubscript{6.79} & 97.43\\textsubscript{0.44} \\\\\n",
      " &  & 25 & 1,975 & 66.01\\textsubscript{7.64} & 91.20\\textsubscript{1.20} & 13.71\\textsubscript{8.59} & 97.08\\textsubscript{0.84} & 70.82\\textsubscript{5.35} & 93.00\\textsubscript{0.58} & 62.63\\textsubscript{5.53} & 94.57\\textsubscript{0.84} & 10.67\\textsubscript{8.17} & 97.10\\textsubscript{1.40} & 68.73\\textsubscript{7.45} & 97.60\\textsubscript{0.52} \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-16}\\arrayrulecolor{black}\n",
      " & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{500}}} & 500 & 500 & 87.26\\textsubscript{3.03} & 95.97\\textsubscript{0.90} & 37.05\\textsubscript{7.43} & 99.08\\textsubscript{0.16} & 85.44\\textsubscript{3.61} & 95.80\\textsubscript{0.63} & 83.58\\textsubscript{1.60} & 97.10\\textsubscript{0.40} & 8.33\\textsubscript{14.43} & 99.50\\textsubscript{0.22} & 73.68\\textsubscript{6.02} & 98.00\\textsubscript{0.46} \\\\\n",
      " &  & 500 & 1,000 & 86.75\\textsubscript{2.68} & 95.83\\textsubscript{0.80} & 25.38\\textsubscript{13.65} & 99.12\\textsubscript{0.20} & 85.31\\textsubscript{4.18} & 95.87\\textsubscript{0.73} & 81.18\\textsubscript{3.79} & 96.73\\textsubscript{0.66} & 8.33\\textsubscript{14.43} & 99.20\\textsubscript{0.37} & 70.08\\textsubscript{6.10} & 97.73\\textsubscript{0.49} \\\\\n",
      " &  & 500 & 1,500 & 84.80\\textsubscript{3.44} & 95.33\\textsubscript{0.80} & 28.95\\textsubscript{8.62} & 98.80\\textsubscript{0.31} & 85.69\\textsubscript{2.08} & 95.87\\textsubscript{0.27} & 81.85\\textsubscript{2.06} & 96.90\\textsubscript{0.30} & 6.25\\textsubscript{10.83} & 99.05\\textsubscript{0.22} & 73.78\\textsubscript{8.24} & 98.00\\textsubscript{0.59} \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-16}\\arrayrulecolor{black}\n",
      "\\hline\n",
      "\\multirow{6}{*}{\\textbf{GPT-3.5-turbo}} & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{25}}} & 25 & 475 & 68.72\\textsubscript{9.66} & 91.90\\textsubscript{1.92} & 58.10\\textsubscript{32.49} & 99.68\\textsubscript{0.24} & 40.35\\textsubscript{10.17} & 88.80\\textsubscript{1.95} & 55.81\\textsubscript{14.16} & 94.13\\textsubscript{1.66} & 50.00\\textsubscript{50.00} & 99.90\\textsubscript{0.10} & 49.72\\textsubscript{17.88} & 97.23\\textsubscript{0.80} \\\\\n",
      " &  & 25 & 975 & 77.21\\textsubscript{7.65} & 93.63\\textsubscript{1.73} & 54.67\\textsubscript{14.85} & 99.52\\textsubscript{0.20} & 53.15\\textsubscript{12.55} & 90.57\\textsubscript{1.53} & 64.35\\textsubscript{11.56} & 94.77\\textsubscript{1.53} & 66.67\\textsubscript{40.82} & 99.75\\textsubscript{0.33} & 72.95\\textsubscript{8.03} & 98.10\\textsubscript{0.55} \\\\\n",
      " &  & 25 & 1,975 & 79.48\\textsubscript{4.89} & 94.13\\textsubscript{1.11} & 41.86\\textsubscript{16.10} & 99.12\\textsubscript{0.45} & 60.45\\textsubscript{5.52} & 91.47\\textsubscript{1.16} & 66.20\\textsubscript{11.10} & 94.90\\textsubscript{1.44} & 70.00\\textsubscript{24.27} & 99.70\\textsubscript{0.30} & 70.61\\textsubscript{6.85} & 97.83\\textsubscript{0.52} \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-16}\\arrayrulecolor{black}\n",
      " & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{500}}} & 500 & 500 & 93.68\\textsubscript{1.53} & 97.87\\textsubscript{0.49} & 73.33\\textsubscript{38.87} & 99.84\\textsubscript{0.23} & 88.49\\textsubscript{1.82} & 96.60\\textsubscript{0.45} & 86.89\\textsubscript{1.66} & 97.63\\textsubscript{0.41} & 70.00\\textsubscript{41.23} & 99.90\\textsubscript{0.10} & 75.16\\textsubscript{7.07} & 98.13\\textsubscript{0.52} \\\\\n",
      " &  & 500 & 1,000 & 92.34\\textsubscript{1.54} & 97.43\\textsubscript{0.52} & 66.67\\textsubscript{36.51} & 99.80\\textsubscript{0.22} & 87.67\\textsubscript{2.33} & 96.43\\textsubscript{0.39} & 86.20\\textsubscript{2.13} & 97.50\\textsubscript{0.49} & 50.00\\textsubscript{50.00} & 99.90\\textsubscript{0.10} & 75.07\\textsubscript{6.24} & 98.13\\textsubscript{0.41} \\\\\n",
      " &  & 500 & 1,500 & 91.13\\textsubscript{2.27} & 97.10\\textsubscript{0.60} & 61.33\\textsubscript{23.63} & 99.64\\textsubscript{0.29} & 87.21\\textsubscript{2.12} & 96.27\\textsubscript{0.72} & 86.67\\textsubscript{1.45} & 97.60\\textsubscript{0.37} & 75.00\\textsubscript{43.30} & 99.90\\textsubscript{0.17} & 76.63\\textsubscript{5.78} & 98.20\\textsubscript{0.38} \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-16}\\arrayrulecolor{black}\n",
      "\\hline\n",
      "Table for: ['PRICE'] \n",
      "\n",
      "\n",
      "\\multirow{3}{*}{\\textbf{Real Examples}} & \\multirow{3}{*}{-} & 500 & 0 & 43.26\\textsubscript{26.86} & 98.93\\textsubscript{0.54} & 0.00\\textsubscript{0.00} & 99.37\\textsubscript{0.21} & 81.58\\textsubscript{5.02} & 98.03\\textsubscript{0.67} \\\\\n",
      " &  & 1,000 & 0 & 85.70\\textsubscript{8.04} & 99.57\\textsubscript{0.31} & 57.30\\textsubscript{31.65} & 99.63\\textsubscript{0.24} & 85.79\\textsubscript{4.59} & 98.40\\textsubscript{0.55} \\\\\n",
      " &  & 2,000 & 0 & 87.12\\textsubscript{9.44} & 99.60\\textsubscript{0.33} & 71.75\\textsubscript{21.87} & 99.67\\textsubscript{0.25} & 86.70\\textsubscript{5.19} & 98.50\\textsubscript{0.60} \\\\\n",
      "\\hline\n",
      "\\multirow{6}{*}{\\textbf{Llama-3-70B}} & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{25}}} & 25 & 475 & 54.22\\textsubscript{18.53} & 99.07\\textsubscript{0.30} & 32.50\\textsubscript{28.25} & 99.20\\textsubscript{0.42} & 58.87\\textsubscript{12.34} & 96.67\\textsubscript{1.04} \\\\\n",
      " &  & 25 & 975 & 52.18\\textsubscript{15.09} & 98.90\\textsubscript{0.30} & 34.97\\textsubscript{21.83} & 98.73\\textsubscript{0.62} & 69.84\\textsubscript{8.44} & 97.27\\textsubscript{0.80} \\\\\n",
      " &  & 25 & 1,975 & 62.83\\textsubscript{13.78} & 98.87\\textsubscript{0.56} & 38.64\\textsubscript{18.36} & 98.63\\textsubscript{0.55} & 72.62\\textsubscript{4.84} & 97.50\\textsubscript{0.38} \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-10}\\arrayrulecolor{black}\n",
      " & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{500}}} & 500 & 500 & 79.97\\textsubscript{12.21} & 99.37\\textsubscript{0.50} & 47.62\\textsubscript{25.20} & 99.40\\textsubscript{0.31} & 77.47\\textsubscript{4.39} & 97.70\\textsubscript{0.30} \\\\\n",
      " &  & 500 & 1,000 & 73.86\\textsubscript{16.40} & 99.23\\textsubscript{0.58} & 35.56\\textsubscript{28.65} & 99.23\\textsubscript{0.39} & 77.54\\textsubscript{7.12} & 97.80\\textsubscript{0.62} \\\\\n",
      " &  & 500 & 1,500 & 73.83\\textsubscript{13.21} & 99.20\\textsubscript{0.46} & 38.52\\textsubscript{36.33} & 99.13\\textsubscript{0.52} & 77.12\\textsubscript{8.44} & 97.73\\textsubscript{0.85} \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-10}\\arrayrulecolor{black}\n",
      "\\hline\n",
      "\\multirow{6}{*}{\\textbf{GPT-3.5-turbo}} & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{25}}} & 25 & 475 & 48.86\\textsubscript{18.74} & 98.97\\textsubscript{0.48} & 8.33\\textsubscript{18.63} & 99.33\\textsubscript{0.25} & 49.84\\textsubscript{17.50} & 96.33\\textsubscript{1.07} \\\\\n",
      " &  & 25 & 975 & 59.02\\textsubscript{14.47} & 98.83\\textsubscript{0.42} & 16.67\\textsubscript{25.46} & 99.10\\textsubscript{0.32} & 68.61\\textsubscript{7.40} & 97.13\\textsubscript{0.75} \\\\\n",
      " &  & 25 & 1,975 & 66.04\\textsubscript{4.35} & 98.87\\textsubscript{0.43} & 33.95\\textsubscript{11.22} & 98.73\\textsubscript{0.52} & 67.34\\textsubscript{7.45} & 96.87\\textsubscript{0.81} \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-10}\\arrayrulecolor{black}\n",
      " & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{500}}} & 500 & 500 & 69.66\\textsubscript{7.73} & 99.07\\textsubscript{0.43} & 61.94\\textsubscript{24.65} & 99.47\\textsubscript{0.39} & 80.04\\textsubscript{4.70} & 97.93\\textsubscript{0.50} \\\\\n",
      " &  & 500 & 1,000 & 77.42\\textsubscript{7.10} & 99.30\\textsubscript{0.34} & 63.06\\textsubscript{13.89} & 99.53\\textsubscript{0.19} & 82.33\\textsubscript{5.04} & 98.17\\textsubscript{0.58} \\\\\n",
      " &  & 500 & 1,500 & 71.70\\textsubscript{7.38} & 99.10\\textsubscript{0.34} & 62.94\\textsubscript{9.60} & 99.47\\textsubscript{0.19} & 80.67\\textsubscript{4.56} & 98.00\\textsubscript{0.69} \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-10}\\arrayrulecolor{black}\n",
      "\\hline\n"
     ]
    }
   ],
   "source": [
    "absa_task = \"aspect_category_sentiment\"\n",
    "\n",
    "idx = 0\n",
    "for ac_idx, aspect_categories in enumerate([[\"GENERAL-IMPRESSION\", \"FOOD\"], [\"SERVICE\", \"AMBIENCE\"], [\"PRICE\"]]):\n",
    "    print(\"Table for:\", aspect_categories, \"\\n\\n\")\n",
    "    for n_real_idx, n_real in enumerate([500, 1000, 2000]):\n",
    "        json_path = RESULTS_PATH_BASE + \\\n",
    "            f\"only_real_real{n_real}_synth0_{absa_task}_random.json\"\n",
    "        with open(json_path, 'r') as json_file:\n",
    "            results = json.load(json_file)\n",
    "\n",
    "        if n_real_idx == 0:\n",
    "            condition_print = \"\\\\multirow{3}{*}{\\\\textbf{Real Examples}} & \\\\multirow{3}{*}{-}\"\n",
    "        else:\n",
    "            condition_print = \" & \"\n",
    "\n",
    "        condition_string = f\"{condition_print} & {add_thousand_dots(str(n_real))} & 0 &\"\n",
    "        metrics_class_wise = \"\"\n",
    "        for ac in aspect_categories:\n",
    "            for polarity in [\"POSITIVE\", \"NEUTRAL\", \"NEGATIVE\"]:\n",
    "                for metric in [\"eval_f1\", \"eval_accuracy\"]:\n",
    "                    metrics_class_wise += f\" {get_metric(metric, ac, polarity, results)} &\"\n",
    "\n",
    "        print(condition_string + metrics_class_wise[:-1] + \"\\\\\\\\\")\n",
    "\n",
    "    print(\"\\\\hline\")\n",
    "    for llm_idx, llm in enumerate(LLMS):\n",
    "        for fs_idx, few_shot_condition in enumerate(SYNTH_COMBINATIONS.keys()):\n",
    "            for freq_idx, freq in enumerate(SYNTH_COMBINATIONS[few_shot_condition]):\n",
    "                n_real = freq[\"real\"]\n",
    "                n_synth = freq[\"synth\"]\n",
    "                json_path = RESULTS_PATH_BASE + llm + \\\n",
    "                    f\"_real{n_real}_synth{n_synth}_{absa_task}_{few_shot_condition}.json\"\n",
    "                with open(json_path, 'r') as json_file:\n",
    "                    results = json.load(json_file)\n",
    "\n",
    "                if fs_idx == 0 and freq_idx == 0:\n",
    "                    llm_print = \"\\\\multirow{6}{*}{\"+LLMS_ENCODED[llm]+\"}\"\n",
    "                else:\n",
    "                    llm_print = \"\"\n",
    "\n",
    "                if freq_idx == 0:\n",
    "                    condition_print = \"\\\\multirow{3}{*}{\" + \\\n",
    "                        ENCODE_CONDITION[few_shot_condition]+\"}\"\n",
    "                else:\n",
    "                    condition_print = \"\"\n",
    "\n",
    "                condition_string = f\"{llm_print} & {condition_print} & {add_thousand_dots(str(n_real))} & {add_thousand_dots(str(n_synth))} &\"\n",
    "                metrics_class_wise = \"\"\n",
    "                for ac in aspect_categories:\n",
    "                    for polarity in [\"POSITIVE\", \"NEUTRAL\", \"NEGATIVE\"]:\n",
    "                        for metric in [\"eval_f1\", \"eval_accuracy\"]:\n",
    "                            metrics_class_wise += f\" {get_metric(metric, ac, polarity, results)} &\"\n",
    "\n",
    "                print(condition_string + metrics_class_wise[:-1] + \"\\\\\\\\\")\n",
    "            \n",
    "                n_col = 10 if ac_idx == 2 else 16\n",
    "                if freq_idx == 2:\n",
    "                   print(\"\\\\arrayrulecolor{gray}\\cline{2-\"+str(n_col)+\"}\\\\arrayrulecolor{black}\")\n",
    "        print(\"\\hline\")\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TASD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_str(values):\n",
    "    return [value for value in values if isinstance(value, (int, float))]\n",
    "\n",
    "\n",
    "def get_metric(metric, ac, polarity, results):\n",
    "    metric_name = f'{metric}_{ac}_{polarity}'\n",
    "    \n",
    "    main_values = []\n",
    "\n",
    "    for i in range(0, 6):\n",
    "        if results[\"single_split_results\"][i][f'eval_n_examples_{ac}_{polarity}'] > 0:\n",
    "            main_values.append(results[\"single_split_results\"][i][metric_name] * 100)\n",
    "\n",
    "    std_metric = round_number(np.std(main_values), 2)\n",
    "    main_metric = add_thousand_dots(round_number(np.mean(main_values), 2))\n",
    "    return main_metric + \"\\\\textsubscript{\" + std_metric + \"}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table for: ['GENERAL-IMPRESSION', 'FOOD'] \n",
      "\n",
      "\n",
      "\\multirow{3}{*}{\\textbf{Real Examples}} & \\multirow{3}{*}{-} & 500 & 0 & 65.42\\textsubscript{7.04} & 49.01\\textsubscript{7.63} & 42.17\\textsubscript{26.07} & 30.32\\textsubscript{22.07} & 65.44\\textsubscript{7.86} & 49.13\\textsubscript{8.52} & 69.22\\textsubscript{4.46} & 53.11\\textsubscript{5.24} & 61.52\\textsubscript{11.66} & 45.44\\textsubscript{12.06} & 50.47\\textsubscript{3.61} & 33.83\\textsubscript{3.24} \\\\\n",
      " &  & 1,000 & 0 & 70.62\\textsubscript{5.18} & 54.84\\textsubscript{6.51} & 53.33\\textsubscript{15.75} & 38.06\\textsubscript{15.82} & 66.53\\textsubscript{8.50} & 50.42\\textsubscript{9.12} & 71.77\\textsubscript{3.25} & 56.07\\textsubscript{3.93} & 71.65\\textsubscript{11.98} & 57.14\\textsubscript{14.24} & 52.95\\textsubscript{2.32} & 36.04\\textsubscript{2.10} \\\\\n",
      " &  & 2,000 & 0 & 74.21\\textsubscript{4.02} & 59.17\\textsubscript{5.16} & 42.20\\textsubscript{23.40} & 29.31\\textsubscript{17.39} & 72.56\\textsubscript{8.03} & 57.51\\textsubscript{9.00} & 75.93\\textsubscript{1.88} & 61.24\\textsubscript{2.44} & 71.62\\textsubscript{11.77} & 57.07\\textsubscript{14.02} & 56.99\\textsubscript{3.71} & 39.94\\textsubscript{3.67} \\\\\n",
      "\\hline\n",
      "\\multirow{6}{*}{\\textbf{Llama-3-70B}} & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{25}}} & 25 & 475 & 48.19\\textsubscript{3.49} & 31.82\\textsubscript{3.10} & 5.67\\textsubscript{3.36} & 2.95\\textsubscript{1.77} & 40.13\\textsubscript{6.85} & 25.34\\textsubscript{5.44} & 45.19\\textsubscript{9.22} & 29.62\\textsubscript{7.24} & 22.47\\textsubscript{9.55} & 13.00\\textsubscript{6.41} & 35.57\\textsubscript{6.34} & 21.82\\textsubscript{4.76} \\\\\n",
      " &  & 25 & 975 & 48.64\\textsubscript{3.94} & 32.23\\textsubscript{3.49} & 7.12\\textsubscript{3.94} & 3.74\\textsubscript{2.14} & 43.03\\textsubscript{7.67} & 27.71\\textsubscript{6.11} & 45.02\\textsubscript{8.75} & 29.44\\textsubscript{6.90} & 23.11\\textsubscript{11.77} & 13.60\\textsubscript{8.08} & 37.42\\textsubscript{2.94} & 23.05\\textsubscript{2.22} \\\\\n",
      " &  & 25 & 1,975 & 47.65\\textsubscript{8.11} & 31.65\\textsubscript{6.97} & 5.24\\textsubscript{2.31} & 2.70\\textsubscript{1.23} & 43.93\\textsubscript{5.39} & 28.30\\textsubscript{4.28} & 47.67\\textsubscript{4.22} & 31.39\\textsubscript{3.52} & 22.51\\textsubscript{8.40} & 12.95\\textsubscript{5.67} & 36.83\\textsubscript{2.50} & 22.60\\textsubscript{1.88} \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-16}\\arrayrulecolor{black}\n",
      " & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{500}}} & 500 & 500 & 65.44\\textsubscript{5.81} & 48.91\\textsubscript{6.55} & 21.72\\textsubscript{11.51} & 12.63\\textsubscript{6.97} & 61.27\\textsubscript{4.44} & 44.31\\textsubscript{4.68} & 66.69\\textsubscript{3.18} & 50.11\\textsubscript{3.54} & 52.08\\textsubscript{11.02} & 36.02\\textsubscript{10.86} & 48.73\\textsubscript{3.94} & 32.30\\textsubscript{3.43} \\\\\n",
      " &  & 500 & 1,000 & 63.87\\textsubscript{5.36} & 47.16\\textsubscript{6.09} & 24.00\\textsubscript{6.95} & 13.82\\textsubscript{4.58} & 61.82\\textsubscript{7.87} & 45.18\\textsubscript{7.77} & 66.05\\textsubscript{2.93} & 49.38\\textsubscript{3.25} & 44.80\\textsubscript{7.35} & 29.17\\textsubscript{6.46} & 49.58\\textsubscript{4.62} & 33.09\\textsubscript{3.97} \\\\\n",
      " &  & 500 & 1,500 & 60.98\\textsubscript{6.40} & 44.19\\textsubscript{6.90} & 18.99\\textsubscript{10.45} & 10.86\\textsubscript{6.32} & 63.22\\textsubscript{6.01} & 46.50\\textsubscript{6.19} & 62.86\\textsubscript{4.21} & 45.98\\textsubscript{4.46} & 34.89\\textsubscript{10.76} & 21.66\\textsubscript{8.08} & 50.06\\textsubscript{5.08} & 33.54\\textsubscript{4.51} \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-16}\\arrayrulecolor{black}\n",
      "\\hline\n",
      "\\multirow{6}{*}{\\textbf{GPT-3.5-turbo}} & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{25}}} & 25 & 475 & 41.89\\textsubscript{7.46} & 26.78\\textsubscript{6.09} & 16.77\\textsubscript{15.63} & 10.07\\textsubscript{10.72} & 36.69\\textsubscript{5.49} & 22.61\\textsubscript{4.11} & 40.83\\textsubscript{4.82} & 25.77\\textsubscript{3.93} & 32.97\\textsubscript{12.17} & 20.43\\textsubscript{9.48} & 31.02\\textsubscript{3.78} & 18.41\\textsubscript{2.64} \\\\\n",
      " &  & 25 & 975 & 39.54\\textsubscript{6.75} & 24.87\\textsubscript{5.42} & 13.51\\textsubscript{8.33} & 7.46\\textsubscript{4.74} & 36.43\\textsubscript{3.11} & 22.32\\textsubscript{2.32} & 42.14\\textsubscript{6.27} & 26.90\\textsubscript{5.14} & 31.59\\textsubscript{8.74} & 19.08\\textsubscript{6.24} & 34.85\\textsubscript{2.92} & 21.14\\textsubscript{2.15} \\\\\n",
      " &  & 25 & 1,975 & 40.49\\textsubscript{7.94} & 25.68\\textsubscript{6.08} & 16.48\\textsubscript{11.66} & 9.44\\textsubscript{7.17} & 39.72\\textsubscript{5.30} & 24.92\\textsubscript{4.19} & 43.34\\textsubscript{4.89} & 27.79\\textsubscript{3.94} & 27.92\\textsubscript{11.57} & 16.80\\textsubscript{8.60} & 33.22\\textsubscript{5.41} & 20.05\\textsubscript{3.91} \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-16}\\arrayrulecolor{black}\n",
      " & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{500}}} & 500 & 500 & 63.95\\textsubscript{8.57} & 47.56\\textsubscript{8.75} & 38.17\\textsubscript{12.58} & 24.35\\textsubscript{9.83} & 63.39\\textsubscript{8.43} & 46.95\\textsubscript{8.81} & 69.50\\textsubscript{3.80} & 53.39\\textsubscript{4.43} & 58.69\\textsubscript{12.11} & 42.57\\textsubscript{12.20} & 51.12\\textsubscript{3.78} & 34.42\\textsubscript{3.30} \\\\\n",
      " &  & 500 & 1,000 & 66.67\\textsubscript{5.27} & 50.24\\textsubscript{6.12} & 44.34\\textsubscript{17.26} & 30.36\\textsubscript{16.97} & 60.71\\textsubscript{7.91} & 44.05\\textsubscript{8.15} & 66.98\\textsubscript{3.28} & 50.44\\textsubscript{3.68} & 56.47\\textsubscript{14.31} & 40.84\\textsubscript{15.12} & 49.78\\textsubscript{2.25} & 33.17\\textsubscript{2.01} \\\\\n",
      " &  & 500 & 1,500 & 64.48\\textsubscript{6.32} & 47.89\\textsubscript{6.75} & 32.19\\textsubscript{21.06} & 21.15\\textsubscript{15.82} & 62.30\\textsubscript{8.28} & 45.75\\textsubscript{8.54} & 66.20\\textsubscript{3.50} & 49.58\\textsubscript{3.80} & 54.62\\textsubscript{14.53} & 39.01\\textsubscript{14.46} & 49.86\\textsubscript{4.63} & 33.33\\textsubscript{3.97} \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-16}\\arrayrulecolor{black}\n",
      "\\hline\n",
      "Table for: ['SERVICE', 'AMBIENCE'] \n",
      "\n",
      "\n",
      "\\multirow{3}{*}{\\textbf{Real Examples}} & \\multirow{3}{*}{-} & 500 & 0 & 73.94\\textsubscript{4.07} & 58.83\\textsubscript{5.34} & 69.33\\textsubscript{36.90} & 63.33\\textsubscript{37.12} & 55.20\\textsubscript{3.18} & 38.19\\textsubscript{3.03} & 65.41\\textsubscript{5.06} & 48.81\\textsubscript{5.65} & 37.50\\textsubscript{41.46} & 33.33\\textsubscript{40.82} & 31.88\\textsubscript{8.87} & 19.31\\textsubscript{6.61} \\\\\n",
      " &  & 1,000 & 0 & 77.72\\textsubscript{3.56} & 63.70\\textsubscript{4.81} & 66.67\\textsubscript{36.51} & 60.00\\textsubscript{37.42} & 61.73\\textsubscript{3.77} & 44.75\\textsubscript{3.90} & 67.76\\textsubscript{4.76} & 51.44\\textsubscript{5.57} & 66.67\\textsubscript{40.82} & 62.50\\textsubscript{41.46} & 37.42\\textsubscript{8.38} & 23.35\\textsubscript{6.60} \\\\\n",
      " &  & 2,000 & 0 & 79.16\\textsubscript{2.73} & 65.59\\textsubscript{3.79} & 56.67\\textsubscript{32.66} & 46.67\\textsubscript{32.32} & 64.55\\textsubscript{3.55} & 47.76\\textsubscript{3.86} & 70.75\\textsubscript{4.53} & 54.93\\textsubscript{5.33} & 66.67\\textsubscript{40.82} & 62.50\\textsubscript{41.46} & 42.72\\textsubscript{8.41} & 27.54\\textsubscript{7.05} \\\\\n",
      "\\hline\n",
      "\\multirow{6}{*}{\\textbf{Llama-3-70B}} & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{25}}} & 25 & 475 & 52.61\\textsubscript{6.15} & 35.93\\textsubscript{5.59} & 10.67\\textsubscript{7.15} & 5.79\\textsubscript{4.00} & 37.24\\textsubscript{6.35} & 23.07\\textsubscript{4.88} & 46.04\\textsubscript{9.14} & 30.36\\textsubscript{7.69} & 9.30\\textsubscript{5.97} & 4.98\\textsubscript{3.24} & 25.65\\textsubscript{6.89} & 14.89\\textsubscript{4.53} \\\\\n",
      " &  & 25 & 975 & 55.36\\textsubscript{2.65} & 38.32\\textsubscript{2.52} & 7.56\\textsubscript{1.13} & 3.93\\textsubscript{0.61} & 38.88\\textsubscript{7.10} & 24.38\\textsubscript{5.62} & 48.64\\textsubscript{4.86} & 32.27\\textsubscript{4.24} & 8.52\\textsubscript{10.21} & 4.76\\textsubscript{5.83} & 26.71\\textsubscript{6.94} & 15.59\\textsubscript{4.55} \\\\\n",
      " &  & 25 & 1,975 & 54.36\\textsubscript{2.83} & 37.38\\textsubscript{2.65} & 4.82\\textsubscript{4.12} & 2.52\\textsubscript{2.15} & 43.74\\textsubscript{2.70} & 28.03\\textsubscript{2.18} & 44.52\\textsubscript{5.89} & 28.82\\textsubscript{4.93} & 1.47\\textsubscript{2.55} & 0.76\\textsubscript{1.31} & 25.04\\textsubscript{7.02} & 14.49\\textsubscript{4.58} \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-16}\\arrayrulecolor{black}\n",
      " & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{500}}} & 500 & 500 & 68.96\\textsubscript{5.78} & 52.91\\textsubscript{6.58} & 21.38\\textsubscript{11.55} & 12.41\\textsubscript{6.85} & 57.62\\textsubscript{2.37} & 40.51\\textsubscript{2.34} & 61.88\\textsubscript{5.28} & 45.01\\textsubscript{5.49} & 25.00\\textsubscript{27.64} & 17.50\\textsubscript{20.46} & 29.55\\textsubscript{3.82} & 17.40\\textsubscript{2.64} \\\\\n",
      " &  & 500 & 1,000 & 69.79\\textsubscript{3.70} & 53.72\\textsubscript{4.38} & 19.65\\textsubscript{16.24} & 11.78\\textsubscript{9.78} & 59.37\\textsubscript{4.24} & 42.34\\textsubscript{4.19} & 63.15\\textsubscript{4.28} & 46.29\\textsubscript{4.65} & 13.39\\textsubscript{13.45} & 7.74\\textsubscript{7.78} & 32.33\\textsubscript{5.16} & 19.40\\textsubscript{3.81} \\\\\n",
      " &  & 500 & 1,500 & 69.45\\textsubscript{2.57} & 53.26\\textsubscript{3.03} & 25.05\\textsubscript{13.42} & 14.94\\textsubscript{8.17} & 54.27\\textsubscript{2.75} & 37.28\\textsubscript{2.55} & 59.92\\textsubscript{5.04} & 42.96\\textsubscript{5.08} & 8.33\\textsubscript{14.43} & 5.00\\textsubscript{8.66} & 28.12\\textsubscript{4.12} & 16.42\\textsubscript{2.73} \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-16}\\arrayrulecolor{black}\n",
      "\\hline\n",
      "\\multirow{6}{*}{\\textbf{GPT-3.5-turbo}} & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{25}}} & 25 & 475 & 51.20\\textsubscript{5.45} & 34.60\\textsubscript{5.20} & 24.41\\textsubscript{14.69} & 14.67\\textsubscript{9.15} & 30.41\\textsubscript{9.25} & 18.30\\textsubscript{6.80} & 36.80\\textsubscript{10.36} & 23.04\\textsubscript{7.77} & 22.50\\textsubscript{22.78} & 14.58\\textsubscript{14.88} & 22.02\\textsubscript{7.61} & 12.58\\textsubscript{4.90} \\\\\n",
      " &  & 25 & 975 & 52.65\\textsubscript{4.77} & 35.88\\textsubscript{4.36} & 38.16\\textsubscript{10.16} & 24.05\\textsubscript{7.46} & 32.60\\textsubscript{7.67} & 19.73\\textsubscript{5.60} & 37.63\\textsubscript{12.42} & 23.92\\textsubscript{9.80} & 38.75\\textsubscript{29.66} & 28.57\\textsubscript{24.97} & 28.86\\textsubscript{7.39} & 17.09\\textsubscript{5.18} \\\\\n",
      " &  & 25 & 1,975 & 54.35\\textsubscript{7.76} & 37.70\\textsubscript{7.22} & 23.81\\textsubscript{16.18} & 14.46\\textsubscript{10.32} & 31.10\\textsubscript{5.14} & 18.52\\textsubscript{3.58} & 36.02\\textsubscript{10.32} & 22.45\\textsubscript{7.71} & 13.39\\textsubscript{13.45} & 7.74\\textsubscript{7.78} & 22.49\\textsubscript{8.52} & 12.94\\textsubscript{5.60} \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-16}\\arrayrulecolor{black}\n",
      " & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{500}}} & 500 & 500 & 72.85\\textsubscript{2.73} & 57.37\\textsubscript{3.38} & 44.67\\textsubscript{24.55} & 31.67\\textsubscript{18.56} & 58.60\\textsubscript{1.19} & 41.45\\textsubscript{1.19} & 61.88\\textsubscript{6.13} & 45.09\\textsubscript{6.49} & 33.33\\textsubscript{40.82} & 30.00\\textsubscript{41.23} & 36.23\\textsubscript{6.78} & 22.33\\textsubscript{5.03} \\\\\n",
      " &  & 500 & 1,000 & 72.54\\textsubscript{3.39} & 57.03\\textsubscript{4.27} & 66.67\\textsubscript{36.51} & 60.00\\textsubscript{37.42} & 54.10\\textsubscript{2.59} & 37.13\\textsubscript{2.48} & 59.25\\textsubscript{3.75} & 42.19\\textsubscript{3.77} & 43.33\\textsubscript{27.28} & 31.25\\textsubscript{20.73} & 36.91\\textsubscript{4.15} & 22.71\\textsubscript{3.13} \\\\\n",
      " &  & 500 & 1,500 & 70.11\\textsubscript{4.45} & 54.16\\textsubscript{5.21} & 50.00\\textsubscript{25.82} & 36.67\\textsubscript{19.44} & 58.08\\textsubscript{3.24} & 41.00\\textsubscript{3.18} & 60.62\\textsubscript{5.54} & 43.72\\textsubscript{5.74} & 47.50\\textsubscript{35.62} & 39.58\\textsubscript{36.98} & 36.79\\textsubscript{3.13} & 22.58\\textsubscript{2.32} \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-16}\\arrayrulecolor{black}\n",
      "\\hline\n",
      "Table for: ['PRICE'] \n",
      "\n",
      "\n",
      "\\multirow{3}{*}{\\textbf{Real Examples}} & \\multirow{3}{*}{-} & 500 & 0 & 57.19\\textsubscript{18.15} & 42.24\\textsubscript{17.41} & 29.76\\textsubscript{24.35} & 20.00\\textsubscript{17.74} & 45.02\\textsubscript{13.70} & 30.11\\textsubscript{12.05} \\\\\n",
      " &  & 1,000 & 0 & 58.27\\textsubscript{10.47} & 41.89\\textsubscript{10.53} & 29.44\\textsubscript{24.98} & 19.91\\textsubscript{18.17} & 55.16\\textsubscript{12.38} & 39.11\\textsubscript{12.03} \\\\\n",
      " &  & 2,000 & 0 & 61.04\\textsubscript{14.46} & 45.62\\textsubscript{16.26} & 44.07\\textsubscript{29.21} & 33.93\\textsubscript{31.05} & 55.79\\textsubscript{12.44} & 39.80\\textsubscript{12.93} \\\\\n",
      "\\hline\n",
      "\\multirow{6}{*}{\\textbf{Llama-3-70B}} & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{25}}} & 25 & 475 & 24.39\\textsubscript{13.22} & 14.51\\textsubscript{8.33} & 16.96\\textsubscript{13.20} & 9.83\\textsubscript{7.89} & 32.31\\textsubscript{4.28} & 19.35\\textsubscript{3.02} \\\\\n",
      " &  & 25 & 975 & 29.58\\textsubscript{4.59} & 17.44\\textsubscript{3.15} & 7.05\\textsubscript{7.65} & 3.82\\textsubscript{4.20} & 31.54\\textsubscript{9.31} & 19.10\\textsubscript{6.78} \\\\\n",
      " &  & 25 & 1,975 & 21.10\\textsubscript{8.30} & 12.03\\textsubscript{5.18} & 11.60\\textsubscript{10.84} & 6.52\\textsubscript{6.36} & 33.38\\textsubscript{8.26} & 20.34\\textsubscript{6.14} \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-10}\\arrayrulecolor{black}\n",
      " & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{500}}} & 500 & 500 & 36.51\\textsubscript{19.06} & 23.86\\textsubscript{13.18} & 17.26\\textsubscript{18.95} & 10.71\\textsubscript{12.28} & 42.59\\textsubscript{10.14} & 27.61\\textsubscript{8.52} \\\\\n",
      " &  & 500 & 1,000 & 42.07\\textsubscript{13.19} & 27.60\\textsubscript{11.58} & 20.60\\textsubscript{17.30} & 12.57\\textsubscript{11.32} & 47.14\\textsubscript{9.09} & 31.35\\textsubscript{8.59} \\\\\n",
      " &  & 500 & 1,500 & 38.66\\textsubscript{5.70} & 24.12\\textsubscript{4.32} & 7.50\\textsubscript{10.70} & 4.23\\textsubscript{6.06} & 46.95\\textsubscript{10.11} & 31.24\\textsubscript{8.64} \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-10}\\arrayrulecolor{black}\n",
      "\\hline\n",
      "\\multirow{6}{*}{\\textbf{GPT-3.5-turbo}} & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{25}}} & 25 & 475 & 26.56\\textsubscript{15.20} & 16.23\\textsubscript{10.47} & 13.58\\textsubscript{15.63} & 8.08\\textsubscript{9.50} & 22.66\\textsubscript{9.85} & 13.16\\textsubscript{6.89} \\\\\n",
      " &  & 25 & 975 & 20.37\\textsubscript{10.49} & 11.74\\textsubscript{6.82} & 17.98\\textsubscript{18.81} & 11.09\\textsubscript{11.79} & 27.10\\textsubscript{12.88} & 16.41\\textsubscript{9.82} \\\\\n",
      " &  & 25 & 1,975 & 16.95\\textsubscript{4.70} & 9.33\\textsubscript{2.80} & 14.41\\textsubscript{13.67} & 8.38\\textsubscript{8.35} & 25.83\\textsubscript{14.02} & 15.66\\textsubscript{10.28} \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-10}\\arrayrulecolor{black}\n",
      " & \\multirow{3}{*}{\\textbf{LRS\\textsubscript{500}}} & 500 & 500 & 50.65\\textsubscript{5.74} & 34.11\\textsubscript{5.06} & 29.63\\textsubscript{36.10} & 24.76\\textsubscript{35.44} & 48.37\\textsubscript{14.96} & 33.25\\textsubscript{13.78} \\\\\n",
      " &  & 500 & 1,000 & 42.79\\textsubscript{14.60} & 28.23\\textsubscript{11.03} & 22.02\\textsubscript{24.08} & 14.60\\textsubscript{16.51} & 40.61\\textsubscript{14.25} & 26.54\\textsubscript{11.87} \\\\\n",
      " &  & 500 & 1,500 & 38.64\\textsubscript{9.43} & 24.40\\textsubscript{7.72} & 19.05\\textsubscript{26.94} & 13.33\\textsubscript{18.86} & 45.09\\textsubscript{12.14} & 29.93\\textsubscript{10.55} \\\\\n",
      "\\arrayrulecolor{gray}\\cline{2-10}\\arrayrulecolor{black}\n",
      "\\hline\n"
     ]
    }
   ],
   "source": [
    "absa_task = \"target_aspect_sentiment_detection\"\n",
    "\n",
    "idx = 0\n",
    "for ac_idx, aspect_categories in enumerate([[\"GENERAL-IMPRESSION\", \"FOOD\"], [\"SERVICE\", \"AMBIENCE\"], [\"PRICE\"]]):\n",
    "    print(\"Table for:\", aspect_categories, \"\\n\\n\")\n",
    "    for n_real_idx, n_real in enumerate([500, 1000, 2000]):\n",
    "        json_path = RESULTS_PATH_BASE + \\\n",
    "            f\"only_real_real{n_real}_synth0_{absa_task}_random.json\"\n",
    "        with open(json_path, 'r') as json_file:\n",
    "            results = json.load(json_file)\n",
    "\n",
    "        if n_real_idx == 0:\n",
    "            condition_print = \"\\\\multirow{3}{*}{\\\\textbf{Real Examples}} & \\\\multirow{3}{*}{-}\"\n",
    "        else:\n",
    "            condition_print = \" & \"\n",
    "\n",
    "        condition_string = f\"{condition_print} & {add_thousand_dots(str(n_real))} & 0 &\"\n",
    "        metrics_class_wise = \"\"\n",
    "        for ac in aspect_categories:\n",
    "            for polarity in [\"POSITIVE\", \"NEUTRAL\", \"NEGATIVE\"]:\n",
    "                for metric in [\"eval_f1\", \"eval_accuracy\"]:\n",
    "                    metrics_class_wise += f\" {get_metric(metric, ac, polarity, results)} &\"\n",
    "\n",
    "        print(condition_string + metrics_class_wise[:-1] + \"\\\\\\\\\")\n",
    "\n",
    "    print(\"\\\\hline\")\n",
    "    for llm_idx, llm in enumerate(LLMS):\n",
    "        for fs_idx, few_shot_condition in enumerate(SYNTH_COMBINATIONS.keys()):\n",
    "            for freq_idx, freq in enumerate(SYNTH_COMBINATIONS[few_shot_condition]):\n",
    "                n_real = freq[\"real\"]\n",
    "                n_synth = freq[\"synth\"]\n",
    "                json_path = RESULTS_PATH_BASE + llm + \\\n",
    "                    f\"_real{n_real}_synth{n_synth}_{absa_task}_{few_shot_condition}.json\"\n",
    "                with open(json_path, 'r') as json_file:\n",
    "                    results = json.load(json_file)\n",
    "\n",
    "                if fs_idx == 0 and freq_idx == 0:\n",
    "                    llm_print = \"\\\\multirow{6}{*}{\"+LLMS_ENCODED[llm]+\"}\"\n",
    "                else:\n",
    "                    llm_print = \"\"\n",
    "\n",
    "                if freq_idx == 0:\n",
    "                    condition_print = \"\\\\multirow{3}{*}{\" + \\\n",
    "                        ENCODE_CONDITION[few_shot_condition]+\"}\"\n",
    "                else:\n",
    "                    condition_print = \"\"\n",
    "\n",
    "                condition_string = f\"{llm_print} & {condition_print} & {add_thousand_dots(str(n_real))} & {add_thousand_dots(str(n_synth))} &\"\n",
    "                metrics_class_wise = \"\"\n",
    "                for ac in aspect_categories:\n",
    "                    for polarity in [\"POSITIVE\", \"NEUTRAL\", \"NEGATIVE\"]:\n",
    "                        for metric in [\"eval_f1\", \"eval_accuracy\"]:\n",
    "                            metrics_class_wise += f\" {get_metric(metric, ac, polarity, results)} &\"\n",
    "\n",
    "                print(condition_string + metrics_class_wise[:-1] + \"\\\\\\\\\")\n",
    "            \n",
    "                n_col = 10 if ac_idx == 2 else 16\n",
    "                if freq_idx == 2:\n",
    "                   print(\"\\\\arrayrulecolor{gray}\\cline{2-\"+str(n_col)+\"}\\\\arrayrulecolor{black}\")\n",
    "        print(\"\\hline\")\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'staff'"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"The staff is very unfriendly, but it was delicious.\"[4:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pizza'"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"It was very delicious, even the pizza was delicious\"[32:37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_m1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
