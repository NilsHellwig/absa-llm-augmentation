{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook: Compare LLM and Human Annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "import json\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath('../07 train models/'))\n",
    "from TASD.evaluation import calculate_metrics_for_examples\n",
    "import constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "LLMS = [\"Llama70B\", \"GPT-3\"]\n",
    "FEW_SHOT_CONDITIONS = [\"random\", \"fixed\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Human Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"annotation_datasets/annotated_synth_dataset.json\", 'r') as json_file:\n",
    "    human_annotations = json.load(json_file)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Synthetic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_annotations = []\n",
    "\n",
    "for llm in LLMS:\n",
    "    for fs in [\"random\", \"fixed\"]:\n",
    "       for split_id in range(5):\n",
    "           with open(f\"../07 train models/synth/{llm}/{fs}/split_{split_id}.json\", 'r') as json_file:\n",
    "              synthetic_data_split = json.load(json_file)\n",
    "              for example in  synthetic_data_split:\n",
    "                  llm_annotations.append(example)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34750, 2293)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(llm_annotations), len(human_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_annotations_aspects = [([{\"aspect_category\": tag[\"label\"], \"aspect_polarity\": tag[\"polarity\"],\n",
    "                              \"aspect_term\": tag[\"text\"]} for tag in example[\"tags\"]], example[\"id\"]) for example in llm_annotations]\n",
    "human_annotations_aspects = [([{\"aspect_category\": tag[\"label\"], \"aspect_polarity\": tag[\"polarity\"], \"aspect_term\": tag[\"text\"]\n",
    "                                if tag[\"text\"] != 'NULL' else None} for tag in example[\"tags\"]], example[\"id\"], example[\"model\"], example[\"few_shot_condtion\"]) for example in human_annotations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'aspect_category': 'GENERAL-IMPRESSION',\n",
       "   'aspect_polarity': 'POSITIVE',\n",
       "   'aspect_term': None}],\n",
       " 'a49a6f01-1ecc-4da0-b76b-f283f518fc60',\n",
       " 'Llama70B',\n",
       " 'random')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_annotations_aspects[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llama70B random \n",
      " ----- ----- -----\n",
      "{'f1': 0.4669312169312169, 'recall': 0.500709219858156, 'precision': 0.43742255266418834, 'accuracy': 0.30457290767903367, 'tp': 353, 'tn': 0, 'fp': 454, 'fn': 352}\n",
      "Llama70B fixed \n",
      " ----- ----- -----\n",
      "{'f1': 0.4382227632379793, 'recall': 0.46272493573264784, 'precision': 0.4161849710982659, 'accuracy': 0.2805923616523772, 'tp': 360, 'tn': 0, 'fp': 505, 'fn': 418}\n",
      "GPT-3 random \n",
      " ----- ----- -----\n",
      "{'f1': 0.572644376899696, 'recall': 0.576499388004896, 'precision': 0.5688405797101449, 'accuracy': 0.40119250425894376, 'tp': 471, 'tn': 0, 'fp': 357, 'fn': 346}\n",
      "GPT-3 fixed \n",
      " ----- ----- -----\n",
      "{'f1': 0.5832414553472989, 'recall': 0.5977401129943503, 'precision': 0.5694294940796556, 'accuracy': 0.41167315175097274, 'tp': 529, 'tn': 0, 'fp': 400, 'fn': 356}\n"
     ]
    }
   ],
   "source": [
    "def get_example_with_id(id, dataset):\n",
    "    return [example for example in dataset if example[1] == id][0][0]\n",
    "\n",
    "for llm in LLMS:\n",
    "    for fs in FEW_SHOT_CONDITIONS:\n",
    "        human_annotations_aspects_ids = [example[1] for example in human_annotations_aspects if example[2] == llm and example[3] == fs]\n",
    "        human_annotations_samples = [example[0] for example in human_annotations_aspects if example[2] == llm and example[3] == fs]\n",
    "        llm_annotations_samples = [get_example_with_id(id, llm_annotations_aspects) for id in human_annotations_aspects_ids]\n",
    "\n",
    "        print(llm, fs, \"\\n\", \"----- ----- -----\")\n",
    "        print(calculate_metrics_for_examples(\n",
    "            human_annotations_samples, llm_annotations_samples))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_m1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
