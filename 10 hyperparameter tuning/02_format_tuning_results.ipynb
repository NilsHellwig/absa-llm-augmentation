{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook: Format Hyperparameter Tuning Results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASKS = [\"acd\", \"acsa\"]\n",
    "TASK_ENCODING = {\"acd\": \"\\\\textbf{ACD}\", \"acsa\": \"\\\\textbf{ACSA}\"}\n",
    "SAMPLE_SIZES = [500, 1000, 1500, 2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_number(num, decimal_places):\n",
    "    formatted_num = \"{:.{}f}\".format(num, decimal_places)\n",
    "    rounded_num_str = \"{:.{}f}\".format(float(formatted_num), decimal_places)\n",
    "    return rounded_num_str\n",
    "\n",
    "\n",
    "def add_thousand_dots(n_sample):\n",
    "    if isinstance(n_sample, str):\n",
    "        if '.' in n_sample:\n",
    "            integer_part, decimal_part = n_sample.split('.')\n",
    "            formatted_integer_part = \"{:,}\".format(int(integer_part))\n",
    "            result = f\"{formatted_integer_part}.{decimal_part}\"\n",
    "        else:\n",
    "            result = \"{:,}\".format(int(n_sample))\n",
    "    elif isinstance(n_sample, np.float64):\n",
    "        result = \"{:,}\".format(round(n_sample, 1))\n",
    "    else:\n",
    "        result = n_sample\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\textbf{ACD} & 500 & 18 & 2.306607423476585e-05 & 32 & 0.883 & 0.787 \\\\\n",
      "\\textbf{ACD} & 1,000 & 18 & 2.2972992439646065e-05 & 16 & 0.897 & 0.818 \\\\\n",
      "\\textbf{ACD} & 1,500 & 15 & 2.4310619959329485e-05 & 16 & 0.912 & 0.842 \\\\\n",
      "\\textbf{ACD} & 2,000 & 13 & 2.007746361441613e-05 & 32 & 0.899 & 0.823 \\\\\n",
      "\\textbf{ACSA} & 500 & 14 & 2.5039162108037824e-05 & 16 & 0.762 & 0.612 \\\\\n",
      "\\textbf{ACSA} & 1,000 & 10 & 2.5286220514948297e-05 & 8 & 0.798 & 0.703 \\\\\n",
      "\\textbf{ACSA} & 1,500 & 14 & 3.002281365452465e-05 & 8 & 0.823 & 0.716 \\\\\n",
      "\\textbf{ACSA} & 2,000 & 14 & 2.892205905032184e-05 & 16 & 0.800 & 0.688 \\\\\n"
     ]
    }
   ],
   "source": [
    "for task_idx, task in enumerate(TASKS):\n",
    "    for sample_size_idx, sample_size in enumerate(SAMPLE_SIZES):\n",
    "        tsv_file_path = f\"optuna_20_gbert_{task}_{sample_size}.tsv\"\n",
    "        df = pd.read_csv(tsv_file_path, delimiter='\\t')\n",
    "        max_f1_micro_index = df['f1_micro'].idxmax()\n",
    "        values_at_max_f1_micro = df.loc[max_f1_micro_index, [\n",
    "            'learning_rate', 'num_train_epochs', 'per_device_train_batch_size', 'f1_micro', 'accuracy']]\n",
    "        print(TASK_ENCODING[task],\n",
    "              \"&\", add_thousand_dots(str(sample_size)),\n",
    "              \"&\", str(values_at_max_f1_micro[\"num_train_epochs\"]),\n",
    "              \"&\", str(values_at_max_f1_micro[\"learning_rate\"]),\n",
    "              \"&\", str(values_at_max_f1_micro[\"per_device_train_batch_size\"]),\n",
    "              \"&\", round_number(values_at_max_f1_micro[\"f1_micro\"], 3),\n",
    "              \"&\", round_number(values_at_max_f1_micro[\"accuracy\"], 3), \"\\\\\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_m1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
